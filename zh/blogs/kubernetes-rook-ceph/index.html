<!doctype html><html lang=en-US><head><meta charset=utf-8><title>Kubernetes 持久化存储之 Rook Ceph 探究</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="本文将重点实战演示使用 Rook Ceph 在 Kubernetes 集群上直接部署 Ceph 集群的方法"><meta name=keywords content="KubeSphere,Kubernetes,Rook,Ceph"><meta property="og:type" content="article"><meta property="og:title" content="Kubernetes 持久化存储之 Rook Ceph 探究"><meta property="og:description" content="本文将重点实战演示使用 Rook Ceph 在 Kubernetes 集群上直接部署 Ceph 集群的方法"><meta property="og:image" content="https://pek3b.qingstor.com/kubesphere-community/images/k8s-rook-ceph--20240813-cover.png"><meta property="og:url" content="https://openksc.github.io/zh/blogs/kubernetes-rook-ceph/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@KubeSphere"><meta property="twitter:image" content="https://pek3b.qingstor.com/kubesphere-community/images/k8s-rook-ceph--20240813-cover.png"><meta name=docsearch:language content="zh-CN"><meta name=docsearch:version content><link rel=canonical href=https://kubesphere.io/zh/blogs/kubernetes-rook-ceph/><link rel="shortcut icon" href=/images/favicons/favicon.ico><link rel=apple-touch-icon href=/images/favicons/apple-touch-icon.png sizes=180x180><link rel=icon type=image/png href=/images/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/images/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/svg+xml href=/images/favicons/favicon.svg><link rel=icon type=image/png href=/images/favicons/favicon.png><link rel=manifest href=/images/favicons/site.webmanifest><link rel=mask-icon href=/images/favicons/safari-pinned-tab.svg color=#00ad6e><meta name=msapplication-config content='/images/favicons/browserconfig.xml'><meta name=msapplication-TileColor content="#ffffff"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=/fonts/Roboto/stylesheet.css><link rel=stylesheet href=/fonts/ProximaNova/stylesheet.css><link rel=stylesheet href=/css/jquery.modal.min.css><link rel=stylesheet href=/css/viewer.min.css><link rel=stylesheet href=/swiper/swiper-bundle.min.css><link rel=stylesheet href=/scss/common.min.0c3fdcc05ec210321169846714f74b11c4a1baf09a1833fa9273b2347c81e636.css><script src=/js/jquery-3.7.1.min.js></script><script src=/js/viewer.min.js></script><script src=/js/jquery.modal.min.js></script><script src=/swiper/swiper-bundle.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?0888981f1fa45d241b1fb6962da2963e",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-YYCVN36HT5"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YYCVN36HT5")</script><script type=text/javascript>!function(e,t,n,s,o){e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},n=t.createElement("script"),tag=t.getElementsByTagName("script")[0],n.async=1,n.src=("https:"==document.location.protocol?"https://":"http://")+s,tag.parentNode.insertBefore(n,tag)}(window,document,"script","assets.giocdn.com/2.1/gio.js","gio"),gio("init","8a24ae300cbf8b8c",{}),gio("send")</script><link rel=stylesheet href=/scss/content.min.f73b326fbf8c5bd331900b0de21c7dde608a4926f482f6465f9ae1d9049b83ad.css><link rel=stylesheet href=/scss/markdown.min.db47186481122431dffae72d17dbbd51f90b66f022cc163458645709924e4eac.css></head><body><header class=navigation><div class=join-div><div class=content>🚀 KubeSphere v4.1.3 发布，多项优化与改进，欢迎体验！<a href=/zh/docs/v4.1/20-release-notes/release-v413/ target=_blank rel="noopener noreferrer">请查看 Release notes →</a>
<img id=close-join src=/images/header/close.svg alt=close></div></div><div class=common-layout><div class=header-container><a href=/zh/ aria-label=logo><img src=/images/header/logo.svg alt class=logo></a><ul class=nav><li class=menu-li><span class=menu-span>应用场景</span><ul class="dropdown-menu menu-2"><li><a href=/zh/devops/>拥抱一站式 DevOps 工作流</a></li><li><a href=/zh/service-mesh/>在 Kubernetes 运行微服务</a></li><li><a href=/zh/observability/>构建丰富的云原生可观测性</a></li></ul></li><li class=menu-li><span class=menu-span>资源</span><ul class="dropdown-menu menu-3"><li><a href=/zh/projects/>开源项目</a></li><li><a href=/zh/conferences/>开源峰会</a></li><li><a href=/zh/blogs/>技术博客</a></li><li><a href=/zh/videos/>视频资源</a></li><li><a href=/zh/learn/>云原生实战</a></li></ul></li><li class=menu-li><span class=menu-span>文档中心</span><ul class="dropdown-menu menu-4"><li><a href=/zh/docs/v4.1>v4.1 <img src=/images/header/star.svg alt=star></a></li><li><a href=/zh/docs/v3.4>v3.4</a></li><li><a href=/zh/docs/v3.3>v3.3</a></li><li><a href=https://dev-guide.kubesphere.io/extension-dev-guide/zh/ target=_blank rel="noopener noreferrer">扩展组件开发</a></li><li><a href=https://kube.design/ target=_blank rel="noopener noreferrer">Kube Design</a></li></ul></li><li class=menu-li><span class=menu-span>开源社区</span><ul class="dropdown-menu menu-5"><li><a href=/zh/contribution/>参与贡献</a></li><li><a href=/zh/live/>社区活动</a></li><li><a href=/zh/case/>案例学习</a></li><li><a href=/zh/partner/>合作伙伴</a></li><li><a href=/zh/user-group/>用户委员会</a></li><li><a href=/zh/news/>动态</a></li><li><a href=https://github.com/kubesphere/kubesphere/blob/master/docs/roadmap.md target=_blank rel="noopener noreferrer">版本计划</a></li><li><a href=https://www.kubesphere.io/zh/ target=_blank rel="noopener noreferrer">中国站</a></li><li><a href=https://github.com/kubesphere/community/tree/master/sig-advocacy-and-outreach/ospp-2025 target=_blank rel="noopener noreferrer">开源之夏 2025</a></li></ul></li><li><a data-docs=用户论坛 href=https://ask.kubesphere.io/forum target=_blank rel="noopener noreferrer">用户论坛</a></li><li><a data-docs=认证 href=https://kubesphere.cloud/certification/ target=_blank rel="noopener noreferrer">认证</a></li></ul><div class=right-menu><ul><li class=language-menu><div><img src=/images/header/black.svg alt>
<span>简体中文</span></div><ul class=dropdown-menu><li onclick='handleLangClick("zh","/zh/blogs/kubernetes-rook-ceph/")'>简体中文</li></ul></li><li class=github-li><div class=github-star><a class=star-btn href=https://github.com/kubesphere/kubesphere rel="noopener noreferrer" target=_blank><span class=star-img></span>&nbsp;<span>Star</span>
</a><a class=social-count href=https://github.com/kubesphere/kubesphere/stargazers rel="noopener noreferrer" target=_blank></a></div></li><li class=menu-icon><img src=/images/header/menu.svg alt></li></ul></div></div></div><div id=modal-for-menu class=modal><ul class=nav><li data-check=0 class=menu-li><span class=menu-span>应用场景</span><ul class=dropdown-menu><li><a href=/zh/devops/>拥抱一站式 DevOps 工作流</a></li><li><a href=/zh/service-mesh/>在 Kubernetes 运行微服务</a></li><li><a href=/zh/observability/>构建丰富的云原生可观测性</a></li></ul></li><li data-check=0 class=menu-li><span class=menu-span>资源</span><ul class=dropdown-menu><li><a href=/zh/projects/>开源项目</a></li><li><a href=/zh/conferences/>开源峰会</a></li><li><a href=/zh/blogs/>技术博客</a></li><li><a href=/zh/videos/>视频资源</a></li><li><a href=/zh/learn/>云原生实战</a></li></ul></li><li data-check=0 class=menu-li><span class=menu-span>文档中心</span><ul class=dropdown-menu><li><a href=/zh/docs/v4.1>v4.1 <img src=/images/header/star.svg alt=star></a></li><li><a href=/zh/docs/v3.4>v3.4</a></li><li><a href=/zh/docs/v3.3>v3.3</a></li><li><a href=https://dev-guide.kubesphere.io/extension-dev-guide/zh/>扩展组件开发</a></li><li><a href=https://kube.design/>Kube Design</a></li></ul></li><li data-check=0 class=menu-li><span class=menu-span>开源社区</span><ul class=dropdown-menu><li><a href=/zh/contribution/>参与贡献</a></li><li><a href=/zh/live/>社区活动</a></li><li><a href=/zh/case/>案例学习</a></li><li><a href=/zh/partner/>合作伙伴</a></li><li><a href=/zh/user-group/>用户委员会</a></li><li><a href=/zh/news/>动态</a></li><li><a href=https://github.com/kubesphere/kubesphere/blob/master/docs/roadmap.md>版本计划</a></li><li><a href=https://www.kubesphere.io/zh/>中国站</a></li><li><a href=https://github.com/kubesphere/community/tree/master/sig-advocacy-and-outreach/ospp-2025>开源之夏 2025</a></li></ul></li><li><a data-docs=用户论坛 href=https://ask.kubesphere.io/forum>用户论坛</a></li><li><a data-docs=认证 href=https://kubesphere.cloud/certification/>认证</a></li></ul><div class=link-div><a href=https://join.slack.com/t/kubesphere/shared_invite/zt-2b4t6rdb4-ico_4UJzCln_S2c1pcrIpQ target=_blank rel="noopener noreferrer" aria-label=slack><img src=/images/header/slack-hover.svg alt>
</a><a href=https://x.com/KubeSphere target=_blank rel="noopener noreferrer" aria-label=twitter><img src=/images/header/twitter-hover.svg alt>
</a><a href=https://github.com/kubesphere/kubesphere target=_blank rel="noopener noreferrer" aria-label=github><img src=/images/header/github-hover.svg alt></a></div></div></header><script>var bindNavMouseEvent,bindScrollChangeHeader,bindClickShowMenu,bindClickModalLi,bindClickClose,language,handleLangClick,githubApiLink="https://api.github.com/repos/kubesphere/kubesphere",getStar=function(){$(".social-count").hide(),$.getJSON(githubApiLink,function(e){$(".social-count").show().html(e.stargazers_count)})};getStar(),bindNavMouseEvent=function(e,t){t||(t=$(e));var n=!1;t.mouseenter(function(){if(n)return!1;n=!0,$(this).find(".dropdown-menu").fadeIn(200,function(){n=!1})}),t.mouseleave(function(){$(this).find(".dropdown-menu").fadeOut(200)})},bindScrollChangeHeader=function(){var t=100,e=$("header");window.addEventListener("scroll",function(){var t=window.scrollY;t>0?e.addClass("navigationScroll"):e.removeClass("navigationScroll")})},bindClickShowMenu=function(){$(".menu-icon").click(function(){$("#modal-for-menu").modal()})},bindClickModalLi=function(){$(".modal .menu-li").click(function(){var e=$(this).data("check");e===0?($(this).data("check",1),$(this).find(".dropdown-menu").slideDown(200)):($(this).data("check",0),$(this).find(".dropdown-menu").slideUp(200)),$(this).find(".menu-span").toggleClass("up")})},bindClickClose=function(){$("#close-join").click(function(){$(".navigation .join-div").hide(),$(".main-section").removeClass("padding")})},language="zh",bindClickClose(),bindScrollChangeHeader(),$(".header-container .menu-li").each(function(){bindNavMouseEvent("",$(this))}),bindNavMouseEvent(".header-container .language-menu"),bindNavMouseEvent(".header-container .btn-li"),bindClickShowMenu(),bindClickModalLi(),handleLangClick=function(e,t){try{localStorage.setItem("lang",e)}catch{}location.href=t}</script><section class=main-section><div class=common-layout><div class=breadcrumb><span><a href=/zh/blogs/>技术博客</a> > </span><span>Kubernetes 持久化存储之 Rook Ceph 探究</span></div><div class='main-div middle-div'><div class=author>运维有术</div><span class=date>发布于：2024-08-13</span>&nbsp;&nbsp;&nbsp;
<span style=font-size:14px;color:#919aa3 id=busuanzi_container_page_pv>本文总阅读量：<span id=busuanzi_value_page_pv></span></span><h1>Kubernetes 持久化存储之 Rook Ceph 探究</h1><div class=share-1><div class=share><a href="https://twitter.com/intent/tweet?url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-rook-ceph%2f&text=Kubernetes%20%e6%8c%81%e4%b9%85%e5%8c%96%e5%ad%98%e5%82%a8%e4%b9%8b%20Rook%20Ceph%20%e6%8e%a2%e7%a9%b6" target=_blank rel="noopener noreferrer"><img src=/images/share/Twitter.svg alt="twitter icon">
</a><a href="https://reddit.com/submit?url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-rook-ceph%2f&title=Kubernetes%20%e6%8c%81%e4%b9%85%e5%8c%96%e5%ad%98%e5%82%a8%e4%b9%8b%20Rook%20Ceph%20%e6%8e%a2%e7%a9%b6" target=_blank rel="noopener noreferrer"><img src=/images/share/Reddit.svg alt="reddit icon">
</a><a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-rook-ceph%2f" target=_blank rel="noopener noreferrer"><img src=/images/share/Facebook.svg alt="facebook icon">
</a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-rook-ceph%2f" target=_blank rel="noopener noreferrer"><img src=/images/share/Linkedin.svg alt="linkedin icon">
</a><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-rook-ceph%2f&t=Kubernetes%20%e6%8c%81%e4%b9%85%e5%8c%96%e5%ad%98%e5%82%a8%e4%b9%8b%20Rook%20Ceph%20%e6%8e%a2%e7%a9%b6" target=_blank rel="noopener noreferrer"><img src=/images/share/HackerNews.svg alt="hackernews icon"></a></div></div><div class=content><div class=md-body><p>在 Kubernetes 生态系统中，持久化存储是支撑业务应用稳定运行的基石，对于维护整个系统的健壮性至关重要。对于选择自主搭建 Kubernetes 集群的运维架构师来说，挑选合适的后端持久化存储解决方案是关键的选型决策。目前，Ceph、GlusterFS、NFS、Longhorn 和 openEBS 等解决方案已在业界得到广泛应用。</p><p>为了丰富技术栈，并为容器云平台的持久化存储设计提供更广泛的灵活性和选择性，今天，我将带领大家一起探索，如何将 Ceph 集成到由 KubeSphere 管理的 Kubernetes 集群中。</p><p>集成 Ceph 至 Kubernetes 集群主要有两种方案：</p><ul><li>利用 Rook Ceph 直接在 Kubernetes 集群上部署 Ceph 集群，这种方式更贴近云原生的应用特性。</li><li>手动部署独立的 Ceph 集群，并配置 Kubernetes 集群与之对接，实现存储服务的集成。</li></ul><p>本文将重点实战演示使用 Rook Ceph 在 Kubernetes 集群上直接部署 Ceph 集群的方法，让您体验到云原生环境下 Ceph 部署的便捷与强大。</p><p><strong>实战服务器配置(架构 1:1 复刻小规模生产环境，配置略有不同)</strong></p><table><thead><tr><th style=text-align:center>主机名</th><th style=text-align:center>IP</th><th style=text-align:center>CPU</th><th style=text-align:center>内存</th><th style=text-align:center>系统盘</th><th style=text-align:center>数据盘</th><th style=text-align:center>用途</th></tr></thead><tbody><tr><td style=text-align:center>ksp-registry</td><td style=text-align:center>192.168.9.90</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>200</td><td style=text-align:center>Harbor 镜像仓库</td></tr><tr><td style=text-align:center>ksp-control-1</td><td style=text-align:center>192.168.9.91</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>KubeSphere/k8s-control-plane</td></tr><tr><td style=text-align:center>ksp-control-2</td><td style=text-align:center>192.168.9.92</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>KubeSphere/k8s-control-plane</td></tr><tr><td style=text-align:center>ksp-control-3</td><td style=text-align:center>192.168.9.93</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>KubeSphere/k8s-control-plane</td></tr><tr><td style=text-align:center>ksp-worker-1</td><td style=text-align:center>192.168.9.94</td><td style=text-align:center>4</td><td style=text-align:center>16</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>k8s-worker/CI</td></tr><tr><td style=text-align:center>ksp-worker-2</td><td style=text-align:center>192.168.9.95</td><td style=text-align:center>4</td><td style=text-align:center>16</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>k8s-worker</td></tr><tr><td style=text-align:center>ksp-worker-3</td><td style=text-align:center>192.168.9.96</td><td style=text-align:center>4</td><td style=text-align:center>16</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>k8s-worker</td></tr><tr><td style=text-align:center>ksp-storage-1</td><td style=text-align:center>192.168.9.97</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>400+</td><td style=text-align:center>Containerd、OpenEBS、ElasticSearch/Longhorn/Ceph/NFS</td></tr><tr><td style=text-align:center>ksp-storage-2</td><td style=text-align:center>192.168.9.98</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>300+</td><td style=text-align:center>Containerd、OpenEBS、ElasticSearch/Longhorn/Ceph</td></tr><tr><td style=text-align:center>ksp-storage-3</td><td style=text-align:center>192.168.9.99</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>300+</td><td style=text-align:center>Containerd、OpenEBS、ElasticSearch/Longhorn/Ceph</td></tr><tr><td style=text-align:center>ksp-gpu-worker-1</td><td style=text-align:center>192.168.9.101</td><td style=text-align:center>4</td><td style=text-align:center>16</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>k8s-worker(GPU NVIDIA Tesla M40 24G)</td></tr><tr><td style=text-align:center>ksp-gpu-worker-2</td><td style=text-align:center>192.168.9.102</td><td style=text-align:center>4</td><td style=text-align:center>16</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>k8s-worker(GPU NVIDIA Tesla P100 16G)</td></tr><tr><td style=text-align:center>ksp-gateway-1</td><td style=text-align:center>192.168.9.103</td><td style=text-align:center>2</td><td style=text-align:center>4</td><td style=text-align:center>40</td><td style=text-align:center></td><td style=text-align:center>自建应用服务代理网关/VIP：192.168.9.100</td></tr><tr><td style=text-align:center>ksp-gateway-2</td><td style=text-align:center>192.168.9.104</td><td style=text-align:center>2</td><td style=text-align:center>4</td><td style=text-align:center>40</td><td style=text-align:center></td><td style=text-align:center>自建应用服务代理网关/VIP：192.168.9.100</td></tr><tr><td style=text-align:center>ksp-mid</td><td style=text-align:center>192.168.9.105</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>部署在 k8s 集群之外的服务节点（Gitlab 等）</td></tr><tr><td style=text-align:center>合计</td><td style=text-align:center>15</td><td style=text-align:center>56</td><td style=text-align:center>152</td><td style=text-align:center>600</td><td style=text-align:center>2100+</td><td style=text-align:center></td></tr></tbody></table><p><strong>实战环境涉及软件版本信息</strong></p><ul><li>操作系统：<strong>openEuler 22.03 LTS SP3 x86_64</strong></li><li>KubeSphere：<strong>v3.4.1</strong></li><li>Kubernetes：<strong>v1.28.8</strong></li><li>KubeKey: <strong>v3.1.1</strong></li><li>Containerd：<strong>1.7.13</strong></li><li>Rook：<strong>v1.14.9</strong></li><li>Ceph: <strong>v18.2.4</strong></li></ul><h2 id=1-rook-部署规划>1. Rook 部署规划</h2><p>为了更好地满足生产环境的实际需求，在规划和部署存储基础设施时，我增加了以下策略：</p><ul><li><strong>节点扩展</strong>：向 Kubernetes 集群中新增三个专用节点，这些节点将专门承载 Ceph 存储服务，确保存储操作的高效性和稳定性。</li><li><strong>组件隔离</strong>：所有 Rook 和 Ceph 组件以及数据卷将被部署在这些专属节点上，实现组件的清晰隔离和专业化管理。</li><li><strong>节点标签化</strong>：为每个存储节点设置了专门的标签 <code>node.kubernetes.io/storage=rook</code>，以便 Kubernetes 能够智能地调度相关资源。同时，非存储节点将被标记为 <code>node.rook.io/rook-csi=true</code>，这表明它们将承载 Ceph CSI 插件，使得运行在这些节点上的业务 Pod 能够利用 Ceph 提供的持久化存储。</li><li><strong>存储介质配置</strong>：在每个存储节点上，我将新增一块 100G 的 Ceph 专用数据盘 <code>/dev/sdd</code>。为保证最佳性能，该磁盘将采用裸设备形态直接供 Ceph OSD 使用，<strong>无需进行分区或格式化</strong>。</li></ul><p><strong>重要提示：</strong></p><ul><li>本文提供的配置和部署经验对于理解 Rook-Ceph 的安装和运行机制具有参考价值。然而，<strong>强烈建议不要将本文描述的配置直接应用于任何形式的生产环境</strong>。</li><li>在生产环境中，还需进一步考虑使用 SSD、NVMe 磁盘等高性能存储介质；细致规划故障域；制定详尽的存储节点策略；以及进行细致的系统优化配置等。</li></ul><h2 id=2-前置条件>2. 前置条件</h2><h3 id=21--kubernetes-版本>2.1 Kubernetes 版本</h3><ul><li><p>Rook 可以安装在任何现有的 Kubernetes 集群上，只要它满足最低版本，并且授予 Rook 所需的特权</p></li><li><p>早期 <strong>v1.9.7</strong> 版本的 Rook 支持 Kubernetes <strong>v1.17</strong> 或更高版本</p></li><li><p>现在的 <strong>v1.14.9</strong> 版本支持 Kubernetes v1.25 到 v1.30 版本（可能支持更低的版本，可以自己验证测试）</p></li></ul><h3 id=22-cpu-architecture>2.2 CPU Architecture</h3><p>支持的 CPU 架构包括： <code>amd64 / x86_64</code> and <code>arm64</code>。</p><h3 id=23-ceph-先决条件>2.3 Ceph 先决条件</h3><p>为了配置 Ceph 存储集群，至少需要以下任意一种类型的本地存储:</p><ul><li>Raw devices (no partitions or formatted filesystems，没有分区和格式化文件系统，<strong>本文选择</strong>)</li><li>Raw partitions (no formatted filesystem，已分区但是没有格式化文件系统)</li><li>LVM Logical Volumes (no formatted filesystem)</li><li>PVs available from a storage class in <code>block</code> mode</li></ul><p>使用以下命令确认分区或设备是否使用文件系统并进行了格式化：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ lsblk -f
</span></span><span style=display:flex><span>NAME               FSTYPE      FSVER    LABEL  UUID                                   FSAVAIL FSUSE% MOUNTPOINTS
</span></span><span style=display:flex><span>sda
</span></span><span style=display:flex><span>├─sda1             ext4        1.0             b5e46d67-426b-476f-bd89-18137af7ff59    682.5M    23% /boot
</span></span><span style=display:flex><span>└─sda2             LVM2_member LVM2 <span style=color:#ae81ff>001</span>        NepB96-M3ux-Ei6Q-V7AX-BCy1-e2RN-Lzbecn
</span></span><span style=display:flex><span>  ├─openeuler-root ext4        1.0             0495bb1d-16f7-4156-ab10-5bd837b24de5     29.9G     7% /
</span></span><span style=display:flex><span>  └─openeuler-swap swap        <span style=color:#ae81ff>1</span>               837d3a7e-8aac-4048-bb7a-a6fdd8eb5931
</span></span><span style=display:flex><span>sdb                LVM2_member LVM2 <span style=color:#ae81ff>001</span>        Dyj93O-8zKr-HMah-hxjd-8IZP-IxVE-riWf3O
</span></span><span style=display:flex><span>└─data-lvdata      xfs                         1e9b612f-dbd9-46d2-996e-db74073d6648       86G    14% /data
</span></span><span style=display:flex><span>sdc                LVM2_member LVM2 <span style=color:#ae81ff>001</span>        LkTCe2-0vp7-e3SJ-Xxzb-UzN1-sd2T-74TF3L
</span></span><span style=display:flex><span>└─longhorn-data    xfs                         30a13ac0-6eef-433c-8d7e-d6776ec669ff     99.1G     1% /longhorn
</span></span><span style=display:flex><span>sdd
</span></span></code></pre></div><ul><li>如果 FSTYPE 字段不为空，说明该设备已经格式化为文件系统，对应的值就是文件系统类型</li><li>如果 FSTYPE 字段为空，说明该设备还没有被格式化，可以被 Ceph 使用</li><li>本例中可以使用的设备为 <strong>sdd</strong></li></ul><p>如果需要清理已有磁盘给 Ceph 使用，请使用下面的命令（<strong>生产环境请谨慎</strong>）：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install gdisk
</span></span><span style=display:flex><span>sgdisk --zap-all /dev/sdd
</span></span></code></pre></div><h3 id=24-lvm-需求>2.4 LVM 需求</h3><p>Ceph OSDs 在以下场景依赖 LVM。</p><ul><li>If encryption is enabled (<code>encryptedDevice: "true"</code> in the cluster CR)</li><li>A <code>metadata</code> device is specified</li><li><code>osdsPerDevice</code> is greater than 1</li></ul><p>Ceph OSDs 在以下场景不需要 LVM。</p><ul><li>OSDs are created on raw devices or partitions</li><li>Creating OSDs on PVCs using the <code>storageClassDeviceSets</code></li></ul><p>openEuler 默认已经安装 lvm2，如果没有装，使用下面的命令安装。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>yum install -y lvm2
</span></span></code></pre></div><h3 id=25-kernel-需求>2.5 Kernel 需求</h3><ul><li>RBD 需求</li></ul><p>Ceph 需要使用构建了 RBD 模块的 Linux 内核。许多 Linux 发行版都有这个模块，但不是所有发行版都有。例如，GKE Container-Optimised OS (COS) 就没有 RBD。</p><p>在 Kubernetes 节点使用 <code>lsmod | grep rbd</code> 命令验证，如果没有任何输出，请执行下面的命令加载 rbd 模块。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 在当前环境加载 rbd 和 nbd 模块</span>
</span></span><span style=display:flex><span>modprobe rbd
</span></span><span style=display:flex><span>modprobe nbd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 开机自动加载 rbd 和 nbd 模式（适用于 openEuler）</span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;rbd&#34;</span> &gt;&gt; /etc/modules-load.d/rook-ceph.conf
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;nbd&#34;</span> &gt;&gt; /etc/modules-load.d/rook-ceph.conf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 再次执行命令验证</span>
</span></span><span style=display:flex><span>lsmod | grep rbd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 正确的输出结果如下</span>
</span></span><span style=display:flex><span>$ lsmod | grep rbd
</span></span><span style=display:flex><span>rbd                   <span style=color:#ae81ff>135168</span>  <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>libceph               <span style=color:#ae81ff>413696</span>  <span style=color:#ae81ff>1</span> rbd
</span></span></code></pre></div><ul><li>CephFS 需求</li></ul><p>如果您将从 Ceph shared file system (CephFS) 创建卷，推荐的最低内核版本是 <strong>4.17</strong>。如果内核版本小于 4.17，则不会强制执行请求的 PVC sizes。存储配额只会在更新的内核上执行。</p><p><strong>注意：</strong> openEuler 22.03 SP3 目前最新的内核为 <code>5.10.0-218.0.0.121</code>，虽然大于 4.17 但是有些过于高了，在安装 Ceph CSI Plugin 的时候可能会遇到 CSI 驱动无法注册的问题。</p><h2 id=3-扩容集群节点>3. 扩容集群节点</h2><h3 id=31-扩容存储专用-worker-节点>3.1 扩容存储专用 Worker 节点</h3><p>将新增的三台存储专用节点加入已有的 Kubernetes 集群，详细的扩容操作请参考 <a href=https://mp.weixin.qq.com/s/l2Xm_g-vS-6Junwe8_38lQ target=_blank rel="noopener noreferrer">KubeKey 扩容 Kubernetes Worker 节点实战指南</a>。</p><h3 id=32-设置节点标签>3.2 设置节点标签</h3><p>按规划给三个存储节点和其它 Worker 节点打上专属标签。</p><ul><li>存储节点标签</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 设置 rook-ceph 部署和存储Osd 节点标签</span>
</span></span><span style=display:flex><span>kubectl label nodes ksp-storage-1 node.kubernetes.io/storage<span style=color:#f92672>=</span>rook
</span></span><span style=display:flex><span>kubectl label nodes ksp-storage-2 node.kubernetes.io/storage<span style=color:#f92672>=</span>rook
</span></span><span style=display:flex><span>kubectl label nodes ksp-storage-3 node.kubernetes.io/storage<span style=color:#f92672>=</span>rook
</span></span></code></pre></div><ul><li>Worker 节点标签</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 安装 ceph csi plugin 节点</span>
</span></span><span style=display:flex><span><span style=color:#75715e># kubectl label nodes ksp-control-1 node.rook.io/rook-csi=true</span>
</span></span><span style=display:flex><span><span style=color:#75715e># kubectl label nodes ksp-control-2 node.rook.io/rook-csi=true</span>
</span></span><span style=display:flex><span><span style=color:#75715e># kubectl label nodes ksp-control-3 node.rook.io/rook-csi=true</span>
</span></span><span style=display:flex><span>kubectl label nodes ksp-worker-1 node.rook.io/rook-csi<span style=color:#f92672>=</span>true
</span></span><span style=display:flex><span>kubectl label nodes ksp-worker-2 node.rook.io/rook-csi<span style=color:#f92672>=</span>true
</span></span><span style=display:flex><span>kubectl label nodes ksp-worker-3 node.rook.io/rook-csi<span style=color:#f92672>=</span>true
</span></span></code></pre></div><ul><li>控制（Control）节点</li></ul><p>不做任何设置，Ceph 的服务组件和 CSI 插件都不会安装在控制节点。网上也有人建议把 Ceph 的管理组件部署在 K8s 的控制节点，我是不赞同的。<strong>个人建议把 Ceph 的所有组件独立部署</strong>。</p><h2 id=4-安装配置-rook-ceph-operator>4. 安装配置 Rook Ceph Operator</h2><h3 id=41-下载部署代码>4.1 下载部署代码</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># git clone --single-branch --branch v1.14.9 https://github.com/rook/rook.git</span>
</span></span><span style=display:flex><span>cd /srv
</span></span><span style=display:flex><span>wget https://github.com/rook/rook/archive/refs/tags/v1.14.9.tar.gz
</span></span><span style=display:flex><span>tar xvf v1.14.9.tar.gz
</span></span><span style=display:flex><span>cd rook-1.14.9/deploy/examples/
</span></span></code></pre></div><h3 id=42-修改镜像地址>4.2 修改镜像地址</h3><p>可选配置，当 <strong>DockerHub</strong> 访问受限时，可以将 Rook-Ceph 需要的镜像离线下载到本地仓库，部署时修改镜像地址。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 取消镜像注释</span>
</span></span><span style=display:flex><span>sed -i <span style=color:#e6db74>&#39;125,130s/^.*#/ /g&#39;</span> operator.yaml
</span></span><span style=display:flex><span>sed -i <span style=color:#e6db74>&#39;506,506s/^.*#/ /g&#39;</span> operator.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 替换镜像地址前缀</span>
</span></span><span style=display:flex><span>sed -i <span style=color:#e6db74>&#39;s#registry.k8s.io#registry.opsxlab.cn:8443/k8sio#g&#39;</span> operator.yaml
</span></span><span style=display:flex><span>sed -i <span style=color:#e6db74>&#39;s#quay.io#registry.opsxlab.cn:8443/quayio#g&#39;</span> operator.yaml
</span></span><span style=display:flex><span>sed -i <span style=color:#e6db74>&#39;s#rook/ceph:v1.14.9#registry.opsxlab.cn:8443/rook/ceph:v1.14.9#g&#39;</span> operator.yaml
</span></span><span style=display:flex><span>sed -i <span style=color:#e6db74>&#39;24,24s#quay.io#registry.opsxlab.cn:8443/quayio#g&#39;</span> cluster.yaml
</span></span></code></pre></div><blockquote><p>注意：上面的镜像仓库是我内部离线仓库，参考我文档的读者不要直接照抄，一定要换成自己的镜像仓库。</p></blockquote><h3 id=43-修改自定义配置>4.3 修改自定义配置</h3><p>修改配置文件 <code>operator.yaml</code> 实现以下需求：</p><ul><li>rook-ceph 所有管理组件部署在指定标签节点</li><li>k8s 其他节点安装 Ceph CSI Plugin</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>CSI_PROVISIONER_NODE_AFFINITY</span>: <span style=color:#e6db74>&#34;node.kubernetes.io/storage=rook&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>CSI_PLUGIN_NODE_AFFINITY</span>: <span style=color:#e6db74>&#34;node.rook.io/rook-csi=true,node.kubernetes.io/storage=rook&#34;</span>
</span></span></code></pre></div><h3 id=44-部署-rook-operator>4.4 部署 Rook Operator</h3><ul><li>部署 Rook operator</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl create -f crds.yaml -f common.yaml -f operator.yaml
</span></span></code></pre></div><ul><li>验证 <code>rook-ceph-operator</code> Pod 的状态是否为 <code>Running</code></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl -n rook-ceph get pod -o wide
</span></span></code></pre></div><p><strong>执行成功后，输出结果如下：</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl -n rook-ceph get pod -o wide
</span></span><span style=display:flex><span>NAME                                 READY   STATUS    RESTARTS   AGE   IP              NODE            NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>rook-ceph-operator-9bd897ff8-426mq   1/1     Running   <span style=color:#ae81ff>0</span>          40s   10.233.77.255   ksp-storage-3   &lt;none&gt;           &lt;none&gt;
</span></span></code></pre></div><h3 id=45-kubesphere-控制台查看-operator-资源>4.5 KubeSphere 控制台查看 Operator 资源</h3><p>登录 KubeSphere 控制台查看创建的 Rook Ceph Operator Deployment 资源。</p><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//ksp-clusters-deployments-rook-ceph-operator-v1149.png alt></p><h2 id=5-创建-ceph-集群>5. 创建 Ceph 集群</h2><h3 id=51--修改集群配置文件>5.1 修改集群配置文件</h3><ul><li>修改集群配置文件 <code>cluster.yaml</code>，增加节点亲和配置</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>placement</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>all</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>nodeAffinity</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>requiredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>nodeSelectorTerms</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>matchExpressions</span>:
</span></span><span style=display:flex><span>          - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>node.kubernetes.io/storage</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>values</span>:
</span></span><span style=display:flex><span>            - <span style=color:#ae81ff>rook</span>
</span></span></code></pre></div><ul><li>修改集群配置文件 <code>cluster.yaml</code>，增加存储节点和 OSD 磁盘配置</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>storage</span>: <span style=color:#75715e># cluster level storage configuration and selection</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>useAllNodes</span>: <span style=color:#66d9ef>false</span>  <span style=color:#75715e># 生产环境，一定要修改，默认会使用所有节点</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>useAllDevices</span>: <span style=color:#66d9ef>false</span> <span style=color:#75715e># 生产环境，一定要修改，默认会使用所有磁盘</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e>#deviceFilter:</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>config</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>storeType</span>: <span style=color:#ae81ff>bluestore</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>nodes</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#34;ksp-storage-1&#34;</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>devices</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#34;sdd&#34;</span>
</span></span><span style=display:flex><span>    - <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#34;ksp-storage-2&#34;</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>devices</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#34;sdd&#34;</span>
</span></span><span style=display:flex><span>    - <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#34;ksp-storage-3&#34;</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>devices</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#34;sdd&#34;</span>
</span></span></code></pre></div><h3 id=52-创建-ceph-集群>5.2 创建 Ceph 集群</h3><ul><li>创建集群</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f cluster.yaml
</span></span></code></pre></div><ul><li>查看资源状态，确保所有相关 Pod 均为 <code>Running</code></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl -n rook-ceph get pod -o wide
</span></span><span style=display:flex><span>NAME                                                      READY   STATUS      RESTARTS   AGE     IP             NODE            NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>csi-cephfsplugin-5mrxf                                    2/2     Running     <span style=color:#ae81ff>0</span>          2m25s   192.168.9.96   ksp-worker-3    &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-cephfsplugin-5s4kz                                    2/2     Running     <span style=color:#ae81ff>0</span>          2m25s   192.168.9.95   ksp-worker-2    &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-cephfsplugin-kgd48                                    2/2     Running     <span style=color:#ae81ff>0</span>          2m25s   192.168.9.94   ksp-worker-1    &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-cephfsplugin-provisioner-7f595d6cc4-5xpm8             5/5     Running     <span style=color:#ae81ff>0</span>          2m25s   10.233.64.1    ksp-storage-1   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-cephfsplugin-provisioner-7f595d6cc4-q7q4v             5/5     Running     <span style=color:#ae81ff>0</span>          2m25s   10.233.77.26   ksp-storage-3   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-cephfsplugin-q7rqj                                    2/2     Running     <span style=color:#ae81ff>0</span>          2m25s   192.168.9.97   ksp-storage-1   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-cephfsplugin-x6tfj                                    2/2     Running     <span style=color:#ae81ff>0</span>          2m25s   192.168.9.99   ksp-storage-3   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-cephfsplugin-z72tl                                    2/2     Running     <span style=color:#ae81ff>0</span>          2m25s   192.168.9.98   ksp-storage-2   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-rbdplugin-2f8db                                       2/2     Running     <span style=color:#ae81ff>0</span>          2m25s   192.168.9.97   ksp-storage-1   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-rbdplugin-6dtwt                                       2/2     Running     <span style=color:#ae81ff>0</span>          2m25s   192.168.9.94   ksp-worker-1    &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-rbdplugin-82jrf                                       2/2     Running     <span style=color:#ae81ff>0</span>          2m25s   192.168.9.95   ksp-worker-2    &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-rbdplugin-dslkj                                       2/2     Running     <span style=color:#ae81ff>0</span>          2m25s   192.168.9.96   ksp-worker-3    &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-rbdplugin-gjmmw                                       2/2     Running     <span style=color:#ae81ff>0</span>          2m25s   192.168.9.98   ksp-storage-2   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-rbdplugin-hfv4k                                       2/2     Running     <span style=color:#ae81ff>0</span>          2m25s   192.168.9.99   ksp-storage-3   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-rbdplugin-provisioner-c845669bc-dp6q4                 5/5     Running     <span style=color:#ae81ff>0</span>          2m25s   10.233.64.4    ksp-storage-1   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>csi-rbdplugin-provisioner-c845669bc-f2s6n                 5/5     Running     <span style=color:#ae81ff>0</span>          2m25s   10.233.77.24   ksp-storage-3   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-crashcollector-ksp-storage-1-7b4cf6c8fb-7s85r   1/1     Running     <span style=color:#ae81ff>0</span>          68s     10.233.64.7    ksp-storage-1   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-crashcollector-ksp-storage-2-cc76b86dc-vb4gl    1/1     Running     <span style=color:#ae81ff>0</span>          53s     10.233.73.85   ksp-storage-2   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-crashcollector-ksp-storage-3-67bf8cf566-6rcjg   1/1     Running     <span style=color:#ae81ff>0</span>          52s     10.233.77.39   ksp-storage-3   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-exporter-ksp-storage-1-646fb48465-5mfcx         1/1     Running     <span style=color:#ae81ff>0</span>          68s     10.233.64.14   ksp-storage-1   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-exporter-ksp-storage-2-79fd64549d-rbcnt         1/1     Running     <span style=color:#ae81ff>0</span>          50s     10.233.73.86   ksp-storage-2   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-exporter-ksp-storage-3-7877646d8c-7h2wc         1/1     Running     <span style=color:#ae81ff>0</span>          48s     10.233.77.32   ksp-storage-3   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-mgr-a-c89b4f8bd-psdwl                           3/3     Running     <span style=color:#ae81ff>0</span>          86s     10.233.73.80   ksp-storage-2   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-mgr-b-7ffd8dcb85-jpj5x                          3/3     Running     <span style=color:#ae81ff>0</span>          86s     10.233.77.29   ksp-storage-3   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-mon-a-654b4f677-fmqhx                           2/2     Running     <span style=color:#ae81ff>0</span>          2m15s   10.233.73.79   ksp-storage-2   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-mon-b-74887d5b9c-4mb62                          2/2     Running     <span style=color:#ae81ff>0</span>          109s    10.233.77.28   ksp-storage-3   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-mon-c-5fb5489c58-7hj6n                          2/2     Running     <span style=color:#ae81ff>0</span>          99s     10.233.64.16   ksp-storage-1   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-operator-9bd897ff8-6z45z                        1/1     Running     <span style=color:#ae81ff>0</span>          29m     10.233.77.18   ksp-storage-3   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-osd-0-65ccb887ff-bjtbs                          2/2     Running     <span style=color:#ae81ff>0</span>          54s     10.233.64.19   ksp-storage-1   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-osd-1-c689d9f57-x6prx                           2/2     Running     <span style=color:#ae81ff>0</span>          53s     10.233.73.84   ksp-storage-2   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-osd-2-776bb9cbd6-vmxxp                          2/2     Running     <span style=color:#ae81ff>0</span>          52s     10.233.77.37   ksp-storage-3   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-osd-prepare-ksp-storage-1-tj6rk                 0/1     Completed   <span style=color:#ae81ff>0</span>          64s     10.233.64.18   ksp-storage-1   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-osd-prepare-ksp-storage-2-rds4q                 0/1     Completed   <span style=color:#ae81ff>0</span>          63s     10.233.73.83   ksp-storage-2   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>rook-ceph-osd-prepare-ksp-storage-3-hpzgs                 0/1     Completed   <span style=color:#ae81ff>0</span>          63s     10.233.77.41   ksp-storage-3   &lt;none&gt;           &lt;none&gt;
</span></span></code></pre></div><h3 id=53-kubesphere-控制台查看-ceph-集群资源>5.3 KubeSphere 控制台查看 Ceph 集群资源</h3><ul><li>Deployment（部署，17个）</li></ul><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//ksp-clusters-deployments-rook-ceph-v1149.png alt></p><ul><li>Daemonsets（守护进程集，2个）</li></ul><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//ksp-clusters-daemonsets-rook-ceph-v1149.png alt></p><h2 id=6-创建-rook-toolbox>6. 创建 Rook toolbox</h2><p>通过 Rook 提供的 toolbox，我们可以实现对 Ceph 集群的管理。</p><h3 id=61-创建-toolbox>6.1 创建 toolbox</h3><ul><li>创建 toolbox</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f toolbox.yaml
</span></span></code></pre></div><ul><li>等待 toolbox pod 下载容器镜像，并进入 <strong>Running</strong> 状态:</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl -n rook-ceph rollout status deploy/rook-ceph-tools
</span></span></code></pre></div><h3 id=62-常用命令>6.2 常用命令</h3><ul><li>登录 Toolbox</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- bash
</span></span></code></pre></div><ul><li>验证 Ceph 集群状态</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- bash
</span></span><span style=display:flex><span>bash-5.1$ ceph -s
</span></span><span style=display:flex><span>  cluster:
</span></span><span style=display:flex><span>    id:     e7913148-d29f-46fa-87a6-1c38ddb1530a
</span></span><span style=display:flex><span>    health: HEALTH_OK
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  services:
</span></span><span style=display:flex><span>    mon: <span style=color:#ae81ff>3</span> daemons, quorum a,b,c <span style=color:#f92672>(</span>age 6m<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>    mgr: a<span style=color:#f92672>(</span>active, since 5m<span style=color:#f92672>)</span>, standbys: b
</span></span><span style=display:flex><span>    osd: <span style=color:#ae81ff>3</span> osds: <span style=color:#ae81ff>3</span> up <span style=color:#f92672>(</span>since 5m<span style=color:#f92672>)</span>, <span style=color:#ae81ff>3</span> in <span style=color:#f92672>(</span>since 5m<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  data:
</span></span><span style=display:flex><span>    pools:   <span style=color:#ae81ff>1</span> pools, <span style=color:#ae81ff>1</span> pgs
</span></span><span style=display:flex><span>    objects: <span style=color:#ae81ff>2</span> objects, <span style=color:#ae81ff>577</span> KiB
</span></span><span style=display:flex><span>    usage:   <span style=color:#ae81ff>81</span> MiB used, <span style=color:#ae81ff>300</span> GiB / <span style=color:#ae81ff>300</span> GiB avail
</span></span><span style=display:flex><span>    pgs:     <span style=color:#ae81ff>1</span> active+clean
</span></span></code></pre></div><blockquote><p>观察 Ceph 集群状态，需要满足下面的条件才会认为集群状态是健康的。</p><ul><li>health 的值为 HEALTH_OK</li><li>Mons 的数量和状态</li><li>Mgr 一个 active，一个 standbys</li><li>OSD 3 个，状态都是 up</li></ul></blockquote><ul><li>其他常用的 Ceph 命令</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#75715e># 查看 OSD 状态</span>
</span></span><span style=display:flex><span>ceph osd status
</span></span><span style=display:flex><span>ceph osd df
</span></span><span style=display:flex><span>ceph osd utilization
</span></span><span style=display:flex><span>ceph osd pool stats
</span></span><span style=display:flex><span>ceph osd tree
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 查看 Ceph 容量</span>
</span></span><span style=display:flex><span>ceph df
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 查看 Rados 状态</span>
</span></span><span style=display:flex><span>rados df
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 查看 PG 状态</span>
</span></span><span style=display:flex><span>ceph pg stat
</span></span></code></pre></div><ul><li>删除 toolbox（可选）</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl -n rook-ceph delete deploy/rook-ceph-tools
</span></span></code></pre></div><h2 id=7-block-storage>7. Block Storage</h2><h3 id=71-storage-介绍>7.1 Storage 介绍</h3><p>Rock Ceph 提供了三种存储类型，请参考官方指南了解详情：</p><ul><li><strong><a href=https://rook.io/docs/rook/latest-release/Storage-Configuration/Block-Storage-RBD/block-storage/ target=_blank rel="noopener noreferrer">Block Storage(RBD)</a></strong>: Create block storage to be consumed by a pod (RWO)</li><li><strong><a href=https://rook.io/docs/rook/latest-release/Storage-Configuration/Shared-Filesystem-CephFS/filesystem-storage/ target=_blank rel="noopener noreferrer">Filesystem Storage(CephFS)</a></strong>: Create a filesystem to be shared across multiple pods (RWX)</li><li><strong><a href=https://rook.io/docs/rook/latest-release/Storage-Configuration/Object-Storage-RGW/object-storage/ target=_blank rel="noopener noreferrer">Object Storage(RGW)</a></strong>: Create an object store that is accessible inside or outside the Kubernetes cluster</li></ul><p>本文使用比较稳定、可靠的 Block Storage（RBD）的方式作为 Kubernetes 的持久化存储。</p><h3 id=72-创建存储池>7.2 创建存储池</h3><p>Rook 允许通过自定义资源定义 (crd) 创建和自定义 Block 存储池。支持 Replicated 和 Erasure Coded 类型。本文演示 Replicated 的创建过程。</p><ul><li>创建一个 3 副本的 Ceph 块存储池，编辑 <code>CephBlockPool</code> CR 资源清单，<code>vi ceph-replicapool.yaml</code></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>ceph.rook.io/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>CephBlockPool</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>replicapool</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>rook-ceph</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>failureDomain</span>: <span style=color:#ae81ff>host</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicated</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>size</span>: <span style=color:#ae81ff>3</span>
</span></span></code></pre></div><ul><li>创建 CephBlockPool 资源</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f ceph-replicapool.yaml
</span></span></code></pre></div><ul><li>查看资源创建情况</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get cephBlockPool -n rook-ceph -o wide
</span></span><span style=display:flex><span>NAME          PHASE   TYPE         FAILUREDOMAIN   REPLICATION   EC-CODINGCHUNKS   EC-DATACHUNKS   AGE
</span></span><span style=display:flex><span>replicapool   Ready   Replicated   host            <span style=color:#ae81ff>3</span>             <span style=color:#ae81ff>0</span>                 <span style=color:#ae81ff>0</span>               16s
</span></span></code></pre></div><ul><li>在 ceph toolbox 中查看 Ceph 集群状态</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#75715e># 登录</span>
</span></span><span style=display:flex><span>kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- bash
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 查看集群</span>
</span></span><span style=display:flex><span>bash-5.1$ ceph -s
</span></span><span style=display:flex><span>  cluster:
</span></span><span style=display:flex><span>    id:     e7913148-d29f-46fa-87a6-1c38ddb1530a
</span></span><span style=display:flex><span>    health: HEALTH_OK
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  services:
</span></span><span style=display:flex><span>    mon: <span style=color:#ae81ff>3</span> daemons, quorum a,b,c <span style=color:#f92672>(</span>age 10m<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>    mgr: a<span style=color:#f92672>(</span>active, since 8m<span style=color:#f92672>)</span>, standbys: b
</span></span><span style=display:flex><span>    osd: <span style=color:#ae81ff>3</span> osds: <span style=color:#ae81ff>3</span> up <span style=color:#f92672>(</span>since 9m<span style=color:#f92672>)</span>, <span style=color:#ae81ff>3</span> in <span style=color:#f92672>(</span>since 9m<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  data:
</span></span><span style=display:flex><span>    pools:   <span style=color:#ae81ff>2</span> pools, <span style=color:#ae81ff>2</span> pgs
</span></span><span style=display:flex><span>    objects: <span style=color:#ae81ff>3</span> objects, <span style=color:#ae81ff>577</span> KiB
</span></span><span style=display:flex><span>    usage:   <span style=color:#ae81ff>81</span> MiB used, <span style=color:#ae81ff>300</span> GiB / <span style=color:#ae81ff>300</span> GiB avail
</span></span><span style=display:flex><span>    pgs:     <span style=color:#ae81ff>2</span> active+clean
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 查看集群存储池 </span>
</span></span><span style=display:flex><span>bash-5.1$ ceph osd pool ls
</span></span><span style=display:flex><span>.mgr
</span></span><span style=display:flex><span>replicapool
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>bash-5.1$ rados df
</span></span><span style=display:flex><span>POOL_NAME       USED  OBJECTS  CLONES  COPIES  MISSING_ON_PRIMARY  UNFOUND  DEGRADED  RD_OPS      RD  WR_OPS       WR  USED COMPR  UNDER COMPR
</span></span><span style=display:flex><span>.mgr         1.7 MiB        <span style=color:#ae81ff>2</span>       <span style=color:#ae81ff>0</span>       <span style=color:#ae81ff>6</span>                   <span style=color:#ae81ff>0</span>        <span style=color:#ae81ff>0</span>         <span style=color:#ae81ff>0</span>     <span style=color:#ae81ff>106</span>  <span style=color:#ae81ff>91</span> KiB     <span style=color:#ae81ff>137</span>  1.8 MiB         <span style=color:#ae81ff>0</span> B          <span style=color:#ae81ff>0</span> B
</span></span><span style=display:flex><span>replicapool   <span style=color:#ae81ff>12</span> KiB        <span style=color:#ae81ff>1</span>       <span style=color:#ae81ff>0</span>       <span style=color:#ae81ff>3</span>                   <span style=color:#ae81ff>0</span>        <span style=color:#ae81ff>0</span>         <span style=color:#ae81ff>0</span>       <span style=color:#ae81ff>0</span>     <span style=color:#ae81ff>0</span> B       <span style=color:#ae81ff>2</span>    <span style=color:#ae81ff>2</span> KiB         <span style=color:#ae81ff>0</span> B          <span style=color:#ae81ff>0</span> B
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>total_objects    <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>total_used       <span style=color:#ae81ff>81</span> MiB
</span></span><span style=display:flex><span>total_avail      <span style=color:#ae81ff>300</span> GiB
</span></span><span style=display:flex><span>total_space      <span style=color:#ae81ff>300</span> GiB
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 查看存储池的 pg number</span>
</span></span><span style=display:flex><span>bash-5.1$ ceph osd pool get replicapool pg_num
</span></span><span style=display:flex><span>pg_num: <span style=color:#ae81ff>32</span>
</span></span></code></pre></div><h3 id=73-创建-storageclass>7.3 创建 StorageClass</h3><ul><li>编辑 StorageClass 资源清单，<code>vi storageclass-rook-ceph-block.yaml</code></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>storage.k8s.io/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>StorageClass</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>   <span style=color:#f92672>name</span>: <span style=color:#ae81ff>rook-ceph-block</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Change &#34;rook-ceph&#34; provisioner prefix to match the operator namespace if needed</span>
</span></span><span style=display:flex><span><span style=color:#f92672>provisioner</span>: <span style=color:#ae81ff>rook-ceph.rbd.csi.ceph.com</span>
</span></span><span style=display:flex><span><span style=color:#f92672>parameters</span>:
</span></span><span style=display:flex><span>    <span style=color:#75715e># clusterID is the namespace where the rook cluster is running</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>clusterID</span>: <span style=color:#ae81ff>rook-ceph</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Ceph pool into which the RBD image shall be created</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>pool</span>: <span style=color:#ae81ff>replicapool</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># RBD image format. Defaults to &#34;2&#34;.</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>imageFormat</span>: <span style=color:#e6db74>&#34;2&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># RBD image features. Available for imageFormat: &#34;2&#34;. CSI RBD currently supports only `layering` feature.</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>imageFeatures</span>: <span style=color:#ae81ff>layering</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># The secrets contain Ceph admin credentials.</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>csi.storage.k8s.io/provisioner-secret-name</span>: <span style=color:#ae81ff>rook-csi-rbd-provisioner</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>csi.storage.k8s.io/provisioner-secret-namespace</span>: <span style=color:#ae81ff>rook-ceph</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>csi.storage.k8s.io/controller-expand-secret-name</span>: <span style=color:#ae81ff>rook-csi-rbd-provisioner</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>csi.storage.k8s.io/controller-expand-secret-namespace</span>: <span style=color:#ae81ff>rook-ceph</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>csi.storage.k8s.io/node-stage-secret-name</span>: <span style=color:#ae81ff>rook-csi-rbd-node</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>csi.storage.k8s.io/node-stage-secret-namespace</span>: <span style=color:#ae81ff>rook-ceph</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Specify the filesystem type of the volume. If not specified, csi-provisioner</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># will set default as `ext4`. Note that `xfs` is not recommended due to potential deadlock</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># in hyperconverged settings where the volume is mounted on the same node as the osds.</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>csi.storage.k8s.io/fstype</span>: <span style=color:#ae81ff>ext4</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Delete the rbd volume when a PVC is deleted</span>
</span></span><span style=display:flex><span><span style=color:#f92672>reclaimPolicy</span>: <span style=color:#ae81ff>Delete</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Optional, if you want to add dynamic resize for PVC.</span>
</span></span><span style=display:flex><span><span style=color:#75715e># For now only ext3, ext4, xfs resize support provided, like in Kubernetes itself.</span>
</span></span><span style=display:flex><span><span style=color:#f92672>allowVolumeExpansion</span>: <span style=color:#66d9ef>true</span>
</span></span></code></pre></div><ul><li>创建 StorageClass 资源</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f storageclass-rook-ceph-block.yaml
</span></span></code></pre></div><blockquote><p>注意： <strong>examples/csi/rbd</strong> 目录中有更多的参考用例。</p></blockquote><ul><li>验证资源</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get sc
</span></span><span style=display:flex><span>NAME               PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
</span></span><span style=display:flex><span>local              openebs.io/local                              Delete          WaitForFirstConsumer   false                  76d
</span></span><span style=display:flex><span>nfs-sc <span style=color:#f92672>(</span>default<span style=color:#f92672>)</span>   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate              false                  22d
</span></span><span style=display:flex><span>rook-ceph-block    rook-ceph.rbd.csi.ceph.com                    Delete          Immediate              true                   11s
</span></span></code></pre></div><h2 id=8-创建测试应用>8. 创建测试应用</h2><h3 id=81-使用-rook-提供的测试案例>8.1 使用 Rook 提供的测试案例</h3><p>我们使用 Rook 官方提供的经典的 Wordpress 和 MySQL 应用程序创建一个使用 Rook 提供块存储的示例应用程序，这两个应用程序都使用由 Rook 提供的块存储卷。</p><ul><li>创建 MySQL 和 Wordpress</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f mysql.yaml
</span></span><span style=display:flex><span>kubectl create -f wordpress.yaml
</span></span></code></pre></div><ul><li>查看 PVC 资源</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get pvc
</span></span><span style=display:flex><span>NAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE
</span></span><span style=display:flex><span>mysql-pv-claim   Bound    pvc-938fc531-cff8-452b-b89a-0040ac0aaa02   20Gi       RWO            rook-ceph-block   31s
</span></span><span style=display:flex><span>wp-pv-claim      Bound    pvc-d94118de-7105-4a05-a4e7-ebc5807cc5c1   20Gi       RWO            rook-ceph-block   13s
</span></span></code></pre></div><ul><li>查看 SVC 资源</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get svc
</span></span><span style=display:flex><span>NAME              TYPE           CLUSTER-IP      EXTERNAL-IP   PORT<span style=color:#f92672>(</span>S<span style=color:#f92672>)</span>           AGE
</span></span><span style=display:flex><span>kubernetes        ClusterIP      10.233.0.1      &lt;none&gt;        443/TCP           76d
</span></span><span style=display:flex><span>wordpress         LoadBalancer   10.233.25.187   &lt;pending&gt;     80:31280/TCP      33s
</span></span><span style=display:flex><span>wordpress-mysql   ClusterIP      None            &lt;none&gt;        3306/TCP          50s
</span></span></code></pre></div><ul><li>查看 Pod 资源</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get pod -o wide
</span></span><span style=display:flex><span>NAME                               READY   STATUS    RESTARTS   AGE    IP              NODE            NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>wordpress-6678b8879f-ql6sm         1/1     Running   <span style=color:#ae81ff>0</span>          49s    10.233.73.89    ksp-storage-2   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>wordpress-mysql-5d69d6696b-fwttl   1/1     Running   <span style=color:#ae81ff>0</span>          67s    10.233.64.15    ksp-storage-1   &lt;none&gt;           &lt;none&gt;
</span></span></code></pre></div><h3 id=82-指定节点创建测试应用>8.2 指定节点创建测试应用</h3><p>Wordpress 和 MySQL 测试用例中，pod 创建在了存储专用节点。为了测试集群中其它 Worker 节点是否可以使用 Ceph 存储，我们再做一个测试，在创建 Pod 时指定 <code>nodeSelector</code> 标签，将 Pod 创建在非 rook-ceph 专用节点的 <code>ksp-worker-1</code> 上。</p><ul><li>编写测试 PVC 资源清单，<code>vi test-pvc-rbd.yaml</code></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>PersistentVolumeClaim</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>test-pvc-rbd</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>storageClassName</span>: <span style=color:#ae81ff>rook-ceph-block</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>accessModes</span>:
</span></span><span style=display:flex><span>    - <span style=color:#ae81ff>ReadWriteOnce</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>requests</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>storage</span>: <span style=color:#ae81ff>2Gi</span>
</span></span></code></pre></div><ul><li>创建 PVC</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f test-pvc-rbd.yaml
</span></span></code></pre></div><ul><li>查看 PVC</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get pvc -o wide
</span></span><span style=display:flex><span>NAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE   VOLUMEMODE
</span></span><span style=display:flex><span>mysql-pv-claim   Bound    pvc-00c09bac-cee2-4a0e-9549-56f05b9c6965   20Gi       RWO            rook-ceph-block   77s   Filesystem
</span></span><span style=display:flex><span>test-pvc-rbd     Bound    pvc-ad475b29-6730-4c9a-8f8d-a0cd99b12781   2Gi        RWO            rook-ceph-block   5s    Filesystem
</span></span><span style=display:flex><span>wp-pv-claim      Bound    pvc-b3b2d6bc-6d62-4ac3-a50c-5dcf076d501c   20Gi       RWO            rook-ceph-block   76s   Filesystem
</span></span></code></pre></div><ul><li>编写测试 Pod 资源清单，<code>vi test-pod-rbd.yaml</code></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Pod</span>
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>test-pod-rbd</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>containers</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>test-pod-rbd</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>busybox:stable</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>command</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;/bin/sh&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>args</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;-c&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;touch /mnt/SUCCESS &amp;&amp; sleep 3600&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumeMounts</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>rbd-pvc</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>mountPath</span>: <span style=color:#e6db74>&#34;/mnt&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>restartPolicy</span>: <span style=color:#e6db74>&#34;Never&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>nodeSelector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>kubernetes.io/hostname</span>: <span style=color:#ae81ff>ksp-worker-1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>rbd-pvc</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>persistentVolumeClaim</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>claimName</span>: <span style=color:#ae81ff>test-pvc-rbd</span>
</span></span></code></pre></div><ul><li>创建 Pod</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f test-pod-rbd.yaml
</span></span></code></pre></div><ul><li>查看 Pod（ <strong>Pod 按预期创建在了 ksp-worker-1 节点，并正确运行</strong>）</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get pods -o wide
</span></span><span style=display:flex><span>NAME                               READY   STATUS    RESTARTS   AGE   IP              NODE            NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>test-pod-rbd                       1/1     Running   <span style=color:#ae81ff>0</span>          5s    10.233.94.210   ksp-worker-1    &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>wordpress-6678b8879f-ql6sm         1/1     Running   <span style=color:#ae81ff>0</span>          10m   10.233.73.89    ksp-storage-2   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>wordpress-mysql-5d69d6696b-fwttl   1/1     Running   <span style=color:#ae81ff>0</span>          10m   10.233.64.15    ksp-storage-1   &lt;none&gt;           &lt;none&gt;
</span></span></code></pre></div><ul><li>查看 Pod 挂载的存储</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl exec test-pod-rbd -- df -h
</span></span><span style=display:flex><span>Filesystem                Size      Used Available Use% Mounted on
</span></span><span style=display:flex><span>overlay                  99.9G     14.0G     85.9G  14% /
</span></span><span style=display:flex><span>tmpfs                    64.0M         <span style=color:#ae81ff>0</span>     64.0M   0% /dev
</span></span><span style=display:flex><span>tmpfs                     7.6G         <span style=color:#ae81ff>0</span>      7.6G   0% /sys/fs/cgroup
</span></span><span style=display:flex><span>/dev/rbd0                 1.9G     24.0K      1.9G   0% /mnt
</span></span><span style=display:flex><span>/dev/mapper/openeuler-root
</span></span><span style=display:flex><span>                         34.2G      2.3G     30.1G   7% /etc/hosts
</span></span><span style=display:flex><span>/dev/mapper/openeuler-root
</span></span><span style=display:flex><span>                         34.2G      2.3G     30.1G   7% /dev/termination-log
</span></span><span style=display:flex><span>/dev/mapper/data-lvdata
</span></span><span style=display:flex><span>                         99.9G     14.0G     85.9G  14% /etc/hostname
</span></span><span style=display:flex><span>/dev/mapper/data-lvdata
</span></span><span style=display:flex><span>                         99.9G     14.0G     85.9G  14% /etc/resolv.conf
</span></span><span style=display:flex><span>shm                      64.0M         <span style=color:#ae81ff>0</span>     64.0M   0% /dev/shm
</span></span><span style=display:flex><span>tmpfs                    13.9G     12.0K     13.9G   0% /var/run/secrets/kubernetes.io/serviceaccount
</span></span><span style=display:flex><span>tmpfs                     7.6G         <span style=color:#ae81ff>0</span>      7.6G   0% /proc/acpi
</span></span><span style=display:flex><span>tmpfs                    64.0M         <span style=color:#ae81ff>0</span>     64.0M   0% /proc/kcore
</span></span><span style=display:flex><span>tmpfs                    64.0M         <span style=color:#ae81ff>0</span>     64.0M   0% /proc/keys
</span></span><span style=display:flex><span>tmpfs                    64.0M         <span style=color:#ae81ff>0</span>     64.0M   0% /proc/timer_list
</span></span><span style=display:flex><span>tmpfs                    64.0M         <span style=color:#ae81ff>0</span>     64.0M   0% /proc/sched_debug
</span></span><span style=display:flex><span>tmpfs                     7.6G         <span style=color:#ae81ff>0</span>      7.6G   0% /proc/scsi
</span></span><span style=display:flex><span>tmpfs                     7.6G         <span style=color:#ae81ff>0</span>      7.6G   0% /sys/firmware
</span></span></code></pre></div><ul><li>测试存储空间读写</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 写入 1GB 的数据</span>
</span></span><span style=display:flex><span>$ kubectl exec test-pod-rbd -- dd <span style=color:#66d9ef>if</span><span style=color:#f92672>=</span>/dev/zero of<span style=color:#f92672>=</span>/mnt/test-disk.img bs<span style=color:#f92672>=</span>1M count<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>
</span></span><span style=display:flex><span>1000+0 records in
</span></span><span style=display:flex><span>1000+0 records out
</span></span><span style=display:flex><span><span style=color:#ae81ff>1048576000</span> bytes <span style=color:#f92672>(</span>1000.0MB<span style=color:#f92672>)</span> copied, 4.710019 seconds, 212.3MB/s
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 查看结果</span>
</span></span><span style=display:flex><span>$ kubectl exec test-pod-rbd -- ls -lh /mnt/
</span></span><span style=display:flex><span>total 1000M
</span></span><span style=display:flex><span>-rw-r--r--    <span style=color:#ae81ff>1</span> root     root           <span style=color:#ae81ff>0</span> Aug  <span style=color:#ae81ff>5</span> 20:11 SUCCESS
</span></span><span style=display:flex><span>drwx------    <span style=color:#ae81ff>2</span> root     root       16.0K Aug  <span style=color:#ae81ff>5</span> 20:11 lost+found
</span></span><span style=display:flex><span>-rw-r--r--    <span style=color:#ae81ff>1</span> root     root     1000.0M Aug  <span style=color:#ae81ff>5</span> 20:14 test-disk.img
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 测试超限（再写入 1GB 数据，只能写入 929.8MB）</span>
</span></span><span style=display:flex><span>$ kubectl exec test-pod-rbd -- dd <span style=color:#66d9ef>if</span><span style=color:#f92672>=</span>/dev/zero of<span style=color:#f92672>=</span>/mnt/test-disk2.img bs<span style=color:#f92672>=</span>1M count<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>
</span></span><span style=display:flex><span>dd: error writing <span style=color:#e6db74>&#39;/mnt/test-disk2.img&#39;</span>: No space left on device
</span></span><span style=display:flex><span>930+0 records in
</span></span><span style=display:flex><span>929+0 records out
</span></span><span style=display:flex><span><span style=color:#ae81ff>974987264</span> bytes <span style=color:#f92672>(</span>929.8MB<span style=color:#f92672>)</span> copied, 3.265758 seconds, 284.7MB/s
</span></span><span style=display:flex><span>command terminated with exit code <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 再次查看结果</span>
</span></span><span style=display:flex><span>$ kubectl exec test-pod-rbd -- ls -lh /mnt/
</span></span><span style=display:flex><span>total 2G
</span></span><span style=display:flex><span>-rw-r--r--    <span style=color:#ae81ff>1</span> root     root           <span style=color:#ae81ff>0</span> Aug  <span style=color:#ae81ff>5</span> 20:11 SUCCESS
</span></span><span style=display:flex><span>drwx------    <span style=color:#ae81ff>2</span> root     root       16.0K Aug  <span style=color:#ae81ff>5</span> 20:11 lost+found
</span></span><span style=display:flex><span>-rw-r--r--    <span style=color:#ae81ff>1</span> root     root     1000.0M Aug  <span style=color:#ae81ff>5</span> 20:14 test-disk.img
</span></span><span style=display:flex><span>-rw-r--r--    <span style=color:#ae81ff>1</span> root     root      929.8M Aug  <span style=color:#ae81ff>5</span> 20:18 test-disk2.img
</span></span></code></pre></div><blockquote><p><strong>注意：</strong> 测试时，我们写入了 2G 的数据量，当达过我们创建的 PVC 2G 容量上限时会报错（实际使用写不满 2G）。说明，<strong>Ceph 存储可以做到容量配额限制</strong>。</p></blockquote><h2 id=9-ceph-dashboard>9. Ceph Dashboard</h2><p>Ceph 提供了一个 Dashboard 工具，我们可以在上面查看集群的状态，包括集群整体运行状态、Mgr、Mon、OSD 和其他 Ceph 进程的状态，查看存储池和 PG 状态，以及显示守护进程的日志等。</p><p>部署集群的配置文件 <code>cluster.yaml</code> ，默认已经开启了 Dashboard 功能，Rook Ceph operator 部署集群时将启用 ceph-mgr 的 Dashboard 模块。</p><h3 id=91-获取-dashboard-的-service-地址>9.1 获取 Dashboard 的 service 地址</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl -n rook-ceph get service
</span></span><span style=display:flex><span>NAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span style=color:#f92672>(</span>S<span style=color:#f92672>)</span>             AGE
</span></span><span style=display:flex><span>rook-ceph-exporter        ClusterIP   10.233.4.126    &lt;none&gt;        9926/TCP            46m
</span></span><span style=display:flex><span>rook-ceph-mgr             ClusterIP   10.233.49.41    &lt;none&gt;        9283/TCP            46m
</span></span><span style=display:flex><span>rook-ceph-mgr-dashboard   ClusterIP   10.233.7.182    &lt;none&gt;        8443/TCP            46m
</span></span><span style=display:flex><span>rook-ceph-mon-a           ClusterIP   10.233.45.222   &lt;none&gt;        6789/TCP,3300/TCP   47m
</span></span><span style=display:flex><span>rook-ceph-mon-b           ClusterIP   10.233.52.144   &lt;none&gt;        6789/TCP,3300/TCP   47m
</span></span><span style=display:flex><span>rook-ceph-mon-c           ClusterIP   10.233.57.144   &lt;none&gt;        6789/TCP,3300/TCP   47m
</span></span></code></pre></div><h3 id=92-配置在集群外部访问-dashboard>9.2 配置在集群外部访问 Dashboard</h3><p>通常我们需要在 K8s 集群外部访问 Ceph Dashboard，可以通过 NodePort 或是 Ingress 的方式。</p><p>本文演示 NodePort 方式。</p><ul><li>创建资源清单文件， <code>vi ceph-dashboard-external-https.yaml</code></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Service</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>rook-ceph-mgr-dashboard-external-https</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>rook-ceph</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>app</span>: <span style=color:#ae81ff>rook-ceph-mgr</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>rook_cluster</span>: <span style=color:#ae81ff>rook-ceph</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>dashboard</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>port</span>: <span style=color:#ae81ff>8443</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>protocol</span>: <span style=color:#ae81ff>TCP</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>targetPort</span>: <span style=color:#ae81ff>8443</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>nodePort</span>: <span style=color:#ae81ff>31443</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>selector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>app</span>: <span style=color:#ae81ff>rook-ceph-mgr</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>mgr_role</span>: <span style=color:#ae81ff>active</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>rook_cluster</span>: <span style=color:#ae81ff>rook-ceph</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>type</span>: <span style=color:#ae81ff>NodePort</span>
</span></span></code></pre></div><ul><li>创建资源</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f ceph-dashboard-external-https.yaml
</span></span></code></pre></div><ul><li>验证创建的资源</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl -n rook-ceph get service rook-ceph-mgr-dashboard-external-https
</span></span><span style=display:flex><span>NAME                                     TYPE       CLUSTER-IP     EXTERNAL-IP   PORT<span style=color:#f92672>(</span>S<span style=color:#f92672>)</span>          AGE
</span></span><span style=display:flex><span>rook-ceph-mgr-dashboard-external-https   NodePort   10.233.5.136   &lt;none&gt;        8443:31443/TCP   5s
</span></span></code></pre></div><h3 id=93-获取-login-credentials>9.3 获取 Login Credentials</h3><p>登陆 Dashboard 时需要身份验证，Rook 创建了一个默认用户，用户名 admin。创建了一个名为 <code>rook-ceph-dashboard-password</code> 的 secret 存储密码，使用下面的命令获取随机生成的密码。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;{[&#39;data&#39;][&#39;password&#39;]}&#34;</span> | base64 --decode <span style=color:#f92672>&amp;&amp;</span> echo
</span></span><span style=display:flex><span>6W6#Y3PvI~<span style=color:#f92672>=</span>CVq0f<span style=color:#960050;background-color:#1e0010>&#39;</span>@Yo
</span></span></code></pre></div><h3 id=94-通过浏览器打开-dashboard>9.4 通过浏览器打开 Dashboard</h3><p>访问 K8s 集群中任意节点的 IP，<code>https://192.168.9.91:31443</code>，默认用户名 <code>admin</code>，密码通过上面的命令获取。</p><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//rook-login-v1149.png alt></p><h3 id=95-ceph-dashboard-概览>9.5 Ceph Dashboard 概览</h3><p>Ceph Dashboard 虽然界面简单，但是常用的管理功能都具备，能实现图形化管理存储资源。下面展示几张截图，作为本文的结尾。</p><ul><li>Dashboard</li></ul><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//rook-dashboard-v1149.png alt></p><ul><li>集群-主机</li></ul><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//rook-cluster-hosts-v1149.png alt></p><ul><li>集群-OSD</li></ul><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//rook-cluster-osds-v1149.png alt></p><ul><li>存储池</li></ul><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//rook-pools-v1149.png alt></p><p><strong>免责声明：</strong></p><ul><li>笔者水平有限，尽管经过多次验证和检查，尽力确保内容的准确性，<strong>但仍可能存在疏漏之处</strong>。敬请业界专家大佬不吝指教。</li><li>本文所述内容仅通过实战环境验证测试，读者可学习、借鉴，但<strong>严禁直接用于生产环境</strong>。<strong>由此引发的任何问题，作者概不负责</strong>！</li></ul></div></div><div class=share-2><div class=share><a href="https://twitter.com/intent/tweet?url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-rook-ceph%2f&text=Kubernetes%20%e6%8c%81%e4%b9%85%e5%8c%96%e5%ad%98%e5%82%a8%e4%b9%8b%20Rook%20Ceph%20%e6%8e%a2%e7%a9%b6" target=_blank rel="noopener noreferrer"><img src=/images/share/Twitter.svg alt="twitter icon">
</a><a href="https://reddit.com/submit?url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-rook-ceph%2f&title=Kubernetes%20%e6%8c%81%e4%b9%85%e5%8c%96%e5%ad%98%e5%82%a8%e4%b9%8b%20Rook%20Ceph%20%e6%8e%a2%e7%a9%b6" target=_blank rel="noopener noreferrer"><img src=/images/share/Reddit.svg alt="reddit icon">
</a><a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-rook-ceph%2f" target=_blank rel="noopener noreferrer"><img src=/images/share/Facebook.svg alt="facebook icon">
</a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-rook-ceph%2f" target=_blank rel="noopener noreferrer"><img src=/images/share/Linkedin.svg alt="linkedin icon">
</a><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-rook-ceph%2f&t=Kubernetes%20%e6%8c%81%e4%b9%85%e5%8c%96%e5%ad%98%e5%82%a8%e4%b9%8b%20Rook%20Ceph%20%e6%8e%a2%e7%a9%b6" target=_blank rel="noopener noreferrer"><img src=/images/share/HackerNews.svg alt="hackernews icon"></a></div></div></div><div class=aside><div class=inner-div><div class=title>目录</div><div class=tabs><nav id=TableOfContents><ul><li><a href=#1-rook-部署规划>1. Rook 部署规划</a></li><li><a href=#2-前置条件>2. 前置条件</a><ul><li><a href=#21--kubernetes-版本>2.1 Kubernetes 版本</a></li><li><a href=#22-cpu-architecture>2.2 CPU Architecture</a></li><li><a href=#23-ceph-先决条件>2.3 Ceph 先决条件</a></li><li><a href=#24-lvm-需求>2.4 LVM 需求</a></li><li><a href=#25-kernel-需求>2.5 Kernel 需求</a></li></ul></li><li><a href=#3-扩容集群节点>3. 扩容集群节点</a><ul><li><a href=#31-扩容存储专用-worker-节点>3.1 扩容存储专用 Worker 节点</a></li><li><a href=#32-设置节点标签>3.2 设置节点标签</a></li></ul></li><li><a href=#4-安装配置-rook-ceph-operator>4. 安装配置 Rook Ceph Operator</a><ul><li><a href=#41-下载部署代码>4.1 下载部署代码</a></li><li><a href=#42-修改镜像地址>4.2 修改镜像地址</a></li><li><a href=#43-修改自定义配置>4.3 修改自定义配置</a></li><li><a href=#44-部署-rook-operator>4.4 部署 Rook Operator</a></li><li><a href=#45-kubesphere-控制台查看-operator-资源>4.5 KubeSphere 控制台查看 Operator 资源</a></li></ul></li><li><a href=#5-创建-ceph-集群>5. 创建 Ceph 集群</a><ul><li><a href=#51--修改集群配置文件>5.1 修改集群配置文件</a></li><li><a href=#52-创建-ceph-集群>5.2 创建 Ceph 集群</a></li><li><a href=#53-kubesphere-控制台查看-ceph-集群资源>5.3 KubeSphere 控制台查看 Ceph 集群资源</a></li></ul></li><li><a href=#6-创建-rook-toolbox>6. 创建 Rook toolbox</a><ul><li><a href=#61-创建-toolbox>6.1 创建 toolbox</a></li><li><a href=#62-常用命令>6.2 常用命令</a></li></ul></li><li><a href=#7-block-storage>7. Block Storage</a><ul><li><a href=#71-storage-介绍>7.1 Storage 介绍</a></li><li><a href=#72-创建存储池>7.2 创建存储池</a></li><li><a href=#73-创建-storageclass>7.3 创建 StorageClass</a></li></ul></li><li><a href=#8-创建测试应用>8. 创建测试应用</a><ul><li><a href=#81-使用-rook-提供的测试案例>8.1 使用 Rook 提供的测试案例</a></li><li><a href=#82-指定节点创建测试应用>8.2 指定节点创建测试应用</a></li></ul></li><li><a href=#9-ceph-dashboard>9. Ceph Dashboard</a><ul><li><a href=#91-获取-dashboard-的-service-地址>9.1 获取 Dashboard 的 service 地址</a></li><li><a href=#92-配置在集群外部访问-dashboard>9.2 配置在集群外部访问 Dashboard</a></li><li><a href=#93-获取-login-credentials>9.3 获取 Login Credentials</a></li><li><a href=#94-通过浏览器打开-dashboard>9.4 通过浏览器打开 Dashboard</a></li><li><a href=#95-ceph-dashboard-概览>9.5 Ceph Dashboard 概览</a></li></ul></li></ul></nav></div></div></div></div></section><div class=SubscribeForm><div class=innerBox><img class=close src=/images/home/close.svg alt=close><p class=description>通过邮件接收 KubeSphere 最新的技术博客与产品更新的通知</p><div id=blog_formAddress data-actionaddress="https://www.sendcloud.net/v3/api/subInvite/subscription?invitecode=1dc5a4fb-894c-4470-b01d-ca7fa9d47a46" data-usesendcloud=true data-lang=zh><input name=EMAIL id=email-input-blog type=text placeholder>
<button id=email-submit-blog>订阅</button>
<span id=message_blog data-message1=请提供您的邮箱 data-message2=请输入有效的邮箱地址! data-message3=邮箱地址已经存在 style=color:red></span><span id=message1_blog style=color:#00a971 data-success=订阅成功啦，我们保证不会给你发垃圾邮件的啦></span></div></div></div><footer><div class=footer><div class="footer-main common-layout"><div class=up-main><div class=left-div><img src=/images/logo.svg alt class=foot-logo><p>通过邮件接收 KubeSphere 最新的技术博客与产品更新的通知</p><div id=formAddress data-actionaddress="https://www.sendcloud.net/v3/api/subInvite/subscription?invitecode=1dc5a4fb-894c-4470-b01d-ca7fa9d47a46" data-usesendcloud=true data-lang=zh><input name=EMAIL id=email-input type=text placeholder=请输入您的邮箱地址>
<button id=email-submit>订阅</button></div><span id=message data-message1=请提供您的邮箱 data-message2=请输入有效的邮箱地址! data-message3=邮箱地址已经存在></span><span id=message1 style=color:#00a971 data-success=订阅成功啦，我们保证不会给你发垃圾邮件的啦></span><script>var bindSubmit=function(){var e=$("#email-input");$("#email-submit").click(function(t){t.stopPropagation();var s,o,n=e.val(),i=$("#message").data("message1"),a=$("#message").data("message2"),r=$("#message").data("message3"),c=$("#message1").data("success");if(n)if(validateEmail(n)){if(s=$("#formAddress").data("usesendcloud"),!s)return;o=$("#formAddress").data("actionaddress"),$.post({type:"post",url:o,data:{email:$("#email-input").val().toString()},success:function(){showSuccessMessage(c),setTimeout(function(){$("#email-input").val("")},1e3)},error:function(){showMessage(r)}})}else t.preventDefault(),showMessage(a);else t.preventDefault(),showMessage(i)})},validateEmail=function(e){var t=/^[A-Za-z0-9]+([_.][A-Za-z0-9]+)*@([A-Za-z0-9-]+\.)+[A-Za-z]{2,6}$/;return t.test(e)},showMessage=function(e){$("#message").html(e).show()},showSuccessMessage=function(e){$("#message1").html(e).show()},bindHideMessage=function(){$(window).click(function(){$("#message").hide(),$("#message1").hide()})},bindClose=function(){$(".formBox .close").click(function(e){e.stopPropagation(),$(".formBox").fadeOut()})};bindSubmit(),bindClose(),bindHideMessage()</script><span id=message data-message1=请提供您的邮箱 data-message2=请输入有效的邮箱地址!></span></div><div class=right-div><ul class=common-flex-layout><li class=nowrap-li><div class=h3>应用场景</div><a href=/zh/devops/>拥抱一站式 DevOps</a>
<a href=/zh/service-mesh/>在 K8s 运行微服务</a>
<a href=/zh/observability/>构建云原生可观测性</a>
<a href=https://github.com/kubesphere/kubekey target=_blank rel="noopener noreferrer">K8s 一键部署与运维</a>
<a href=https://github.com/OpenFunction/OpenFunction target=_blank rel="noopener noreferrer">构建 FaaS 平台与 Serverless 架构</a>
<a href=https://github.com/openpitrix/openpitrix target=_blank rel="noopener noreferrer">多云应用管理平台</a></li><li class=nowrap-li><div class=h3>资源</div><a href=/zh/projects/>开源项目</a>
<a href=/zh/blogs/>技术博客</a>
<a href=/zh/conferences/>开源峰会</a>
<a href=/zh/videos/>视频资源</a>
<a href=/zh/learn/>云原生实战</a></li><li class=nowrap-li><div class=h3>文档中心</div><a href=/zh/docs/v4.1/01-intro/01-introduction/>产品介绍</a>
<a href=/zh/docs/v4.1/03-installation-and-upgrade/02-install-kubesphere/02-install-kubernetes-and-kubesphere/>如何安装</a>
<a href=/zh/docs/v4.1/02-quickstart/>快速入门</a>
<a href=/zh/docs/v3.4/reference/api-docs/>API 文档</a></li><li class=nowrap-li><div class=h3>开源社区</div><a href=/zh/contribution/>参与贡献</a>
<a href=/zh/live/>社区活动</a>
<a href=/zh/case/>案例学习</a>
<a href=/zh/partner/>合作伙伴</a>
<a href=/zh/user-group/>用户委员会</a>
<a href=https://github.com/kubesphere/kubesphere/blob/master/docs/roadmap.md target=_blank rel="noopener noreferrer">版本计划</a>
<a href=https://kubesphere.com.cn/ target=_blank rel="noopener noreferrer">中国站</a>
<a href=https://ask.kubesphere.io/forum target=_blank rel="noopener noreferrer">中文论坛</a>
<a href=https://kubesphere.io target=_blank rel="noopener noreferrer">全球站</a></li><li class=nowrap-li><div class=h3>产品与服务</div><a href=https://aws.amazon.com/cn/quickstart/architecture/qingcloud-kubesphere/ target=_blank rel="noopener noreferrer">KubeSphere on AWS</a>
<a href=https://market.azure.cn/marketplace/apps/qingcloud.kubesphere target=_blank rel="noopener noreferrer">KubeSphere on Azure</a>
<a href=https://marketplace.digitalocean.com/apps/kubesphere target=_blank rel="noopener noreferrer">KubeSphere on DigitalOcean</a>
<a href=https://www.qingcloud.com/products/kubesphereqke target=_blank rel="noopener noreferrer">KubeSphere on QingCloud(QKE)</a>
<a href=https://kubesphere.com.cn/kse/ target=_blank rel="noopener noreferrer">KubeSphere 企业版</a>
<a href=https://kubesphere.cloud/ksv/ target=_blank rel="noopener noreferrer">KubeSphere 虚拟化平台</a>
<a href=https://kubesphere.com.cn/marketplace/ target=_blank rel="noopener noreferrer">云原生扩展组件市场</a>
<a href=https://kubesphere.cloud target=_blank rel="noopener noreferrer">云原生应用服务平台</a>
<a href=https://m.qingcloud.com/p/aec50 target=_blank rel="noopener noreferrer">了解商业产品与咨询合作</a></li></ul></div></div><div class=down-main><div class=img-div><a class=wechat href=javascript:void(0); aria-label=wechat><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28" height="28" viewBox="0 0 28 28"><defs><path id="a" d="M0 0h15.673v12.156H0z"/></defs><g fill="none" fill-rule="evenodd" transform="translate(1 1)"><circle cx="13" cy="13" r="13" stroke="#B6C2CD"/><g transform="translate(5 7)"><mask id="b" fill="#fff"><use xlink:href="#a"/></mask><path fill="currentColor" d="M15.673 7.898c0-2.061-2.173-3.74-4.619-3.74-2.59.0-4.625 1.679-4.625 3.74.0 2.066 2.035 3.738 4.625 3.738.542.0 1.09-.13 1.632-.256l1.493.776-.408-1.29c1.09-.776 1.902-1.81 1.902-2.968zm-6.119-.645c-.27.0-.541-.257-.541-.514.0-.256.27-.514.541-.514.41.0.681.258.681.514.0.257-.271.514-.681.514zm2.994.0c-.27.0-.541-.257-.541-.514.0-.256.27-.514.54-.514.41.0.681.258.681.514.0.257-.277.514-.68.514z" mask="url(#b)"/><path fill="currentColor" d="M10.602 3.674c.177.0.356.011.533.029C10.657 1.576 8.27.0 5.543.0 2.498.0.0 1.974.0 4.485c0 1.45.829 2.64 2.216 3.564l-.552 1.588 1.94-.929c.693.129 1.251.263 1.94.263.17.0.343-.005.515-.022a3.68 3.68.0 01-.172-1.104c0-2.302 2.081-4.171 4.715-4.171zM7.618 2.243c.417.0.693.263.693.66s-.276.66-.693.66c-.418.0-.835-.263-.835-.66.006-.398.423-.66.835-.66zm-3.88 1.319c-.417.0-.834-.263-.834-.66s.417-.66.834-.66c.418.0.695.263.695.66.0.392-.277.66-.695.66z" mask="url(#b)"/></g></g></svg><div class=hide-div><img src=/images/home/wechat.svg alt></div></a><a class=facebook-a href=https://www.facebook.com/kubesphere target=_blank aria-label=facebook></a><a class=twitter-a href=https://x.com/KubeSphere target=_blank aria-label=twitter rel="noopener noreferrer"></a><a class=linkedin-a href=https://www.linkedin.com/company/kubesphere/ target=_blank aria-label=linkedin rel="noopener noreferrer"></a><a class=bilibili-a href=https://space.bilibili.com/438908638 target=_blank aria-label=bilibili rel="noopener noreferrer"></a><a class=slack-a href=https://join.slack.com/t/kubesphere/shared_invite/zt-2b4t6rdb4-ico_4UJzCln_S2c1pcrIpQ target=_blank aria-label=slack rel="noopener noreferrer"></a><a class=github-a href=https://github.com/kubesphere/kubesphere target=_blank aria-label=github rel="noopener noreferrer"></a><a class=medium-a href=https://itnext.io/@kubesphere target=_blank aria-label=medium rel="noopener noreferrer"></a></div><p class=p1></p><p class=case><a href=http://www.beian.miit.gov.cn/ target=_blank rel="noopener noreferrer"><span>京ICP备13019086号</span>
</a><a target=_blank rel="noopener noreferrer" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010502041003"><img src=/images/footer/case-icon.png alt=备案图标>
<span>京公网安备 11010502041003号</span></a></p></div></div></div><div class=cookie><div class=common-layout><p>您的隐私对我们很重要。我们使用Cookie来记住订阅详细信息，优化网站功能并交付根据您的兴趣量身定制的内容。要了解更多信息，请参阅我们的<a href=/zh/privacy>隐私政策</a>.</p><button>
接受并继续</button></div></div></footer><script>var lazyLoad=function(e,t){for(var n,o,i,s=0;s<t;s++){if(n=e.eq(s),o=n.attr("data-loaded"),o)continue;n.offset().top<parseInt($(window).height())+parseInt($(window).scrollTop())&&(i=n.attr("src"),n.attr("src",i),n.attr("data-loaded",!0))}},bindLayLoad=function(){var e=$("img"),t=e.length;lazyLoad(e,t),$(window).scroll(function(){lazyLoad(e,t)})},bindAddPadding=function(){var e=$("#close-join");e.length>0&&$(".main-section").addClass("padding")},docCookies={getItem:function(e){return decodeURIComponent(document.cookie.replace(new RegExp("(?:(?:^|.*;)\\s*"+encodeURIComponent(e).replace(/[-.+*]/g,"\\$&")+"\\s*\\=\\s*([^;]*).*$)|^.*$"),"$1"))||null},setItem:function(e,t){return!!e&&!/^(?:expires|max-age|path|domain|secure)$/i.test(e)&&(document.cookie=encodeURIComponent(e)+"="+encodeURIComponent(t),!0)}},bindHideCookie=function(){var t=docCookies.getItem("hasAuth"),e=$(".cookie");t?e.hide():e.show(),e.find("button").on("click",function(){docCookies.setItem("hasAuth","1"),e.hide()})};bindAddPadding(),bindHideCookie()</script><script type=text/javascript src=/js/aside.2d6977c0f16aef4ed3e886dd66675ce74bd0efcd467c2b2bcdb30b92d5e7c7c0e5c6e0c9d8f09a883c22f58df9e6b0b6347fcdd3c9a920b7faba6d7f91a201c3.js integrity="sha512-LWl3wPFq707T6IbdZmdc50vQ781GfCsrzbMLktXnx8DlxuDJ2PCaiDwi9Y355rC2NH/N08mpILf6um1/kaIBww=="></script><script type=text/javascript src=/js/markdown-tab.17f9f46b021adebc7250ce1b07134a577b307e7a436daa4aaf388f218e8463966f53770b26a64817c06c168738a887672d47fb4c29615adfc446e11d09a344cf.js integrity="sha512-F/n0awIa3rxyUM4bBxNKV3swfnpDbapKrziPIY6EY5ZvU3cLJqZIF8BsFoc4qIdnLUf7TClhWt/ERuEdCaNEzw=="></script><script>let forbidForm=!1;var viewer=new Viewer(document.querySelector(".md-body"),{url:"src"}),blogBindSubmit=function(){var e=$("#email-input-blog");$("#email-submit-blog").click(function(t){t.stopPropagation();var s,o,n=e.val(),i=$("#message_blog").data("message1"),a=$("#message_blog").data("message2"),r=$("#message_blog").data("message3"),c=$("#message1_blog").data("success");if(n)if(validateEmail(n)){if(s=$("#blog_formAddress").data("usesendcloud"),!s)return;o=$("#blog_formAddress").data("actionaddress"),$.post({type:"post",url:o,data:{email:n.toString()},success:function(){showSuccessMessage_blog(c),setTimeout(function(){window.onscroll="",$(".SubscribeForm").hide(),$("#email-input-blog").val("")},5e3)},error:function(){showMessage_blog(r)}})}else t.preventDefault(),$("#message_blog").html(a).show();else t.preventDefault(),$("#message_blog").html(i).show()})},validateEmail=function(e){var t=/^[A-Za-z0-9]+([_.][A-Za-z0-9]+)*@([A-Za-z0-9-]+\.)+[A-Za-z]{2,6}$/;return t.test(e)},bindHideMessageBlog=function(){$(window).click(function(){$("#message_blog").hide()})},bindCloseBlog=function(){$(".SubscribeForm .close").click(function(e){e.stopPropagation(),$(".SubscribeForm").fadeOut(),window.onscroll=""})},showMessage_blog=function(e){$("#message_blog").html(e).show()},showSuccessMessage_blog=function(e){$("#message1_blog").html(e).show()};window.onscroll=()=>{var e=document.documentElement.scrollTop||document.body.scrollTop,t=document.documentElement.clientHeight||document.body.clientHeight,n=document.documentElement.scrollHeight||document.body.scrollHeight;forbidForm&&(window.onscroll=""),e+t>n-710?$(".SubscribeForm").hide():$(".SubscribeForm").show()},blogBindSubmit(),bindCloseBlog(),bindHideMessageBlog()</script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script></body></html>