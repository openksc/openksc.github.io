<!doctype html><html lang=en-US><head><meta charset=utf-8><title>在 KubeSphere 上部署 AI 大模型 Ollama</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="通过阅读本文，您将获得 Kubernetes 上 管理 GPU 资源的知识和技巧，帮助您在云原生环境中，充分利用 GPU 资源，推动 AI 应用的快速发展。"><meta name=keywords content="Kubernetes,KubeSphere,AI,Ollama"><meta property="og:type" content="article"><meta property="og:title" content="在 KubeSphere 上部署 AI 大模型 Ollama"><meta property="og:description" content="通过阅读本文，您将获得 Kubernetes 上 管理 GPU 资源的知识和技巧，帮助您在云原生环境中，充分利用 GPU 资源，推动 AI 应用的快速发展。"><meta property="og:image" content="https://pek3b.qingstor.com/kubesphere-community/images/ollama-on-kubesphere-cover.png"><meta property="og:url" content="https://openksc.github.io/zh/blogs/deploy-ollama-on-kubesphere/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@KubeSphere"><meta property="twitter:image" content="https://pek3b.qingstor.com/kubesphere-community/images/ollama-on-kubesphere-cover.png"><meta name=docsearch:language content="zh-CN"><meta name=docsearch:version content><link rel=canonical href=https://kubesphere.io/zh/blogs/deploy-ollama-on-kubesphere/><link rel="shortcut icon" href=/images/favicons/favicon.ico><link rel=apple-touch-icon href=/images/favicons/apple-touch-icon.png sizes=180x180><link rel=icon type=image/png href=/images/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/images/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/svg+xml href=/images/favicons/favicon.svg><link rel=icon type=image/png href=/images/favicons/favicon.png><link rel=manifest href=/images/favicons/site.webmanifest><link rel=mask-icon href=/images/favicons/safari-pinned-tab.svg color=#00ad6e><meta name=msapplication-config content='/images/favicons/browserconfig.xml'><meta name=msapplication-TileColor content="#ffffff"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=/fonts/Roboto/stylesheet.css><link rel=stylesheet href=/fonts/ProximaNova/stylesheet.css><link rel=stylesheet href=/css/jquery.modal.min.css><link rel=stylesheet href=/css/viewer.min.css><link rel=stylesheet href=/swiper/swiper-bundle.min.css><link rel=stylesheet href=/scss/common.min.0c3fdcc05ec210321169846714f74b11c4a1baf09a1833fa9273b2347c81e636.css><script src=/js/jquery-3.7.1.min.js></script><script src=/js/viewer.min.js></script><script src=/js/jquery.modal.min.js></script><script src=/swiper/swiper-bundle.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?0888981f1fa45d241b1fb6962da2963e",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-YYCVN36HT5"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YYCVN36HT5")</script><script type=text/javascript>!function(e,t,n,s,o){e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},n=t.createElement("script"),tag=t.getElementsByTagName("script")[0],n.async=1,n.src=("https:"==document.location.protocol?"https://":"http://")+s,tag.parentNode.insertBefore(n,tag)}(window,document,"script","assets.giocdn.com/2.1/gio.js","gio"),gio("init","8a24ae300cbf8b8c",{}),gio("send")</script><link rel=stylesheet href=/scss/content.min.f73b326fbf8c5bd331900b0de21c7dde608a4926f482f6465f9ae1d9049b83ad.css><link rel=stylesheet href=/scss/markdown.min.db47186481122431dffae72d17dbbd51f90b66f022cc163458645709924e4eac.css></head><body><header class=navigation><div class=join-div><div class=content>🚀 KubeSphere v4.1.3 发布，多项优化与改进，欢迎体验！<a href=/zh/docs/v4.1/20-release-notes/release-v413/ target=_blank rel="noopener noreferrer">请查看 Release notes →</a>
<img id=close-join src=/images/header/close.svg alt=close></div></div><div class=common-layout><div class=header-container><a href=/zh/ aria-label=logo><img src=/images/header/logo.svg alt class=logo></a><ul class=nav><li class=menu-li><span class=menu-span>应用场景</span><ul class="dropdown-menu menu-2"><li><a href=/zh/devops/>拥抱一站式 DevOps 工作流</a></li><li><a href=/zh/service-mesh/>在 Kubernetes 运行微服务</a></li><li><a href=/zh/observability/>构建丰富的云原生可观测性</a></li></ul></li><li class=menu-li><span class=menu-span>资源</span><ul class="dropdown-menu menu-3"><li><a href=/zh/projects/>开源项目</a></li><li><a href=/zh/conferences/>开源峰会</a></li><li><a href=/zh/blogs/>技术博客</a></li><li><a href=/zh/videos/>视频资源</a></li><li><a href=/zh/learn/>云原生实战</a></li></ul></li><li class=menu-li><span class=menu-span>文档中心</span><ul class="dropdown-menu menu-4"><li><a href=/zh/docs/v4.1>v4.1 <img src=/images/header/star.svg alt=star></a></li><li><a href=/zh/docs/v3.4>v3.4</a></li><li><a href=/zh/docs/v3.3>v3.3</a></li><li><a href=https://dev-guide.kubesphere.io/extension-dev-guide/zh/ target=_blank rel="noopener noreferrer">扩展组件开发</a></li><li><a href=https://kube.design/ target=_blank rel="noopener noreferrer">Kube Design</a></li></ul></li><li class=menu-li><span class=menu-span>开源社区</span><ul class="dropdown-menu menu-5"><li><a href=/zh/contribution/>参与贡献</a></li><li><a href=/zh/live/>社区活动</a></li><li><a href=/zh/case/>案例学习</a></li><li><a href=/zh/partner/>合作伙伴</a></li><li><a href=/zh/user-group/>用户委员会</a></li><li><a href=/zh/news/>动态</a></li><li><a href=https://github.com/kubesphere/kubesphere/blob/master/docs/roadmap.md target=_blank rel="noopener noreferrer">版本计划</a></li><li><a href=https://www.kubesphere.io/zh/ target=_blank rel="noopener noreferrer">中国站</a></li><li><a href=https://github.com/kubesphere/community/tree/master/sig-advocacy-and-outreach/ospp-2025 target=_blank rel="noopener noreferrer">开源之夏 2025</a></li></ul></li><li><a data-docs=用户论坛 href=https://ask.kubesphere.io/forum target=_blank rel="noopener noreferrer">用户论坛</a></li><li><a data-docs=认证 href=https://kubesphere.cloud/certification/ target=_blank rel="noopener noreferrer">认证</a></li></ul><div class=right-menu><ul><li class=language-menu><div><img src=/images/header/black.svg alt>
<span>简体中文</span></div><ul class=dropdown-menu><li onclick='handleLangClick("zh","/zh/blogs/deploy-ollama-on-kubesphere/")'>简体中文</li></ul></li><li class=github-li><div class=github-star><a class=star-btn href=https://github.com/kubesphere/kubesphere rel="noopener noreferrer" target=_blank><span class=star-img></span>&nbsp;<span>Star</span>
</a><a class=social-count href=https://github.com/kubesphere/kubesphere/stargazers rel="noopener noreferrer" target=_blank></a></div></li><li class=menu-icon><img src=/images/header/menu.svg alt></li></ul></div></div></div><div id=modal-for-menu class=modal><ul class=nav><li data-check=0 class=menu-li><span class=menu-span>应用场景</span><ul class=dropdown-menu><li><a href=/zh/devops/>拥抱一站式 DevOps 工作流</a></li><li><a href=/zh/service-mesh/>在 Kubernetes 运行微服务</a></li><li><a href=/zh/observability/>构建丰富的云原生可观测性</a></li></ul></li><li data-check=0 class=menu-li><span class=menu-span>资源</span><ul class=dropdown-menu><li><a href=/zh/projects/>开源项目</a></li><li><a href=/zh/conferences/>开源峰会</a></li><li><a href=/zh/blogs/>技术博客</a></li><li><a href=/zh/videos/>视频资源</a></li><li><a href=/zh/learn/>云原生实战</a></li></ul></li><li data-check=0 class=menu-li><span class=menu-span>文档中心</span><ul class=dropdown-menu><li><a href=/zh/docs/v4.1>v4.1 <img src=/images/header/star.svg alt=star></a></li><li><a href=/zh/docs/v3.4>v3.4</a></li><li><a href=/zh/docs/v3.3>v3.3</a></li><li><a href=https://dev-guide.kubesphere.io/extension-dev-guide/zh/>扩展组件开发</a></li><li><a href=https://kube.design/>Kube Design</a></li></ul></li><li data-check=0 class=menu-li><span class=menu-span>开源社区</span><ul class=dropdown-menu><li><a href=/zh/contribution/>参与贡献</a></li><li><a href=/zh/live/>社区活动</a></li><li><a href=/zh/case/>案例学习</a></li><li><a href=/zh/partner/>合作伙伴</a></li><li><a href=/zh/user-group/>用户委员会</a></li><li><a href=/zh/news/>动态</a></li><li><a href=https://github.com/kubesphere/kubesphere/blob/master/docs/roadmap.md>版本计划</a></li><li><a href=https://www.kubesphere.io/zh/>中国站</a></li><li><a href=https://github.com/kubesphere/community/tree/master/sig-advocacy-and-outreach/ospp-2025>开源之夏 2025</a></li></ul></li><li><a data-docs=用户论坛 href=https://ask.kubesphere.io/forum>用户论坛</a></li><li><a data-docs=认证 href=https://kubesphere.cloud/certification/>认证</a></li></ul><div class=link-div><a href=https://join.slack.com/t/kubesphere/shared_invite/zt-2b4t6rdb4-ico_4UJzCln_S2c1pcrIpQ target=_blank rel="noopener noreferrer" aria-label=slack><img src=/images/header/slack-hover.svg alt>
</a><a href=https://x.com/KubeSphere target=_blank rel="noopener noreferrer" aria-label=twitter><img src=/images/header/twitter-hover.svg alt>
</a><a href=https://github.com/kubesphere/kubesphere target=_blank rel="noopener noreferrer" aria-label=github><img src=/images/header/github-hover.svg alt></a></div></div></header><script>var bindNavMouseEvent,bindScrollChangeHeader,bindClickShowMenu,bindClickModalLi,bindClickClose,language,handleLangClick,githubApiLink="https://api.github.com/repos/kubesphere/kubesphere",getStar=function(){$(".social-count").hide(),$.getJSON(githubApiLink,function(e){$(".social-count").show().html(e.stargazers_count)})};getStar(),bindNavMouseEvent=function(e,t){t||(t=$(e));var n=!1;t.mouseenter(function(){if(n)return!1;n=!0,$(this).find(".dropdown-menu").fadeIn(200,function(){n=!1})}),t.mouseleave(function(){$(this).find(".dropdown-menu").fadeOut(200)})},bindScrollChangeHeader=function(){var t=100,e=$("header");window.addEventListener("scroll",function(){var t=window.scrollY;t>0?e.addClass("navigationScroll"):e.removeClass("navigationScroll")})},bindClickShowMenu=function(){$(".menu-icon").click(function(){$("#modal-for-menu").modal()})},bindClickModalLi=function(){$(".modal .menu-li").click(function(){var e=$(this).data("check");e===0?($(this).data("check",1),$(this).find(".dropdown-menu").slideDown(200)):($(this).data("check",0),$(this).find(".dropdown-menu").slideUp(200)),$(this).find(".menu-span").toggleClass("up")})},bindClickClose=function(){$("#close-join").click(function(){$(".navigation .join-div").hide(),$(".main-section").removeClass("padding")})},language="zh",bindClickClose(),bindScrollChangeHeader(),$(".header-container .menu-li").each(function(){bindNavMouseEvent("",$(this))}),bindNavMouseEvent(".header-container .language-menu"),bindNavMouseEvent(".header-container .btn-li"),bindClickShowMenu(),bindClickModalLi(),handleLangClick=function(e,t){try{localStorage.setItem("lang",e)}catch{}location.href=t}</script><section class=main-section><div class=common-layout><div class=breadcrumb><span><a href=/zh/blogs/>技术博客</a> > </span><span>在 KubeSphere 上部署 AI 大模型 Ollama</span></div><div class='main-div middle-div'><div class=author>运维有术</div><span class=date>发布于：2024-07-09</span>&nbsp;&nbsp;&nbsp;
<span style=font-size:14px;color:#919aa3 id=busuanzi_container_page_pv>本文总阅读量：<span id=busuanzi_value_page_pv></span></span><h1>在 KubeSphere 上部署 AI 大模型 Ollama</h1><div class=share-1><div class=share><a href="https://twitter.com/intent/tweet?url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fdeploy-ollama-on-kubesphere%2f&text=%e5%9c%a8%20KubeSphere%20%e4%b8%8a%e9%83%a8%e7%bd%b2%20AI%20%e5%a4%a7%e6%a8%a1%e5%9e%8b%20Ollama" target=_blank rel="noopener noreferrer"><img src=/images/share/Twitter.svg alt="twitter icon">
</a><a href="https://reddit.com/submit?url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fdeploy-ollama-on-kubesphere%2f&title=%e5%9c%a8%20KubeSphere%20%e4%b8%8a%e9%83%a8%e7%bd%b2%20AI%20%e5%a4%a7%e6%a8%a1%e5%9e%8b%20Ollama" target=_blank rel="noopener noreferrer"><img src=/images/share/Reddit.svg alt="reddit icon">
</a><a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fdeploy-ollama-on-kubesphere%2f" target=_blank rel="noopener noreferrer"><img src=/images/share/Facebook.svg alt="facebook icon">
</a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fdeploy-ollama-on-kubesphere%2f" target=_blank rel="noopener noreferrer"><img src=/images/share/Linkedin.svg alt="linkedin icon">
</a><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fdeploy-ollama-on-kubesphere%2f&t=%e5%9c%a8%20KubeSphere%20%e4%b8%8a%e9%83%a8%e7%bd%b2%20AI%20%e5%a4%a7%e6%a8%a1%e5%9e%8b%20Ollama" target=_blank rel="noopener noreferrer"><img src=/images/share/HackerNews.svg alt="hackernews icon"></a></div></div><div class=content><div class=md-body><p>随着人工智能、机器学习、AI 大模型技术的迅猛发展，我们对计算资源的需求也在不断攀升。特别是对于需要处理大规模数据和复杂算法的 AI 大模型，GPU 资源的使用变得至关重要。对于运维工程师而言，掌握如何在 Kubernetes 集群上管理和配置 GPU 资源，以及如何高效部署依赖这些资源的应用，已成为一项不可或缺的技能。</p><p>今天，我将带领大家深入了解如何在 KubeSphere 平台上，利用 Kubernetes 强大的生态和工具，实现 GPU 资源的管理和应用部署。以下是本文将要探讨的三个核心主题：</p><ol><li><strong>集群扩容与 GPU 节点集成</strong>：我们将通过 KubeKey 工具，扩展 Kubernetes 集群并增加具备 GPU 能力的 Worker 节点，为 AI 应用提供必要的硬件支持。</li><li><strong>GPU 资源的 Kubernetes 集成</strong>：使用 Helm 安装和配置 NVIDIA GPU Operator，这是 NVIDIA 官方提供的一个解决方案，旨在简化 Kubernetes 集群中 GPU 资源的调用和管理。</li><li><strong>实战部署：Ollama 大模型管理工具</strong>：我们将在 KubeSphere 上部署 Ollama，一个专为 AI 大模型设计的管理工具，以验证 GPU 资源是否能够被正确调度和高效使用。</li></ol><p>通过阅读本文，您将获得 Kubernetes 上 管理 GPU 资源的知识和技巧，帮助您在云原生环境中，充分利用 GPU 资源，推动 AI 应用的快速发展。</p><p><strong>KubeSphere 最佳实战「2024」</strong> 系列文档的实验环境硬件配置和软件信息如下：</p><p><strong>实战服务器配置(架构1:1复刻小规模生产环境，配置略有不同)</strong></p><table><thead><tr><th style=text-align:center>主机名</th><th style=text-align:center>IP</th><th style=text-align:center>CPU</th><th style=text-align:center>内存</th><th style=text-align:center>系统盘</th><th style=text-align:center>数据盘</th><th style=text-align:center>用途</th></tr></thead><tbody><tr><td style=text-align:center>ksp-registry</td><td style=text-align:center>192.168.9.90</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>200</td><td style=text-align:center>Harbor 镜像仓库</td></tr><tr><td style=text-align:center>ksp-control-1</td><td style=text-align:center>192.168.9.91</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>KubeSphere/k8s-control-plane</td></tr><tr><td style=text-align:center>ksp-control-2</td><td style=text-align:center>192.168.9.92</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>KubeSphere/k8s-control-plane</td></tr><tr><td style=text-align:center>ksp-control-3</td><td style=text-align:center>192.168.9.93</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>KubeSphere/k8s-control-plane</td></tr><tr><td style=text-align:center>ksp-worker-1</td><td style=text-align:center>192.168.9.94</td><td style=text-align:center>4</td><td style=text-align:center>16</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>k8s-worker/CI</td></tr><tr><td style=text-align:center>ksp-worker-2</td><td style=text-align:center>192.168.9.95</td><td style=text-align:center>4</td><td style=text-align:center>16</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>k8s-worker</td></tr><tr><td style=text-align:center>ksp-worker-3</td><td style=text-align:center>192.168.9.96</td><td style=text-align:center>4</td><td style=text-align:center>16</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>k8s-worker</td></tr><tr><td style=text-align:center>ksp-storage-1</td><td style=text-align:center>192.168.9.97</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>300+</td><td style=text-align:center>ElasticSearch/Ceph/Longhorn/NFS/</td></tr><tr><td style=text-align:center>ksp-storage-2</td><td style=text-align:center>192.168.9.98</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>300+</td><td style=text-align:center>ElasticSearch//Ceph/Longhorn</td></tr><tr><td style=text-align:center>ksp-storage-3</td><td style=text-align:center>192.168.9.99</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>300+</td><td style=text-align:center>ElasticSearch//Ceph/Longhorn</td></tr><tr><td style=text-align:center>ksp-gpu-worker-1</td><td style=text-align:center>192.168.9.101</td><td style=text-align:center>4</td><td style=text-align:center>16</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>k8s-worker(GPU NVIDIA Tesla M40 24G)</td></tr><tr><td style=text-align:center>ksp-gpu-worker-2</td><td style=text-align:center>192.168.9.102</td><td style=text-align:center>4</td><td style=text-align:center>16</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>k8s-worker(GPU NVIDIA Tesla P100 16G)</td></tr><tr><td style=text-align:center>ksp-gateway-1</td><td style=text-align:center>192.168.9.103</td><td style=text-align:center>2</td><td style=text-align:center>4</td><td style=text-align:center>40</td><td style=text-align:center></td><td style=text-align:center>自建应用服务代理网关/VIP：192.168.9.100</td></tr><tr><td style=text-align:center>ksp-gateway-2</td><td style=text-align:center>192.168.9.104</td><td style=text-align:center>2</td><td style=text-align:center>4</td><td style=text-align:center>40</td><td style=text-align:center></td><td style=text-align:center>自建应用服务代理网关/VIP：192.168.9.100</td></tr><tr><td style=text-align:center>ksp-mid</td><td style=text-align:center>192.168.9.105</td><td style=text-align:center>4</td><td style=text-align:center>8</td><td style=text-align:center>40</td><td style=text-align:center>100</td><td style=text-align:center>部署在 k8s 集群之外的服务节点（Gitlab 等）</td></tr><tr><td style=text-align:center>合计</td><td style=text-align:center>15</td><td style=text-align:center>56</td><td style=text-align:center>152</td><td style=text-align:center>600</td><td style=text-align:center>2000</td><td style=text-align:center></td></tr></tbody></table><p><strong>实战环境涉及软件版本信息</strong></p><ul><li>操作系统：<strong>openEuler 22.03 LTS SP3 x86_64</strong></li><li>KubeSphere：<strong>v3.4.1</strong></li><li>Kubernetes：<strong>v1.28.8</strong></li><li>KubeKey: <strong>v3.1.1</strong></li><li>Containerd：<strong>1.7.13</strong></li><li>NVIDIA GPU Operator：<strong>v24.3.0</strong></li><li>NVIDIA 显卡驱动：<strong>550.54.15</strong></li></ul><h2 id=1-前置条件>1. 前置条件</h2><h3 id=11-准备带有显卡的-worker-节点>1.1 准备带有显卡的 Worker 节点</h3><p>鉴于资源和成本的限制，我没有高端物理主机和显卡来做实验。只能增加两台配备入门级 GPU 显卡的虚拟机，作为集群的 Worker 节点。</p><ul><li>节点 1，配置 GPU NVIDIA Tesla M40 24G 显卡。唯一优点 24G 大显存，性能低。</li><li>节点 2，配置 GPU NVIDIA Tesla P100 16G 显卡。显存小，但是速度快于 M40、P40 等显卡。</li></ul><p>尽管这些显卡在性能上不及高端型号，但它们足以应对大多数学习和开发任务，在资源有限的情况下，这样的配置为我提供了宝贵的实践机会，让我能够深入探索 Kubernetes 集群中 GPU 资源的管理和调度策略。</p><h3 id=12-操作系统初始化配置>1.2 操作系统初始化配置</h3><p>请参考 <a href=https://mp.weixin.qq.com/s/YDnvnuTqYfmgvF3HGOJ4WQ target=_blank rel="noopener noreferrer">Kubernetes 集群节点 openEuler 22.03 LTS SP3 系统初始化指南</a>，完成操作系统初始化配置。</p><p><strong>初始化配置指南中没有涉及操作系统升级的任务，在能联网的环境初始化系统的时候一定要升级操作系统，然后重启节点。</strong></p><h2 id=2-使用-kubekey-扩容-gpu-worker-节点>2. 使用 KubeKey 扩容 GPU Worker 节点</h2><p>接下来我们使用 KubeKey 将新增加的 GPU 节点加入到已有的 Kubernetes 集群，参考官方说明文档，整个过程比较简单，仅需两步。</p><ul><li>修改 KubeKey 部署时使用的集群配置文件</li><li>执行增加节点的命令</li></ul><h3 id=21-修改集群配置文件>2.1 修改集群配置文件</h3><p>在 Control-1 节点，切换到部署用的 KubeKey 目录，修改原有的集群配置文件，我们实战中使用的名字为 <strong>ksp-v341-v1288.yaml</strong>，请根据实际情况修改 。</p><p>主要修改点：</p><ul><li>spec.hosts 部分：增加新的 worker 节点的信息。</li><li>spec.roleGroups.worker 部分：增加新的 worker 节点的信息</li></ul><p>修改后的示例如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>kubekey.kubesphere.io/v1alpha2</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Cluster</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>opsxlab</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>hosts</span>:
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>......(保持不变)</span>
</span></span><span style=display:flex><span>  - {<span style=color:#f92672>name: ksp-gpu-worker-1, address: 192.168.9.101, internalAddress: 192.168.9.101, user: root, password</span>: <span style=color:#e6db74>&#34;OpsXlab@2024&#34;</span>}
</span></span><span style=display:flex><span>  - {<span style=color:#f92672>name: ksp-gpu-worker-2, address: 192.168.9.102, internalAddress: 192.168.9.102, user: root, password</span>: <span style=color:#e6db74>&#34;OpsXlab@2024&#34;</span>}
</span></span><span style=display:flex><span>  <span style=color:#f92672>roleGroups</span>:
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>......(保持不变)</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>worker</span>:
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>......(保持不变)</span>
</span></span><span style=display:flex><span>    - <span style=color:#ae81ff>ksp-gpu-worker-1</span>
</span></span><span style=display:flex><span>    - <span style=color:#ae81ff>ksp-gpu-worker-2</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#75715e># 下面的内容保持不变</span>
</span></span></code></pre></div><h3 id=22-使用-kubekey-增加节点>2.2 使用 KubeKey 增加节点</h3><p>在增加节点之前，我们再确认一下当前集群的节点信息。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get nodes -o wide
</span></span><span style=display:flex><span>NAME            STATUS   ROLES           AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE                    KERNEL-VERSION                       CONTAINER-RUNTIME
</span></span><span style=display:flex><span>ksp-control-1   Ready    control-plane   24h   v1.28.8   192.168.9.91   &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-182.0.0.95.oe2203sp3.x86_64   containerd://1.7.13
</span></span><span style=display:flex><span>ksp-control-2   Ready    control-plane   24h   v1.28.8   192.168.9.92   &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-182.0.0.95.oe2203sp3.x86_64   containerd://1.7.13
</span></span><span style=display:flex><span>ksp-control-3   Ready    control-plane   24h   v1.28.8   192.168.9.93   &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-182.0.0.95.oe2203sp3.x86_64   containerd://1.7.13
</span></span><span style=display:flex><span>ksp-worker-1    Ready    worker          24h   v1.28.8   192.168.9.94   &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-182.0.0.95.oe2203sp3.x86_64   containerd://1.7.13
</span></span><span style=display:flex><span>ksp-worker-2    Ready    worker          24h   v1.28.8   192.168.9.95   &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-182.0.0.95.oe2203sp3.x86_64   containerd://1.7.13
</span></span><span style=display:flex><span>ksp-worker-3    Ready    worker          24h   v1.28.8   192.168.9.96   &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-182.0.0.95.oe2203sp3.x86_64   containerd://1.7.13
</span></span></code></pre></div><p>接下来我们执行下面的命令，使用修改后的配置文件将新增的 Worker 节点加入集群。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>export KKZONE<span style=color:#f92672>=</span>cn
</span></span><span style=display:flex><span>./kk add nodes -f ksp-v341-v1288.yaml
</span></span></code></pre></div><p>上面的命令执行后，KubeKey 先检查部署 Kubernetes 的依赖及其它配置是否符合要求。通过检查后，系统将提示您确认安装。输入 <strong>yes</strong> 并按 ENTER 继续部署。</p><p>部署完成需要大约 5 分钟左右，具体时间看网速、机器配置、增加的节点数量。</p><p>部署完成后，您应该会在终端上看到类似于下面的输出。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>......
</span></span><span style=display:flex><span>19:29:26 CST <span style=color:#f92672>[</span>AutoRenewCertsModule<span style=color:#f92672>]</span> Generate k8s certs renew script
</span></span><span style=display:flex><span>19:29:27 CST success: <span style=color:#f92672>[</span>ksp-control-2<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>19:29:27 CST success: <span style=color:#f92672>[</span>ksp-control-1<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>19:29:27 CST success: <span style=color:#f92672>[</span>ksp-control-3<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>19:29:27 CST <span style=color:#f92672>[</span>AutoRenewCertsModule<span style=color:#f92672>]</span> Generate k8s certs renew service
</span></span><span style=display:flex><span>19:29:29 CST success: <span style=color:#f92672>[</span>ksp-control-3<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>19:29:29 CST success: <span style=color:#f92672>[</span>ksp-control-2<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>19:29:29 CST success: <span style=color:#f92672>[</span>ksp-control-1<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>19:29:29 CST <span style=color:#f92672>[</span>AutoRenewCertsModule<span style=color:#f92672>]</span> Generate k8s certs renew timer
</span></span><span style=display:flex><span>19:29:30 CST success: <span style=color:#f92672>[</span>ksp-control-2<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>19:29:30 CST success: <span style=color:#f92672>[</span>ksp-control-1<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>19:29:30 CST success: <span style=color:#f92672>[</span>ksp-control-3<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>19:29:30 CST <span style=color:#f92672>[</span>AutoRenewCertsModule<span style=color:#f92672>]</span> Enable k8s certs renew service
</span></span><span style=display:flex><span>19:29:30 CST success: <span style=color:#f92672>[</span>ksp-control-3<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>19:29:30 CST success: <span style=color:#f92672>[</span>ksp-control-2<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>19:29:30 CST success: <span style=color:#f92672>[</span>ksp-control-1<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>19:29:30 CST Pipeline<span style=color:#f92672>[</span>AddNodesPipeline<span style=color:#f92672>]</span> execute successfully
</span></span></code></pre></div><h2 id=3-扩容后集群状态验证>3. 扩容后集群状态验证</h2><h3 id=31-kubesphere-管理控制台验证集群状态>3.1 KubeSphere 管理控制台验证集群状态</h3><p>我们打开浏览器访问 Control-1 节点的 IP 地址和端口 <strong>30880</strong>，登陆 KubeSphere 管理控制台的登录页面。</p><p>进入集群管理界面，单击左侧「节点」菜单，点击「集群节点」查看 Kubernetes 集群可用节点的详细信息。</p><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//ksp-clusters-nodes-add-v341-v128.png alt></p><h3 id=32-kubectl-命令行验证集群状态>3.2 Kubectl 命令行验证集群状态</h3><ul><li>查看集群节点信息</li></ul><p>在 Control-1 节点运行 kubectl 命令获取 Kubernetes 集群的节点信息。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get nodes -o wide
</span></span></code></pre></div><p>在输出结果中可以看到，当前的 Kubernetes 集群有 8个节点，并详细展示每个节点的名字、状态、角色、存活时间、Kubernetes 版本号、内部 IP、操作系统类型、内核版本和容器运行时等信息。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get nodes -o wide
</span></span><span style=display:flex><span>NAME               STATUS     ROLES           AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                    KERNEL-VERSION                        CONTAINER-RUNTIME
</span></span><span style=display:flex><span>ksp-control-1      Ready      control-plane   25h   v1.28.8   192.168.9.91    &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-182.0.0.95.oe2203sp3.x86_64    containerd://1.7.13
</span></span><span style=display:flex><span>ksp-control-2      Ready      control-plane   25h   v1.28.8   192.168.9.92    &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-182.0.0.95.oe2203sp3.x86_64    containerd://1.7.13
</span></span><span style=display:flex><span>ksp-control-3      Ready      control-plane   25h   v1.28.8   192.168.9.93    &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-182.0.0.95.oe2203sp3.x86_64    containerd://1.7.13
</span></span><span style=display:flex><span>ksp-gpu-worker-1   Ready      worker          59m   v1.28.8   192.168.9.101   &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-199.0.0.112.oe2203sp3.x86_64   containerd://1.7.13
</span></span><span style=display:flex><span>ksp-gpu-worker-2   Ready      worker          59m   v1.28.8   192.168.9.102   &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-199.0.0.112.oe2203sp3.x86_64   containerd://1.7.13
</span></span><span style=display:flex><span>ksp-worker-1       Ready      worker          25h   v1.28.8   192.168.9.94    &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-182.0.0.95.oe2203sp3.x86_64    containerd://1.7.13
</span></span><span style=display:flex><span>ksp-worker-2       Ready      worker          25h   v1.28.8   192.168.9.95    &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-182.0.0.95.oe2203sp3.x86_64    containerd://1.7.13
</span></span><span style=display:flex><span>ksp-worker-3       Ready      worker          25h   v1.28.8   192.168.9.96    &lt;none&gt;        openEuler 22.03 <span style=color:#f92672>(</span>LTS-SP3<span style=color:#f92672>)</span>   5.10.0-182.0.0.95.oe2203sp3.x86_64    containerd://1.7.13
</span></span></code></pre></div><p>至此，我们完成了利用 Kubekey 在现有的 3个 Master 节点和 3个 Worker 节点组成的 Kubernetes 集群中增加 2 个 Worker 节点的全部任务。</p><p>接下来我们安装 NVIDIA 官方出品的 NVIDIA GPU Operator，实现 K8s 调度 Pod 使用 GPU 资源。</p><h2 id=4-安装配置-nvidia-gpu-operator>4. 安装配置 NVIDIA GPU Operator</h2><h3 id=41--安装-nvidia-显卡驱动>4.1 安装 NVIDIA 显卡驱动</h3><p>NVIDIA GPU Operator 支持自动安装显卡驱动，但是只 CentOS 7、8 和 Ubuntu 20.04、22.04 等版本，并不支持 openEuler，所以需要手工安装显卡驱动。</p><p>请参考 <a href=https://mp.weixin.qq.com/s/Naugx0rUmgR2UywYXpjEHQ target=_blank rel="noopener noreferrer">KubeSphere 最佳实战：openEuler 22.03 LTS SP3 安装 NVIDIA 显卡驱动</a>，完成显卡驱动安装。</p><h3 id=42-前提条件>4.2 前提条件</h3><p>Node Feature Discovery (NFD) 检测功能检查。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get nodes -o json | jq <span style=color:#e6db74>&#39;.items[].metadata.labels | keys | any(startswith(&#34;feature.node.kubernetes.io&#34;))&#39;</span>
</span></span></code></pre></div><p>上面的命令执行结果为 <code>true</code>, 说明 <code>NFD</code> 已经在集群中运行。如果NFD已经在集群中运行，那么在安装 Operator 时必须禁用部署 NFD。</p><blockquote><p><strong>说明：</strong> 使用 KubeSphere 部署的 K8s 集群默认不会安装配置 NFD。</p></blockquote><h3 id=43-安装-nvidia-gpu-operator>4.3 安装 NVIDIA GPU Operator</h3><ol><li>添加 NVIDIA Helm repository</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>helm repo add nvidia https://helm.ngc.nvidia.com/nvidia <span style=color:#f92672>&amp;&amp;</span> helm repo update
</span></span></code></pre></div><ol start=2><li>安装 GPU Operator</li></ol><p>使用默认配置文件，禁用自动安装显卡驱动功能，安装 GPU Operator。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>helm install -n gpu-operator --create-namespace gpu-operator nvidia/gpu-operator --set driver.enabled<span style=color:#f92672>=</span>false
</span></span></code></pre></div><blockquote><p>注意： 由于安装的镜像比较大，所以初次安装过程中可能会出现超时的情形，请检查你的镜像是否成功拉取！可以考虑使用离线安装解决该类问题。</p></blockquote><ol start=3><li>使用自定义 values 安装 GPU Operator（<strong>可选，离线或是自定义配置时使用</strong>）</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>helm install -f gpu-operator-values.yaml -n gpu-operator --create-namespace gpu-operator nvidia/gpu-operator --set driver.enabled<span style=color:#f92672>=</span>false
</span></span></code></pre></div><p>正确执行输出结果如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ helm install -n gpu-operator --create-namespace gpu-operator nvidia/gpu-operator --set driver.enabled<span style=color:#f92672>=</span>false
</span></span><span style=display:flex><span>NAME: gpu-operator
</span></span><span style=display:flex><span>LAST DEPLOYED: Tue Jul  <span style=color:#ae81ff>2</span> 21:40:29 <span style=color:#ae81ff>2024</span>
</span></span><span style=display:flex><span>NAMESPACE: gpu-operator
</span></span><span style=display:flex><span>STATUS: deployed
</span></span><span style=display:flex><span>REVISION: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>TEST SUITE: None
</span></span></code></pre></div><h3 id=44-命令行检查-gpu-operator-部署状态>4.4 命令行检查 GPU Operator 部署状态</h3><p>执行安装 GPU Operator 的命令后请耐心等待所有镜像成功拉取，所有 Pod 都处于 Running 状态。</p><ol><li>命令行检查 pods 状态</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get pods -n gpu-operator
</span></span><span style=display:flex><span>NAME                                                          READY   STATUS      RESTARTS   AGE
</span></span><span style=display:flex><span>gpu-feature-discovery-czdf5                                   1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>gpu-feature-discovery-q9qlm                                   1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>gpu-operator-67c68ddccf-x29pm                                 1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>gpu-operator-node-feature-discovery-gc-57457b6d8f-zjqhr       1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>gpu-operator-node-feature-discovery-master-5fb74ff754-fzbzm   1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>gpu-operator-node-feature-discovery-worker-68459              1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>gpu-operator-node-feature-discovery-worker-74ps5              1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>gpu-operator-node-feature-discovery-worker-dpmg9              1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>gpu-operator-node-feature-discovery-worker-jvk4t              1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>gpu-operator-node-feature-discovery-worker-k5kwq              1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>gpu-operator-node-feature-discovery-worker-ll4bk              1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>gpu-operator-node-feature-discovery-worker-p4q5q              1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>gpu-operator-node-feature-discovery-worker-rmk99              1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>nvidia-container-toolkit-daemonset-9zcnj                      1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>nvidia-container-toolkit-daemonset-kcz9g                      1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>nvidia-cuda-validator-l8vjb                                   0/1     Completed   <span style=color:#ae81ff>0</span>          14m
</span></span><span style=display:flex><span>nvidia-cuda-validator-svn2p                                   0/1     Completed   <span style=color:#ae81ff>0</span>          13m
</span></span><span style=display:flex><span>nvidia-dcgm-exporter-9lq4c                                    1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>nvidia-dcgm-exporter-qhmkg                                    1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>nvidia-device-plugin-daemonset-7rvfm                          1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>nvidia-device-plugin-daemonset-86gx2                          1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>nvidia-operator-validator-csr2z                               1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span><span style=display:flex><span>nvidia-operator-validator-svlc4                               1/1     Running     <span style=color:#ae81ff>0</span>          15m
</span></span></code></pre></div><ol start=2><li>查看节点可分配的 GPU 资源</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl describe node ksp-gpu-worker-1 | grep <span style=color:#e6db74>&#34;^Capacity&#34;</span> -A <span style=color:#ae81ff>7</span>
</span></span><span style=display:flex><span>Capacity:
</span></span><span style=display:flex><span>  cpu:                <span style=color:#ae81ff>4</span>
</span></span><span style=display:flex><span>  ephemeral-storage:  35852924Ki
</span></span><span style=display:flex><span>  hugepages-1Gi:      <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>  hugepages-2Mi:      <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>  memory:             15858668Ki
</span></span><span style=display:flex><span>  nvidia.com/gpu:     <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  pods:               <span style=color:#ae81ff>110</span>
</span></span></code></pre></div><blockquote><p><strong>说明：</strong> 重点关注 <code>nvidia.com/gpu: </code>字段的值。</p></blockquote><h3 id=45-kubesphere-控制台查看-gpu-operator-部署状态>4.5 KubeSphere 控制台查看 GPU Operator 部署状态</h3><p>创建成功的工作负载如下：</p><ul><li>Deployments</li></ul><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//ksp-gpu-operator-deployments.png alt></p><ul><li>Daemonsets</li></ul><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//ksp-gpu-operator-daemonsets.png alt></p><h2 id=5-gpu-功能验证测试>5. GPU 功能验证测试</h2><h3 id=51-测试示例1-验证测试-cuda>5.1 测试示例1-验证测试 CUDA</h3><p>GPU Operator 正确安装完成后，使用 CUDA 基础镜像，测试 K8s 是否能正确创建使用 GPU 资源的 Pod。</p><ol><li>创建资源清单文件，<code>vi cuda-ubuntu.yaml</code></li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Pod
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: cuda-ubuntu2204
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  restartPolicy: OnFailure
</span></span><span style=display:flex><span>  containers:
</span></span><span style=display:flex><span>  - name: cuda-ubuntu2204
</span></span><span style=display:flex><span>    image: <span style=color:#e6db74>&#34;nvcr.io/nvidia/cuda:12.4.0-base-ubuntu22.04&#34;</span>
</span></span><span style=display:flex><span>    resources:
</span></span><span style=display:flex><span>      limits:
</span></span><span style=display:flex><span>        nvidia.com/gpu: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    command: <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;nvidia-smi&#34;</span><span style=color:#f92672>]</span>
</span></span></code></pre></div><ol start=2><li>创建资源</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f cuda-ubuntu.yaml
</span></span></code></pre></div><ol start=3><li>查看创建的资源</li></ol><p>从结果中可以看到 pod 创建在了 ksp-gpu-worker-2 节点（<strong>该节点显卡型号 Tesla P100-PCIE-16GB</strong>）。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get pods -o wide
</span></span><span style=display:flex><span>NAME                      READY   STATUS      RESTARTS   AGE   IP             NODE               NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>cuda-ubuntu2204           0/1     Completed   <span style=color:#ae81ff>0</span>          73s   10.233.99.15   ksp-gpu-worker-2   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>ollama-79688d46b8-vxmhg   1/1     Running     <span style=color:#ae81ff>0</span>          47m   10.233.72.17   ksp-gpu-worker-1   &lt;none&gt;           &lt;none&gt;
</span></span></code></pre></div><ol start=4><li>查看 Pod 日志</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl logs pod/cuda-ubuntu2204
</span></span></code></pre></div><p>正确执行输出结果如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl logs pod/cuda-ubuntu2204
</span></span><span style=display:flex><span>Mon Jul  <span style=color:#ae81ff>8</span> 11:10:59 <span style=color:#ae81ff>2024</span>
</span></span><span style=display:flex><span>+-----------------------------------------------------------------------------------------+
</span></span><span style=display:flex><span>| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
</span></span><span style=display:flex><span>|-----------------------------------------+------------------------+----------------------+
</span></span><span style=display:flex><span>| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
</span></span><span style=display:flex><span>| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
</span></span><span style=display:flex><span>|                                         |                        |               MIG M. |
</span></span><span style=display:flex><span>|<span style=color:#f92672>=========================================</span>+<span style=color:#f92672>========================</span>+<span style=color:#f92672>======================</span>|
</span></span><span style=display:flex><span>|   <span style=color:#ae81ff>0</span>  Tesla P100-PCIE-16GB           Off |   00000000:00:10.0 Off |                    <span style=color:#ae81ff>0</span> |
</span></span><span style=display:flex><span>| N/A   40C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |
</span></span><span style=display:flex><span>|                                         |                        |                  N/A |
</span></span><span style=display:flex><span>+-----------------------------------------+------------------------+----------------------+
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>+-----------------------------------------------------------------------------------------+
</span></span><span style=display:flex><span>| Processes:                                                                              |
</span></span><span style=display:flex><span>|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
</span></span><span style=display:flex><span>|        ID   ID                                                               Usage      |
</span></span><span style=display:flex><span>|<span style=color:#f92672>=========================================================================================</span>|
</span></span><span style=display:flex><span>|  No running processes found                                                             |
</span></span><span style=display:flex><span>+-----------------------------------------------------------------------------------------+
</span></span></code></pre></div><ol start=5><li>清理测试资源</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#ae81ff>kubectl apply -f cuda-ubuntu.yaml</span>
</span></span></code></pre></div><h3 id=52-测试示例-2-官方-gpu-applications-示例>5.2 测试示例 2-官方 GPU Applications 示例</h3><p>执行一个简单的 CUDA 示例，用于将两个向量（vectors）相加。</p><ol><li>创建资源清单文件，<code>vi cuda-vectoradd.yaml</code></li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Pod
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: cuda-vectoradd
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  restartPolicy: OnFailure
</span></span><span style=display:flex><span>  containers:
</span></span><span style=display:flex><span>  - name: cuda-vectoradd
</span></span><span style=display:flex><span>    image: <span style=color:#e6db74>&#34;nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04&#34;</span>
</span></span><span style=display:flex><span>    resources:
</span></span><span style=display:flex><span>      limits:
</span></span><span style=display:flex><span>        nvidia.com/gpu: <span style=color:#ae81ff>1</span>
</span></span></code></pre></div><ol start=2><li>执行命令创建 Pod</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl apply -f cuda-vectoradd.yaml
</span></span></code></pre></div><ol start=3><li>查看 Pod 执行结果</li></ol><p>Pod 创建成功，启动后会运行 <code>vectorAdd</code> 命令并退出。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl logs pod/cuda-vectoradd
</span></span></code></pre></div><p>正确执行输出结果如下：</p><pre tabindex=0><code>[Vector addition of 50000 elements]
Copy input data from the host memory to the CUDA device
CUDA kernel launch with 196 blocks of 256 threads
Copy output data from the CUDA device to the host memory
Test PASSED
Done
</code></pre><ol start=4><li>清理测试资源</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl delete -f cuda-vectoradd.yaml
</span></span></code></pre></div><h2 id=6-kubesphere-部署-ollama>6. KubeSphere 部署 Ollama</h2><p>通过上面的验证测试，证明可以在 K8s 集群上创建使用 GPU 的 Pod 资源，接下来我们结合实际使用需求，利用 KubeSphere 在 K8s 集群创建一套大模型管理工具 Ollama。</p><h3 id=61-创建部署资源清单>6.1 创建部署资源清单</h3><p>本示例属于简单测试，存储选择了 <strong>hostPath</strong> 模式，实际使用中请替换为存储类或是其他类型的持久化存储。</p><ol><li>创建资源清单，<code>vi deploy-ollama.yaml</code></li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Deployment</span>
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>apps/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>ollama</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>default</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>app</span>: <span style=color:#ae81ff>ollama</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>selector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>matchLabels</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>app</span>: <span style=color:#ae81ff>ollama</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>template</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>app</span>: <span style=color:#ae81ff>ollama</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>ollama-models</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>hostPath</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/data/openebs/local/ollama</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>type</span>: <span style=color:#e6db74>&#39;&#39;</span>
</span></span><span style=display:flex><span>        - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>host-time</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>hostPath</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/etc/localtime</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>type</span>: <span style=color:#e6db74>&#39;&#39;</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>containers</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>ollama</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>image</span>: <span style=color:#e6db74>&#39;ollama/ollama:latest&#39;</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>            - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>http-11434</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>containerPort</span>: <span style=color:#ae81ff>11434</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>protocol</span>: <span style=color:#ae81ff>TCP</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>              <span style=color:#f92672>nvidia.com/gpu</span>: <span style=color:#e6db74>&#39;1&#39;</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>requests</span>:
</span></span><span style=display:flex><span>              <span style=color:#f92672>nvidia.com/gpu</span>: <span style=color:#e6db74>&#39;1&#39;</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>volumeMounts</span>:
</span></span><span style=display:flex><span>            - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>ollama-models</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>mountPath</span>: <span style=color:#ae81ff>/root/.ollama</span>
</span></span><span style=display:flex><span>            - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>host-time</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>readOnly</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>mountPath</span>: <span style=color:#ae81ff>/etc/localtime</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>imagePullPolicy</span>: <span style=color:#ae81ff>IfNotPresent</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>restartPolicy</span>: <span style=color:#ae81ff>Always</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Service</span>
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>ollama</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>default</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>app</span>: <span style=color:#ae81ff>ollama</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>http-11434</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>protocol</span>: <span style=color:#ae81ff>TCP</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>port</span>: <span style=color:#ae81ff>11434</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>targetPort</span>: <span style=color:#ae81ff>11434</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>nodePort</span>: <span style=color:#ae81ff>31434</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>selector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>app</span>: <span style=color:#ae81ff>ollama</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>type</span>: <span style=color:#ae81ff>NodePort</span>
</span></span></code></pre></div><blockquote><p><strong>特殊说明：</strong> KubeSphere 的管理控制台支持图形化配置 Deployment 等资源使用 GPU 资源，配置示例如下，感兴趣的朋友可以自行研究。</p></blockquote><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//ksp-deployments-ollama-resource-status.png alt></p><h3 id=62-部署-ollama-服务>6.2 部署 Ollama 服务</h3><ul><li>创建 Ollama</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f deploy-ollama.yaml
</span></span></code></pre></div><ul><li>查看 Pod 创建结果</li></ul><p>从结果中可以看到 pod 创建在了 ksp-gpu-worker-1 节点（<strong>该节点显卡型号 Tesla M40 24GB</strong>）。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get pods -o wide
</span></span><span style=display:flex><span>NAME                      READY   STATUS    RESTARTS   AGE   IP             NODE               NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>k   1/1     Running   <span style=color:#ae81ff>0</span>          12s   10.233.72.17   ksp-gpu-worker-1   &lt;none&gt;           &lt;none&gt;
</span></span></code></pre></div><ul><li>查看容器 log</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@ksp-control-1 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl logs ollama-79688d46b8-vxmhg</span>
</span></span><span style=display:flex><span>2024/07/08 18:24:27 routes.go:1064: INFO server config env<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST:http://0.0.0.0:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE: OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_MODELS:/root/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR: OLLAMA_SCHED_SPREAD:false OLLAMA_TMPDIR: ROCR_VISIBLE_DEVICES:]&#34;</span>
</span></span><span style=display:flex><span>time<span style=color:#f92672>=</span>2024-07-08T18:24:27.829+08:00 level<span style=color:#f92672>=</span>INFO source<span style=color:#f92672>=</span>images.go:730 msg<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;total blobs: 5&#34;</span>
</span></span><span style=display:flex><span>time<span style=color:#f92672>=</span>2024-07-08T18:24:27.829+08:00 level<span style=color:#f92672>=</span>INFO source<span style=color:#f92672>=</span>images.go:737 msg<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;total unused blobs removed: 0&#34;</span>
</span></span><span style=display:flex><span>time<span style=color:#f92672>=</span>2024-07-08T18:24:27.830+08:00 level<span style=color:#f92672>=</span>INFO source<span style=color:#f92672>=</span>routes.go:1111 msg<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Listening on [::]:11434 (version 0.1.48)&#34;</span>
</span></span><span style=display:flex><span>time<span style=color:#f92672>=</span>2024-07-08T18:24:27.830+08:00 level<span style=color:#f92672>=</span>INFO source<span style=color:#f92672>=</span>payload.go:30 msg<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;extracting embedded files&#34;</span> dir<span style=color:#f92672>=</span>/tmp/ollama2414166698/runners
</span></span><span style=display:flex><span>time<span style=color:#f92672>=</span>2024-07-08T18:24:32.454+08:00 level<span style=color:#f92672>=</span>INFO source<span style=color:#f92672>=</span>payload.go:44 msg<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Dynamic LLM libraries [cpu cpu_avx cpu_avx2 cuda_v11 rocm_v60101]&#34;</span>
</span></span><span style=display:flex><span>time<span style=color:#f92672>=</span>2024-07-08T18:24:32.567+08:00 level<span style=color:#f92672>=</span>INFO source<span style=color:#f92672>=</span>types.go:98 msg<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;inference compute&#34;</span> id<span style=color:#f92672>=</span>GPU-9e48dc13-f8f1-c6bb-860f-c82c96df22a4 library<span style=color:#f92672>=</span>cuda compute<span style=color:#f92672>=</span>5.2 driver<span style=color:#f92672>=</span>12.4 name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Tesla M40 24GB&#34;</span> total<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;22.4 GiB&#34;</span> available<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;22.3 GiB&#34;</span>
</span></span></code></pre></div><h3 id=63-拉取-ollama-使用的大模型>6.3 拉取 Ollama 使用的大模型</h3><ul><li>Ollama 拉取模型</li></ul><p>本示例为了节省时间，采用阿里开源的 qwen2 1.5b 小尺寸模型作为测试模型。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl exec -it ollama-79688d46b8-vxmhg -- ollama pull qwen2:1.5b
</span></span></code></pre></div><p>正确执行输出结果如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>[</span>root@ksp-control-1 ~<span style=color:#f92672>]</span><span style=color:#75715e># kubectl exec -it ollama-79688d46b8-vxmhg -- ollama pull qwen2:1.5b</span>
</span></span><span style=display:flex><span>pulling manifest
</span></span><span style=display:flex><span>pulling 405b56374e02... 100% ▕█████████████████████████████████████████████████████▏ <span style=color:#ae81ff>934</span> MB
</span></span><span style=display:flex><span>pulling 62fbfd9ed093... 100% ▕█████████████████████████████████████████████████████▏  <span style=color:#ae81ff>182</span> B
</span></span><span style=display:flex><span>pulling c156170b718e... 100% ▕█████████████████████████████████████████████████████▏  <span style=color:#ae81ff>11</span> KB
</span></span><span style=display:flex><span>pulling f02dd72bb242... 100% ▕█████████████████████████████████████████████████████▏   <span style=color:#ae81ff>59</span> B
</span></span><span style=display:flex><span>pulling c9f5e9ffbc5f... 100% ▕█████████████████████████████████████████████████████▏  <span style=color:#ae81ff>485</span> B
</span></span><span style=display:flex><span>verifying sha256 digest
</span></span><span style=display:flex><span>writing manifest
</span></span><span style=display:flex><span>removing any unused layers
</span></span><span style=display:flex><span>success
</span></span></code></pre></div><ul><li>查看模型文件的内容</li></ul><p>在 <strong>ksp-gpu-worker-1</strong> 节点执行下面的查看命令</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ ls -R /data/openebs/local/ollama/
</span></span><span style=display:flex><span>/data/openebs/local/ollama/:
</span></span><span style=display:flex><span>id_ed25519  id_ed25519.pub  models
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data/openebs/local/ollama/models:
</span></span><span style=display:flex><span>blobs  manifests
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data/openebs/local/ollama/models/blobs:
</span></span><span style=display:flex><span>sha256-405b56374e02b21122ae1469db646be0617c02928fd78e246723ebbb98dbca3e
</span></span><span style=display:flex><span>sha256-62fbfd9ed093d6e5ac83190c86eec5369317919f4b149598d2dbb38900e9faef
</span></span><span style=display:flex><span>sha256-c156170b718ec29139d3653d40ed1986fd92fb7e0959b5c71f3c48f62e6636f4
</span></span><span style=display:flex><span>sha256-c9f5e9ffbc5f14febb85d242942bd3d674a8e4c762aaab034ec88d6ba839b596
</span></span><span style=display:flex><span>sha256-f02dd72bb2423204352eabc5637b44d79d17f109fdb510a7c51455892aa2d216
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data/openebs/local/ollama/models/manifests:
</span></span><span style=display:flex><span>registry.ollama.ai
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data/openebs/local/ollama/models/manifests/registry.ollama.ai:
</span></span><span style=display:flex><span>library
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data/openebs/local/ollama/models/manifests/registry.ollama.ai/library:
</span></span><span style=display:flex><span>qwen2
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data/openebs/local/ollama/models/manifests/registry.ollama.ai/library/qwen2:
</span></span><span style=display:flex><span>1.5b
</span></span></code></pre></div><h3 id=64-模型能力测试>6.4 模型能力测试</h3><ul><li>调用接口测试</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl http://192.168.9.91:31434/api/chat -d <span style=color:#e6db74>&#39;{
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  &#34;model&#34;: &#34;qwen2:1.5b&#34;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  &#34;messages&#34;: [
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    { &#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;用20个字，介绍你自己&#34; }
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  ]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>}&#39;</span>
</span></span></code></pre></div><ul><li>测试结果</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ curl http://192.168.9.91:31434/api/chat -d <span style=color:#e6db74>&#39;{
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  &#34;model&#34;: &#34;qwen2:1.5b&#34;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  &#34;messages&#34;: [
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    { &#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;用20个字，介绍你自己&#34; }
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  ]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>}&#39;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;model&#34;</span>:<span style=color:#e6db74>&#34;qwen2:1.5b&#34;</span>,<span style=color:#e6db74>&#34;created_at&#34;</span>:<span style=color:#e6db74>&#34;2024-07-08T09:54:48.011798927Z&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#f92672>{</span><span style=color:#e6db74>&#34;role&#34;</span>:<span style=color:#e6db74>&#34;assistant&#34;</span>,<span style=color:#e6db74>&#34;content&#34;</span>:<span style=color:#e6db74>&#34;我&#34;</span><span style=color:#f92672>}</span>,<span style=color:#e6db74>&#34;done&#34;</span>:false<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;model&#34;</span>:<span style=color:#e6db74>&#34;qwen2:1.5b&#34;</span>,<span style=color:#e6db74>&#34;created_at&#34;</span>:<span style=color:#e6db74>&#34;2024-07-08T09:54:48.035291669Z&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#f92672>{</span><span style=color:#e6db74>&#34;role&#34;</span>:<span style=color:#e6db74>&#34;assistant&#34;</span>,<span style=color:#e6db74>&#34;content&#34;</span>:<span style=color:#e6db74>&#34;是一个&#34;</span><span style=color:#f92672>}</span>,<span style=color:#e6db74>&#34;done&#34;</span>:false<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;model&#34;</span>:<span style=color:#e6db74>&#34;qwen2:1.5b&#34;</span>,<span style=color:#e6db74>&#34;created_at&#34;</span>:<span style=color:#e6db74>&#34;2024-07-08T09:54:48.06360233Z&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#f92672>{</span><span style=color:#e6db74>&#34;role&#34;</span>:<span style=color:#e6db74>&#34;assistant&#34;</span>,<span style=color:#e6db74>&#34;content&#34;</span>:<span style=color:#e6db74>&#34;人工智能&#34;</span><span style=color:#f92672>}</span>,<span style=color:#e6db74>&#34;done&#34;</span>:false<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;model&#34;</span>:<span style=color:#e6db74>&#34;qwen2:1.5b&#34;</span>,<span style=color:#e6db74>&#34;created_at&#34;</span>:<span style=color:#e6db74>&#34;2024-07-08T09:54:48.092411266Z&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#f92672>{</span><span style=color:#e6db74>&#34;role&#34;</span>:<span style=color:#e6db74>&#34;assistant&#34;</span>,<span style=color:#e6db74>&#34;content&#34;</span>:<span style=color:#e6db74>&#34;助手&#34;</span><span style=color:#f92672>}</span>,<span style=color:#e6db74>&#34;done&#34;</span>:false<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;model&#34;</span>:<span style=color:#e6db74>&#34;qwen2:1.5b&#34;</span>,<span style=color:#e6db74>&#34;created_at&#34;</span>:<span style=color:#e6db74>&#34;2024-07-08T09:54:48.12016935Z&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#f92672>{</span><span style=color:#e6db74>&#34;role&#34;</span>:<span style=color:#e6db74>&#34;assistant&#34;</span>,<span style=color:#e6db74>&#34;content&#34;</span>:<span style=color:#e6db74>&#34;，&#34;</span><span style=color:#f92672>}</span>,<span style=color:#e6db74>&#34;done&#34;</span>:false<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;model&#34;</span>:<span style=color:#e6db74>&#34;qwen2:1.5b&#34;</span>,<span style=color:#e6db74>&#34;created_at&#34;</span>:<span style=color:#e6db74>&#34;2024-07-08T09:54:48.144921623Z&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#f92672>{</span><span style=color:#e6db74>&#34;role&#34;</span>:<span style=color:#e6db74>&#34;assistant&#34;</span>,<span style=color:#e6db74>&#34;content&#34;</span>:<span style=color:#e6db74>&#34;专注于&#34;</span><span style=color:#f92672>}</span>,<span style=color:#e6db74>&#34;done&#34;</span>:false<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;model&#34;</span>:<span style=color:#e6db74>&#34;qwen2:1.5b&#34;</span>,<span style=color:#e6db74>&#34;created_at&#34;</span>:<span style=color:#e6db74>&#34;2024-07-08T09:54:48.169803961Z&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#f92672>{</span><span style=color:#e6db74>&#34;role&#34;</span>:<span style=color:#e6db74>&#34;assistant&#34;</span>,<span style=color:#e6db74>&#34;content&#34;</span>:<span style=color:#e6db74>&#34;提供&#34;</span><span style=color:#f92672>}</span>,<span style=color:#e6db74>&#34;done&#34;</span>:false<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;model&#34;</span>:<span style=color:#e6db74>&#34;qwen2:1.5b&#34;</span>,<span style=color:#e6db74>&#34;created_at&#34;</span>:<span style=color:#e6db74>&#34;2024-07-08T09:54:48.194796364Z&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#f92672>{</span><span style=color:#e6db74>&#34;role&#34;</span>:<span style=color:#e6db74>&#34;assistant&#34;</span>,<span style=color:#e6db74>&#34;content&#34;</span>:<span style=color:#e6db74>&#34;信息&#34;</span><span style=color:#f92672>}</span>,<span style=color:#e6db74>&#34;done&#34;</span>:false<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;model&#34;</span>:<span style=color:#e6db74>&#34;qwen2:1.5b&#34;</span>,<span style=color:#e6db74>&#34;created_at&#34;</span>:<span style=color:#e6db74>&#34;2024-07-08T09:54:48.21978104Z&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#f92672>{</span><span style=color:#e6db74>&#34;role&#34;</span>:<span style=color:#e6db74>&#34;assistant&#34;</span>,<span style=color:#e6db74>&#34;content&#34;</span>:<span style=color:#e6db74>&#34;和&#34;</span><span style=color:#f92672>}</span>,<span style=color:#e6db74>&#34;done&#34;</span>:false<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;model&#34;</span>:<span style=color:#e6db74>&#34;qwen2:1.5b&#34;</span>,<span style=color:#e6db74>&#34;created_at&#34;</span>:<span style=color:#e6db74>&#34;2024-07-08T09:54:48.244976103Z&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#f92672>{</span><span style=color:#e6db74>&#34;role&#34;</span>:<span style=color:#e6db74>&#34;assistant&#34;</span>,<span style=color:#e6db74>&#34;content&#34;</span>:<span style=color:#e6db74>&#34;帮助&#34;</span><span style=color:#f92672>}</span>,<span style=color:#e6db74>&#34;done&#34;</span>:false<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;model&#34;</span>:<span style=color:#e6db74>&#34;qwen2:1.5b&#34;</span>,<span style=color:#e6db74>&#34;created_at&#34;</span>:<span style=color:#e6db74>&#34;2024-07-08T09:54:48.270233992Z&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#f92672>{</span><span style=color:#e6db74>&#34;role&#34;</span>:<span style=color:#e6db74>&#34;assistant&#34;</span>,<span style=color:#e6db74>&#34;content&#34;</span>:<span style=color:#e6db74>&#34;。&#34;</span><span style=color:#f92672>}</span>,<span style=color:#e6db74>&#34;done&#34;</span>:false<span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>{</span><span style=color:#e6db74>&#34;model&#34;</span>:<span style=color:#e6db74>&#34;qwen2:1.5b&#34;</span>,<span style=color:#e6db74>&#34;created_at&#34;</span>:<span style=color:#e6db74>&#34;2024-07-08T09:54:48.29548561Z&#34;</span>,<span style=color:#e6db74>&#34;message&#34;</span>:<span style=color:#f92672>{</span><span style=color:#e6db74>&#34;role&#34;</span>:<span style=color:#e6db74>&#34;assistant&#34;</span>,<span style=color:#e6db74>&#34;content&#34;</span>:<span style=color:#e6db74>&#34;&#34;</span><span style=color:#f92672>}</span>,<span style=color:#e6db74>&#34;done_reason&#34;</span>:<span style=color:#e6db74>&#34;stop&#34;</span>,<span style=color:#e6db74>&#34;done&#34;</span>:true,<span style=color:#e6db74>&#34;total_duration&#34;</span>:454377627,<span style=color:#e6db74>&#34;load_duration&#34;</span>:1535754,<span style=color:#e6db74>&#34;prompt_eval_duration&#34;</span>:36172000,<span style=color:#e6db74>&#34;eval_count&#34;</span>:12,<span style=color:#e6db74>&#34;eval_duration&#34;</span>:287565000<span style=color:#f92672>}</span>
</span></span></code></pre></div><h3 id=65-查看-gpu-分配信息>6.5 查看 GPU 分配信息</h3><ul><li>查看 Worker 节点已分配的 GPU 资源</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#ae81ff>$ kubectl describe node ksp-gpu-worker-1 | grep &#34;Allocated resources&#34; -A 9</span>
</span></span><span style=display:flex><span><span style=color:#f92672>Allocated resources</span>:
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>(Total limits may be over 100 percent, i.e., overcommitted.)</span>
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>Resource           Requests        Limits</span>
</span></span><span style=display:flex><span>  --------           --------        ------
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>cpu                487m (13%)      2 (55%)</span>
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>memory             315115520 (2%)  800Mi (5%)</span>
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>ephemeral-storage  0 (0%)          0 (0%)</span>
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>hugepages-1Gi      0 (0%)          0 (0%)</span>
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>hugepages-2Mi      0 (0%)          0 (0%)</span>
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>nvidia.com/gpu     1               1</span>
</span></span></code></pre></div><ul><li>Ollama 运行时物理 GPU 使用情况</li></ul><p>在 Worker 节点上执行 <code>nvidia-smi -l </code>观察 GPU 的使用情况。</p><p><img src=https://opsxlab-1258881081.cos.ap-beijing.myqcloud.com//ksp-ollama-gpu-util-M40.png alt></p><blockquote><p><strong>免责声明：</strong></p></blockquote><ul><li>笔者水平有限，尽管经过多次验证和检查，尽力确保内容的准确性，<strong>但仍可能存在疏漏之处</strong>。敬请业界专家大佬不吝指教。</li><li>本文所述内容仅通过实战环境验证测试，读者可学习、借鉴，但<strong>严禁直接用于生产环境</strong>。<strong>由此引发的任何问题，作者概不负责</strong>！</li></ul></div></div><div class=share-2><div class=share><a href="https://twitter.com/intent/tweet?url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fdeploy-ollama-on-kubesphere%2f&text=%e5%9c%a8%20KubeSphere%20%e4%b8%8a%e9%83%a8%e7%bd%b2%20AI%20%e5%a4%a7%e6%a8%a1%e5%9e%8b%20Ollama" target=_blank rel="noopener noreferrer"><img src=/images/share/Twitter.svg alt="twitter icon">
</a><a href="https://reddit.com/submit?url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fdeploy-ollama-on-kubesphere%2f&title=%e5%9c%a8%20KubeSphere%20%e4%b8%8a%e9%83%a8%e7%bd%b2%20AI%20%e5%a4%a7%e6%a8%a1%e5%9e%8b%20Ollama" target=_blank rel="noopener noreferrer"><img src=/images/share/Reddit.svg alt="reddit icon">
</a><a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fdeploy-ollama-on-kubesphere%2f" target=_blank rel="noopener noreferrer"><img src=/images/share/Facebook.svg alt="facebook icon">
</a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fdeploy-ollama-on-kubesphere%2f" target=_blank rel="noopener noreferrer"><img src=/images/share/Linkedin.svg alt="linkedin icon">
</a><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fdeploy-ollama-on-kubesphere%2f&t=%e5%9c%a8%20KubeSphere%20%e4%b8%8a%e9%83%a8%e7%bd%b2%20AI%20%e5%a4%a7%e6%a8%a1%e5%9e%8b%20Ollama" target=_blank rel="noopener noreferrer"><img src=/images/share/HackerNews.svg alt="hackernews icon"></a></div></div></div><div class=aside><div class=inner-div><div class=title>目录</div><div class=tabs><nav id=TableOfContents><ul><li><a href=#1-前置条件>1. 前置条件</a><ul><li><a href=#11-准备带有显卡的-worker-节点>1.1 准备带有显卡的 Worker 节点</a></li><li><a href=#12-操作系统初始化配置>1.2 操作系统初始化配置</a></li></ul></li><li><a href=#2-使用-kubekey-扩容-gpu-worker-节点>2. 使用 KubeKey 扩容 GPU Worker 节点</a><ul><li><a href=#21-修改集群配置文件>2.1 修改集群配置文件</a></li><li><a href=#22-使用-kubekey-增加节点>2.2 使用 KubeKey 增加节点</a></li></ul></li><li><a href=#3-扩容后集群状态验证>3. 扩容后集群状态验证</a><ul><li><a href=#31-kubesphere-管理控制台验证集群状态>3.1 KubeSphere 管理控制台验证集群状态</a></li><li><a href=#32-kubectl-命令行验证集群状态>3.2 Kubectl 命令行验证集群状态</a></li></ul></li><li><a href=#4-安装配置-nvidia-gpu-operator>4. 安装配置 NVIDIA GPU Operator</a><ul><li><a href=#41--安装-nvidia-显卡驱动>4.1 安装 NVIDIA 显卡驱动</a></li><li><a href=#42-前提条件>4.2 前提条件</a></li><li><a href=#43-安装-nvidia-gpu-operator>4.3 安装 NVIDIA GPU Operator</a></li><li><a href=#44-命令行检查-gpu-operator-部署状态>4.4 命令行检查 GPU Operator 部署状态</a></li><li><a href=#45-kubesphere-控制台查看-gpu-operator-部署状态>4.5 KubeSphere 控制台查看 GPU Operator 部署状态</a></li></ul></li><li><a href=#5-gpu-功能验证测试>5. GPU 功能验证测试</a><ul><li><a href=#51-测试示例1-验证测试-cuda>5.1 测试示例1-验证测试 CUDA</a></li><li><a href=#52-测试示例-2-官方-gpu-applications-示例>5.2 测试示例 2-官方 GPU Applications 示例</a></li></ul></li><li><a href=#6-kubesphere-部署-ollama>6. KubeSphere 部署 Ollama</a><ul><li><a href=#61-创建部署资源清单>6.1 创建部署资源清单</a></li><li><a href=#62-部署-ollama-服务>6.2 部署 Ollama 服务</a></li><li><a href=#63-拉取-ollama-使用的大模型>6.3 拉取 Ollama 使用的大模型</a></li><li><a href=#64-模型能力测试>6.4 模型能力测试</a></li><li><a href=#65-查看-gpu-分配信息>6.5 查看 GPU 分配信息</a></li></ul></li></ul></nav></div></div></div></div></section><div class=SubscribeForm><div class=innerBox><img class=close src=/images/home/close.svg alt=close><p class=description>通过邮件接收 KubeSphere 最新的技术博客与产品更新的通知</p><div id=blog_formAddress data-actionaddress="https://www.sendcloud.net/v3/api/subInvite/subscription?invitecode=1dc5a4fb-894c-4470-b01d-ca7fa9d47a46" data-usesendcloud=true data-lang=zh><input name=EMAIL id=email-input-blog type=text placeholder>
<button id=email-submit-blog>订阅</button>
<span id=message_blog data-message1=请提供您的邮箱 data-message2=请输入有效的邮箱地址! data-message3=邮箱地址已经存在 style=color:red></span><span id=message1_blog style=color:#00a971 data-success=订阅成功啦，我们保证不会给你发垃圾邮件的啦></span></div></div></div><footer><div class=footer><div class="footer-main common-layout"><div class=up-main><div class=left-div><img src=/images/logo.svg alt class=foot-logo><p>通过邮件接收 KubeSphere 最新的技术博客与产品更新的通知</p><div id=formAddress data-actionaddress="https://www.sendcloud.net/v3/api/subInvite/subscription?invitecode=1dc5a4fb-894c-4470-b01d-ca7fa9d47a46" data-usesendcloud=true data-lang=zh><input name=EMAIL id=email-input type=text placeholder=请输入您的邮箱地址>
<button id=email-submit>订阅</button></div><span id=message data-message1=请提供您的邮箱 data-message2=请输入有效的邮箱地址! data-message3=邮箱地址已经存在></span><span id=message1 style=color:#00a971 data-success=订阅成功啦，我们保证不会给你发垃圾邮件的啦></span><script>var bindSubmit=function(){var e=$("#email-input");$("#email-submit").click(function(t){t.stopPropagation();var s,o,n=e.val(),i=$("#message").data("message1"),a=$("#message").data("message2"),r=$("#message").data("message3"),c=$("#message1").data("success");if(n)if(validateEmail(n)){if(s=$("#formAddress").data("usesendcloud"),!s)return;o=$("#formAddress").data("actionaddress"),$.post({type:"post",url:o,data:{email:$("#email-input").val().toString()},success:function(){showSuccessMessage(c),setTimeout(function(){$("#email-input").val("")},1e3)},error:function(){showMessage(r)}})}else t.preventDefault(),showMessage(a);else t.preventDefault(),showMessage(i)})},validateEmail=function(e){var t=/^[A-Za-z0-9]+([_.][A-Za-z0-9]+)*@([A-Za-z0-9-]+\.)+[A-Za-z]{2,6}$/;return t.test(e)},showMessage=function(e){$("#message").html(e).show()},showSuccessMessage=function(e){$("#message1").html(e).show()},bindHideMessage=function(){$(window).click(function(){$("#message").hide(),$("#message1").hide()})},bindClose=function(){$(".formBox .close").click(function(e){e.stopPropagation(),$(".formBox").fadeOut()})};bindSubmit(),bindClose(),bindHideMessage()</script><span id=message data-message1=请提供您的邮箱 data-message2=请输入有效的邮箱地址!></span></div><div class=right-div><ul class=common-flex-layout><li class=nowrap-li><div class=h3>应用场景</div><a href=/zh/devops/>拥抱一站式 DevOps</a>
<a href=/zh/service-mesh/>在 K8s 运行微服务</a>
<a href=/zh/observability/>构建云原生可观测性</a>
<a href=https://github.com/kubesphere/kubekey target=_blank rel="noopener noreferrer">K8s 一键部署与运维</a>
<a href=https://github.com/OpenFunction/OpenFunction target=_blank rel="noopener noreferrer">构建 FaaS 平台与 Serverless 架构</a>
<a href=https://github.com/openpitrix/openpitrix target=_blank rel="noopener noreferrer">多云应用管理平台</a></li><li class=nowrap-li><div class=h3>资源</div><a href=/zh/projects/>开源项目</a>
<a href=/zh/blogs/>技术博客</a>
<a href=/zh/conferences/>开源峰会</a>
<a href=/zh/videos/>视频资源</a>
<a href=/zh/learn/>云原生实战</a></li><li class=nowrap-li><div class=h3>文档中心</div><a href=/zh/docs/v4.1/01-intro/01-introduction/>产品介绍</a>
<a href=/zh/docs/v4.1/03-installation-and-upgrade/02-install-kubesphere/02-install-kubernetes-and-kubesphere/>如何安装</a>
<a href=/zh/docs/v4.1/02-quickstart/>快速入门</a>
<a href=/zh/docs/v3.4/reference/api-docs/>API 文档</a></li><li class=nowrap-li><div class=h3>开源社区</div><a href=/zh/contribution/>参与贡献</a>
<a href=/zh/live/>社区活动</a>
<a href=/zh/case/>案例学习</a>
<a href=/zh/partner/>合作伙伴</a>
<a href=/zh/user-group/>用户委员会</a>
<a href=https://github.com/kubesphere/kubesphere/blob/master/docs/roadmap.md target=_blank rel="noopener noreferrer">版本计划</a>
<a href=https://kubesphere.com.cn/ target=_blank rel="noopener noreferrer">中国站</a>
<a href=https://ask.kubesphere.io/forum target=_blank rel="noopener noreferrer">中文论坛</a>
<a href=https://kubesphere.io target=_blank rel="noopener noreferrer">全球站</a></li><li class=nowrap-li><div class=h3>产品与服务</div><a href=https://aws.amazon.com/cn/quickstart/architecture/qingcloud-kubesphere/ target=_blank rel="noopener noreferrer">KubeSphere on AWS</a>
<a href=https://market.azure.cn/marketplace/apps/qingcloud.kubesphere target=_blank rel="noopener noreferrer">KubeSphere on Azure</a>
<a href=https://marketplace.digitalocean.com/apps/kubesphere target=_blank rel="noopener noreferrer">KubeSphere on DigitalOcean</a>
<a href=https://www.qingcloud.com/products/kubesphereqke target=_blank rel="noopener noreferrer">KubeSphere on QingCloud(QKE)</a>
<a href=https://kubesphere.com.cn/kse/ target=_blank rel="noopener noreferrer">KubeSphere 企业版</a>
<a href=https://kubesphere.cloud/ksv/ target=_blank rel="noopener noreferrer">KubeSphere 虚拟化平台</a>
<a href=https://kubesphere.com.cn/marketplace/ target=_blank rel="noopener noreferrer">云原生扩展组件市场</a>
<a href=https://kubesphere.cloud target=_blank rel="noopener noreferrer">云原生应用服务平台</a>
<a href=https://m.qingcloud.com/p/aec50 target=_blank rel="noopener noreferrer">了解商业产品与咨询合作</a></li></ul></div></div><div class=down-main><div class=img-div><a class=wechat href=javascript:void(0); aria-label=wechat><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28" height="28" viewBox="0 0 28 28"><defs><path id="a" d="M0 0h15.673v12.156H0z"/></defs><g fill="none" fill-rule="evenodd" transform="translate(1 1)"><circle cx="13" cy="13" r="13" stroke="#B6C2CD"/><g transform="translate(5 7)"><mask id="b" fill="#fff"><use xlink:href="#a"/></mask><path fill="currentColor" d="M15.673 7.898c0-2.061-2.173-3.74-4.619-3.74-2.59.0-4.625 1.679-4.625 3.74.0 2.066 2.035 3.738 4.625 3.738.542.0 1.09-.13 1.632-.256l1.493.776-.408-1.29c1.09-.776 1.902-1.81 1.902-2.968zm-6.119-.645c-.27.0-.541-.257-.541-.514.0-.256.27-.514.541-.514.41.0.681.258.681.514.0.257-.271.514-.681.514zm2.994.0c-.27.0-.541-.257-.541-.514.0-.256.27-.514.54-.514.41.0.681.258.681.514.0.257-.277.514-.68.514z" mask="url(#b)"/><path fill="currentColor" d="M10.602 3.674c.177.0.356.011.533.029C10.657 1.576 8.27.0 5.543.0 2.498.0.0 1.974.0 4.485c0 1.45.829 2.64 2.216 3.564l-.552 1.588 1.94-.929c.693.129 1.251.263 1.94.263.17.0.343-.005.515-.022a3.68 3.68.0 01-.172-1.104c0-2.302 2.081-4.171 4.715-4.171zM7.618 2.243c.417.0.693.263.693.66s-.276.66-.693.66c-.418.0-.835-.263-.835-.66.006-.398.423-.66.835-.66zm-3.88 1.319c-.417.0-.834-.263-.834-.66s.417-.66.834-.66c.418.0.695.263.695.66.0.392-.277.66-.695.66z" mask="url(#b)"/></g></g></svg><div class=hide-div><img src=/images/home/wechat.svg alt></div></a><a class=facebook-a href=https://www.facebook.com/kubesphere target=_blank aria-label=facebook></a><a class=twitter-a href=https://x.com/KubeSphere target=_blank aria-label=twitter rel="noopener noreferrer"></a><a class=linkedin-a href=https://www.linkedin.com/company/kubesphere/ target=_blank aria-label=linkedin rel="noopener noreferrer"></a><a class=bilibili-a href=https://space.bilibili.com/438908638 target=_blank aria-label=bilibili rel="noopener noreferrer"></a><a class=slack-a href=https://join.slack.com/t/kubesphere/shared_invite/zt-2b4t6rdb4-ico_4UJzCln_S2c1pcrIpQ target=_blank aria-label=slack rel="noopener noreferrer"></a><a class=github-a href=https://github.com/kubesphere/kubesphere target=_blank aria-label=github rel="noopener noreferrer"></a><a class=medium-a href=https://itnext.io/@kubesphere target=_blank aria-label=medium rel="noopener noreferrer"></a></div><p class=p1></p><p class=case><a href=http://www.beian.miit.gov.cn/ target=_blank rel="noopener noreferrer"><span>京ICP备13019086号</span>
</a><a target=_blank rel="noopener noreferrer" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010502041003"><img src=/images/footer/case-icon.png alt=备案图标>
<span>京公网安备 11010502041003号</span></a></p></div></div></div><div class=cookie><div class=common-layout><p>您的隐私对我们很重要。我们使用Cookie来记住订阅详细信息，优化网站功能并交付根据您的兴趣量身定制的内容。要了解更多信息，请参阅我们的<a href=/zh/privacy>隐私政策</a>.</p><button>
接受并继续</button></div></div></footer><script>var lazyLoad=function(e,t){for(var n,o,i,s=0;s<t;s++){if(n=e.eq(s),o=n.attr("data-loaded"),o)continue;n.offset().top<parseInt($(window).height())+parseInt($(window).scrollTop())&&(i=n.attr("src"),n.attr("src",i),n.attr("data-loaded",!0))}},bindLayLoad=function(){var e=$("img"),t=e.length;lazyLoad(e,t),$(window).scroll(function(){lazyLoad(e,t)})},bindAddPadding=function(){var e=$("#close-join");e.length>0&&$(".main-section").addClass("padding")},docCookies={getItem:function(e){return decodeURIComponent(document.cookie.replace(new RegExp("(?:(?:^|.*;)\\s*"+encodeURIComponent(e).replace(/[-.+*]/g,"\\$&")+"\\s*\\=\\s*([^;]*).*$)|^.*$"),"$1"))||null},setItem:function(e,t){return!!e&&!/^(?:expires|max-age|path|domain|secure)$/i.test(e)&&(document.cookie=encodeURIComponent(e)+"="+encodeURIComponent(t),!0)}},bindHideCookie=function(){var t=docCookies.getItem("hasAuth"),e=$(".cookie");t?e.hide():e.show(),e.find("button").on("click",function(){docCookies.setItem("hasAuth","1"),e.hide()})};bindAddPadding(),bindHideCookie()</script><script type=text/javascript src=/js/aside.2d6977c0f16aef4ed3e886dd66675ce74bd0efcd467c2b2bcdb30b92d5e7c7c0e5c6e0c9d8f09a883c22f58df9e6b0b6347fcdd3c9a920b7faba6d7f91a201c3.js integrity="sha512-LWl3wPFq707T6IbdZmdc50vQ781GfCsrzbMLktXnx8DlxuDJ2PCaiDwi9Y355rC2NH/N08mpILf6um1/kaIBww=="></script><script type=text/javascript src=/js/markdown-tab.17f9f46b021adebc7250ce1b07134a577b307e7a436daa4aaf388f218e8463966f53770b26a64817c06c168738a887672d47fb4c29615adfc446e11d09a344cf.js integrity="sha512-F/n0awIa3rxyUM4bBxNKV3swfnpDbapKrziPIY6EY5ZvU3cLJqZIF8BsFoc4qIdnLUf7TClhWt/ERuEdCaNEzw=="></script><script>let forbidForm=!1;var viewer=new Viewer(document.querySelector(".md-body"),{url:"src"}),blogBindSubmit=function(){var e=$("#email-input-blog");$("#email-submit-blog").click(function(t){t.stopPropagation();var s,o,n=e.val(),i=$("#message_blog").data("message1"),a=$("#message_blog").data("message2"),r=$("#message_blog").data("message3"),c=$("#message1_blog").data("success");if(n)if(validateEmail(n)){if(s=$("#blog_formAddress").data("usesendcloud"),!s)return;o=$("#blog_formAddress").data("actionaddress"),$.post({type:"post",url:o,data:{email:n.toString()},success:function(){showSuccessMessage_blog(c),setTimeout(function(){window.onscroll="",$(".SubscribeForm").hide(),$("#email-input-blog").val("")},5e3)},error:function(){showMessage_blog(r)}})}else t.preventDefault(),$("#message_blog").html(a).show();else t.preventDefault(),$("#message_blog").html(i).show()})},validateEmail=function(e){var t=/^[A-Za-z0-9]+([_.][A-Za-z0-9]+)*@([A-Za-z0-9-]+\.)+[A-Za-z]{2,6}$/;return t.test(e)},bindHideMessageBlog=function(){$(window).click(function(){$("#message_blog").hide()})},bindCloseBlog=function(){$(".SubscribeForm .close").click(function(e){e.stopPropagation(),$(".SubscribeForm").fadeOut(),window.onscroll=""})},showMessage_blog=function(e){$("#message_blog").html(e).show()},showSuccessMessage_blog=function(e){$("#message1_blog").html(e).show()};window.onscroll=()=>{var e=document.documentElement.scrollTop||document.body.scrollTop,t=document.documentElement.clientHeight||document.body.clientHeight,n=document.documentElement.scrollHeight||document.body.scrollHeight;forbidForm&&(window.onscroll=""),e+t>n-710?$(".SubscribeForm").hide():$(".SubscribeForm").show()},blogBindSubmit(),bindCloseBlog(),bindHideMessageBlog()</script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script></body></html>