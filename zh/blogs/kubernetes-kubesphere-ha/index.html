<!doctype html><html lang=en-US><head><meta charset=utf-8><title>手把手从零部署与运营生产级的 Kubernetes 集群与 KubeSphere</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="KubeSphere 是在 Kubernetes 之上构建的以应用为中心的多租户容器平台，提供全栈的 IT 自动化运维的能力，简化企业的 DevOps 工作流。KubeSphere 提供了运维友好的向导式操作界面，帮助企业快速构建一个强大和功能丰富的容器云平台。"><meta name=keywords content="Kubernetes,KubeSphere"><meta property="og:type" content="article"><meta property="og:title" content="手把手从零部署与运营生产级的 Kubernetes 集群与 KubeSphere"><meta property="og:description" content="KubeSphere 是在 Kubernetes 之上构建的以应用为中心的多租户容器平台，提供全栈的 IT 自动化运维的能力，简化企业的 DevOps 工作流。KubeSphere 提供了运维友好的向导式操作界面，帮助企业快速构建一个强大和功能丰富的容器云平台。"><meta property="og:image" content="https://92uu-blog.oss-cn-beijing.aliyuncs.com/2020-03-25-091655.png"><meta property="og:url" content="https://openksc.github.io/zh/blogs/kubernetes-kubesphere-ha/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@KubeSphere"><meta property="twitter:image" content="https://92uu-blog.oss-cn-beijing.aliyuncs.com/2020-03-25-091655.png"><meta name=docsearch:language content="zh-CN"><meta name=docsearch:version content><link rel=canonical href=https://kubesphere.io/zh/blogs/kubernetes-kubesphere-ha/><link rel="shortcut icon" href=/images/favicons/favicon.ico><link rel=apple-touch-icon href=/images/favicons/apple-touch-icon.png sizes=180x180><link rel=icon type=image/png href=/images/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/images/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/svg+xml href=/images/favicons/favicon.svg><link rel=icon type=image/png href=/images/favicons/favicon.png><link rel=manifest href=/images/favicons/site.webmanifest><link rel=mask-icon href=/images/favicons/safari-pinned-tab.svg color=#00ad6e><meta name=msapplication-config content='/images/favicons/browserconfig.xml'><meta name=msapplication-TileColor content="#ffffff"><meta name=theme-color content="#ffffff"><link rel=stylesheet href=/fonts/Roboto/stylesheet.css><link rel=stylesheet href=/fonts/ProximaNova/stylesheet.css><link rel=stylesheet href=/css/jquery.modal.min.css><link rel=stylesheet href=/css/viewer.min.css><link rel=stylesheet href=/swiper/swiper-bundle.min.css><link rel=stylesheet href=/scss/common.min.0c3fdcc05ec210321169846714f74b11c4a1baf09a1833fa9273b2347c81e636.css><script src=/js/jquery-3.7.1.min.js></script><script src=/js/viewer.min.js></script><script src=/js/jquery.modal.min.js></script><script src=/swiper/swiper-bundle.min.js></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?0888981f1fa45d241b1fb6962da2963e",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-YYCVN36HT5"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YYCVN36HT5")</script><script type=text/javascript>!function(e,t,n,s,o){e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},n=t.createElement("script"),tag=t.getElementsByTagName("script")[0],n.async=1,n.src=("https:"==document.location.protocol?"https://":"http://")+s,tag.parentNode.insertBefore(n,tag)}(window,document,"script","assets.giocdn.com/2.1/gio.js","gio"),gio("init","8a24ae300cbf8b8c",{}),gio("send")</script><link rel=stylesheet href=/scss/content.min.f73b326fbf8c5bd331900b0de21c7dde608a4926f482f6465f9ae1d9049b83ad.css><link rel=stylesheet href=/scss/markdown.min.db47186481122431dffae72d17dbbd51f90b66f022cc163458645709924e4eac.css></head><body><header class=navigation><div class=join-div><div class=content>🚀 KubeSphere v4.1.3 发布，多项优化与改进，欢迎体验！<a href=/zh/docs/v4.1/20-release-notes/release-v413/ target=_blank rel="noopener noreferrer">请查看 Release notes →</a>
<img id=close-join src=/images/header/close.svg alt=close></div></div><div class=common-layout><div class=header-container><a href=/zh/ aria-label=logo><img src=/images/header/logo.svg alt class=logo></a><ul class=nav><li class=menu-li><span class=menu-span>应用场景</span><ul class="dropdown-menu menu-2"><li><a href=/zh/devops/>拥抱一站式 DevOps 工作流</a></li><li><a href=/zh/service-mesh/>在 Kubernetes 运行微服务</a></li><li><a href=/zh/observability/>构建丰富的云原生可观测性</a></li></ul></li><li class=menu-li><span class=menu-span>资源</span><ul class="dropdown-menu menu-3"><li><a href=/zh/projects/>开源项目</a></li><li><a href=/zh/conferences/>开源峰会</a></li><li><a href=/zh/blogs/>技术博客</a></li><li><a href=/zh/videos/>视频资源</a></li><li><a href=/zh/learn/>云原生实战</a></li></ul></li><li class=menu-li><span class=menu-span>文档中心</span><ul class="dropdown-menu menu-4"><li><a href=/zh/docs/v4.1>v4.1 <img src=/images/header/star.svg alt=star></a></li><li><a href=/zh/docs/v3.4>v3.4</a></li><li><a href=/zh/docs/v3.3>v3.3</a></li><li><a href=https://dev-guide.kubesphere.io/extension-dev-guide/zh/ target=_blank rel="noopener noreferrer">扩展组件开发</a></li><li><a href=https://kube.design/ target=_blank rel="noopener noreferrer">Kube Design</a></li></ul></li><li class=menu-li><span class=menu-span>开源社区</span><ul class="dropdown-menu menu-5"><li><a href=/zh/contribution/>参与贡献</a></li><li><a href=/zh/live/>社区活动</a></li><li><a href=/zh/case/>案例学习</a></li><li><a href=/zh/partner/>合作伙伴</a></li><li><a href=/zh/user-group/>用户委员会</a></li><li><a href=/zh/news/>动态</a></li><li><a href=https://github.com/kubesphere/kubesphere/blob/master/docs/roadmap.md target=_blank rel="noopener noreferrer">版本计划</a></li><li><a href=https://www.kubesphere.io/zh/ target=_blank rel="noopener noreferrer">中国站</a></li><li><a href=https://github.com/kubesphere/community/tree/master/sig-advocacy-and-outreach/ospp-2025 target=_blank rel="noopener noreferrer">开源之夏 2025</a></li></ul></li><li><a data-docs=用户论坛 href=https://ask.kubesphere.io/forum target=_blank rel="noopener noreferrer">用户论坛</a></li><li><a data-docs=认证 href=https://kubesphere.cloud/certification/ target=_blank rel="noopener noreferrer">认证</a></li></ul><div class=right-menu><ul><li class=language-menu><div><img src=/images/header/black.svg alt>
<span>简体中文</span></div><ul class=dropdown-menu><li onclick='handleLangClick("zh","/zh/blogs/kubernetes-kubesphere-ha/")'>简体中文</li></ul></li><li class=github-li><div class=github-star><a class=star-btn href=https://github.com/kubesphere/kubesphere rel="noopener noreferrer" target=_blank><span class=star-img></span>&nbsp;<span>Star</span>
</a><a class=social-count href=https://github.com/kubesphere/kubesphere/stargazers rel="noopener noreferrer" target=_blank></a></div></li><li class=menu-icon><img src=/images/header/menu.svg alt></li></ul></div></div></div><div id=modal-for-menu class=modal><ul class=nav><li data-check=0 class=menu-li><span class=menu-span>应用场景</span><ul class=dropdown-menu><li><a href=/zh/devops/>拥抱一站式 DevOps 工作流</a></li><li><a href=/zh/service-mesh/>在 Kubernetes 运行微服务</a></li><li><a href=/zh/observability/>构建丰富的云原生可观测性</a></li></ul></li><li data-check=0 class=menu-li><span class=menu-span>资源</span><ul class=dropdown-menu><li><a href=/zh/projects/>开源项目</a></li><li><a href=/zh/conferences/>开源峰会</a></li><li><a href=/zh/blogs/>技术博客</a></li><li><a href=/zh/videos/>视频资源</a></li><li><a href=/zh/learn/>云原生实战</a></li></ul></li><li data-check=0 class=menu-li><span class=menu-span>文档中心</span><ul class=dropdown-menu><li><a href=/zh/docs/v4.1>v4.1 <img src=/images/header/star.svg alt=star></a></li><li><a href=/zh/docs/v3.4>v3.4</a></li><li><a href=/zh/docs/v3.3>v3.3</a></li><li><a href=https://dev-guide.kubesphere.io/extension-dev-guide/zh/>扩展组件开发</a></li><li><a href=https://kube.design/>Kube Design</a></li></ul></li><li data-check=0 class=menu-li><span class=menu-span>开源社区</span><ul class=dropdown-menu><li><a href=/zh/contribution/>参与贡献</a></li><li><a href=/zh/live/>社区活动</a></li><li><a href=/zh/case/>案例学习</a></li><li><a href=/zh/partner/>合作伙伴</a></li><li><a href=/zh/user-group/>用户委员会</a></li><li><a href=/zh/news/>动态</a></li><li><a href=https://github.com/kubesphere/kubesphere/blob/master/docs/roadmap.md>版本计划</a></li><li><a href=https://www.kubesphere.io/zh/>中国站</a></li><li><a href=https://github.com/kubesphere/community/tree/master/sig-advocacy-and-outreach/ospp-2025>开源之夏 2025</a></li></ul></li><li><a data-docs=用户论坛 href=https://ask.kubesphere.io/forum>用户论坛</a></li><li><a data-docs=认证 href=https://kubesphere.cloud/certification/>认证</a></li></ul><div class=link-div><a href=https://join.slack.com/t/kubesphere/shared_invite/zt-2b4t6rdb4-ico_4UJzCln_S2c1pcrIpQ target=_blank rel="noopener noreferrer" aria-label=slack><img src=/images/header/slack-hover.svg alt>
</a><a href=https://x.com/KubeSphere target=_blank rel="noopener noreferrer" aria-label=twitter><img src=/images/header/twitter-hover.svg alt>
</a><a href=https://github.com/kubesphere/kubesphere target=_blank rel="noopener noreferrer" aria-label=github><img src=/images/header/github-hover.svg alt></a></div></div></header><script>var bindNavMouseEvent,bindScrollChangeHeader,bindClickShowMenu,bindClickModalLi,bindClickClose,language,handleLangClick,githubApiLink="https://api.github.com/repos/kubesphere/kubesphere",getStar=function(){$(".social-count").hide(),$.getJSON(githubApiLink,function(e){$(".social-count").show().html(e.stargazers_count)})};getStar(),bindNavMouseEvent=function(e,t){t||(t=$(e));var n=!1;t.mouseenter(function(){if(n)return!1;n=!0,$(this).find(".dropdown-menu").fadeIn(200,function(){n=!1})}),t.mouseleave(function(){$(this).find(".dropdown-menu").fadeOut(200)})},bindScrollChangeHeader=function(){var t=100,e=$("header");window.addEventListener("scroll",function(){var t=window.scrollY;t>0?e.addClass("navigationScroll"):e.removeClass("navigationScroll")})},bindClickShowMenu=function(){$(".menu-icon").click(function(){$("#modal-for-menu").modal()})},bindClickModalLi=function(){$(".modal .menu-li").click(function(){var e=$(this).data("check");e===0?($(this).data("check",1),$(this).find(".dropdown-menu").slideDown(200)):($(this).data("check",0),$(this).find(".dropdown-menu").slideUp(200)),$(this).find(".menu-span").toggleClass("up")})},bindClickClose=function(){$("#close-join").click(function(){$(".navigation .join-div").hide(),$(".main-section").removeClass("padding")})},language="zh",bindClickClose(),bindScrollChangeHeader(),$(".header-container .menu-li").each(function(){bindNavMouseEvent("",$(this))}),bindNavMouseEvent(".header-container .language-menu"),bindNavMouseEvent(".header-container .btn-li"),bindClickShowMenu(),bindClickModalLi(),handleLangClick=function(e,t){try{localStorage.setItem("lang",e)}catch{}location.href=t}</script><section class=main-section><div class=common-layout><div class=breadcrumb><span><a href=/zh/blogs/>技术博客</a> > </span><span>手把手从零部署与运营生产级的 Kubernetes 集群与 KubeSphere</span></div><div class='main-div middle-div'><div class=author>Liu_wt</div><span class=date>发布于：2020-03-26</span>&nbsp;&nbsp;&nbsp;
<span style=font-size:14px;color:#919aa3 id=busuanzi_container_page_pv>本文总阅读量：<span id=busuanzi_value_page_pv></span></span><h1>手把手从零部署与运营生产级的 Kubernetes 集群与 KubeSphere</h1><div class=share-1><div class=share><a href="https://twitter.com/intent/tweet?url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-kubesphere-ha%2f&text=%e6%89%8b%e6%8a%8a%e6%89%8b%e4%bb%8e%e9%9b%b6%e9%83%a8%e7%bd%b2%e4%b8%8e%e8%bf%90%e8%90%a5%e7%94%9f%e4%ba%a7%e7%ba%a7%e7%9a%84%20Kubernetes%20%e9%9b%86%e7%be%a4%e4%b8%8e%20KubeSphere" target=_blank rel="noopener noreferrer"><img src=/images/share/Twitter.svg alt="twitter icon">
</a><a href="https://reddit.com/submit?url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-kubesphere-ha%2f&title=%e6%89%8b%e6%8a%8a%e6%89%8b%e4%bb%8e%e9%9b%b6%e9%83%a8%e7%bd%b2%e4%b8%8e%e8%bf%90%e8%90%a5%e7%94%9f%e4%ba%a7%e7%ba%a7%e7%9a%84%20Kubernetes%20%e9%9b%86%e7%be%a4%e4%b8%8e%20KubeSphere" target=_blank rel="noopener noreferrer"><img src=/images/share/Reddit.svg alt="reddit icon">
</a><a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-kubesphere-ha%2f" target=_blank rel="noopener noreferrer"><img src=/images/share/Facebook.svg alt="facebook icon">
</a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-kubesphere-ha%2f" target=_blank rel="noopener noreferrer"><img src=/images/share/Linkedin.svg alt="linkedin icon">
</a><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-kubesphere-ha%2f&t=%e6%89%8b%e6%8a%8a%e6%89%8b%e4%bb%8e%e9%9b%b6%e9%83%a8%e7%bd%b2%e4%b8%8e%e8%bf%90%e8%90%a5%e7%94%9f%e4%ba%a7%e7%ba%a7%e7%9a%84%20Kubernetes%20%e9%9b%86%e7%be%a4%e4%b8%8e%20KubeSphere" target=_blank rel="noopener noreferrer"><img src=/images/share/HackerNews.svg alt="hackernews icon"></a></div></div><div class=content><div class=md-body><p><img src=https://pek3b.qingstor.com/kubesphere-docs/png/20200327191533.png alt></p><blockquote><p>本文来自 KubeSphere 社区用户 <strong>Liu_wt</strong> 投稿，欢迎所有社区用户参与投稿或分享经验案例。</p></blockquote><p>本文将从零开始，在干净的机器上安装 Docker、Kubernetes (使用 kubeadm)、Calico、Helm 与 KubeSphere，通过手把手的教程演示如何搭建一个高可用生产级的 Kubernetes，并在 Kubernetes 集群之上安装 KubeSphere 容器平台可视化运营集群环境。</p><h2 id=一准备环境>一、准备环境</h2><p>开始部署之前，请先确定当前满足如下条件，本次集群搭建，所有机器处于同一内网网段，并且可以互相通信。</p><p>⚠️⚠️⚠️：<strong>请详细阅读第一部分，后面的所有操作都是基于这个环境的，为了避免后面部署集群出现各种各样的问题，强烈建议你完全满足第一部分的环境要求</strong></p><blockquote><ul><li>两台以上主机</li><li>每台主机的主机名、Mac 地址、UUID 不相同</li><li>CentOS 7（本文用 7.6/7.7）</li><li>每台机器最好有 2G 内存或以上</li><li>Control-plane/Master至少 2U 或以上</li><li>各个主机之间网络相通</li><li>禁用交换分区</li><li>禁用 SELINUX</li><li>关闭防火墙（我自己的选择，你也可以设置相关防火墙规则）</li><li>Control-plane/Master和Worker节点分别开放如下端口</li></ul></blockquote><p><strong>Master节点</strong></p><table><thead><tr><th>协议</th><th>方向</th><th>端口范围</th><th>作用</th><th>使用者</th></tr></thead><tbody><tr><td>TCP</td><td>入站</td><td>6443*</td><td>Kubernetes API 服务器</td><td>所有组件</td></tr><tr><td>TCP</td><td>入站</td><td>2379-2380</td><td>etcd server client API</td><td>kube-apiserver, etcd</td></tr><tr><td>TCP</td><td>入站</td><td>10250</td><td>Kubelet API</td><td>kubelet 自身、控制平面组件</td></tr><tr><td>TCP</td><td>入站</td><td>10251</td><td>kube-scheduler</td><td>kube-scheduler 自身</td></tr><tr><td>TCP</td><td>入站</td><td>10252</td><td>kube-controller-manager</td><td>kube-controller-manager 自身</td></tr></tbody></table><p><strong>Worker节点</strong></p><table><thead><tr><th>协议</th><th>方向</th><th>端口范围</th><th>作用</th><th>使用者</th></tr></thead><tbody><tr><td>TCP</td><td>入站</td><td>10250</td><td>Kubelet API</td><td>kubelet 自身、控制平面组件</td></tr><tr><td>TCP</td><td>入站</td><td>30000-32767</td><td>NodePort 服务**</td><td>所有组件</td></tr></tbody></table><p>其他相关操作如下：</p><blockquote><p>友情提示😊，如果集群过多，可以了解下 ansible，批量管理你的多台机器，方便实用的工具。</p></blockquote><p>先进行防火墙、交换分区设置</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 为了方便本操作关闭了防火墙，也建议你这样操作</span>
</span></span><span style=display:flex><span>systemctl stop firewalld
</span></span><span style=display:flex><span>systemctl disable firewalld
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 关闭 SeLinux</span>
</span></span><span style=display:flex><span>setenforce <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>sed -i <span style=color:#e6db74>&#34;s/SELINUX=enforcing/SELINUX=disabled/g&#34;</span> /etc/selinux/config
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 关闭 swap</span>
</span></span><span style=display:flex><span>swapoff -a
</span></span><span style=display:flex><span>yes | cp /etc/fstab /etc/fstab_bak
</span></span><span style=display:flex><span>cat /etc/fstab_bak |grep -v swap &gt; /etc/fstab
</span></span></code></pre></div><p>更换CentOS YUM源为阿里云yum源</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 安装wget</span>
</span></span><span style=display:flex><span>yum install wget -y
</span></span><span style=display:flex><span><span style=color:#75715e># 备份</span>
</span></span><span style=display:flex><span>mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
</span></span><span style=display:flex><span><span style=color:#75715e># 获取阿里云yum源</span>
</span></span><span style=display:flex><span>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
</span></span><span style=display:flex><span><span style=color:#75715e># 获取阿里云epel源</span>
</span></span><span style=display:flex><span>wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
</span></span><span style=display:flex><span><span style=color:#75715e># 清理缓存并创建新的缓存</span>
</span></span><span style=display:flex><span>yum clean all <span style=color:#f92672>&amp;&amp;</span> yum makecache
</span></span><span style=display:flex><span><span style=color:#75715e># 系统更新</span>
</span></span><span style=display:flex><span>yum update -y
</span></span></code></pre></div><p>进行时间同步，并确认时间同步成功</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>timedatectl
</span></span><span style=display:flex><span>timedatectl set-ntp true
</span></span></code></pre></div><blockquote><p>⚠️⚠️⚠️以下操作请严格按照声明的版本进行部署，否则将碰到乱七八糟的问题</p></blockquote><h1 id=二安装-docker>二、安装 Docker</h1><h2 id=21安装-docker>2.1、安装 Docker</h2><p>您需要在每台机器上安装 Docker，我这里安装的是 <code>docker-ce-19.03.4</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 安装 Docker CE</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 设置仓库</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 安装所需包</span>
</span></span><span style=display:flex><span>yum install -y yum-utils <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    device-mapper-persistent-data <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    lvm2
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 新增 Docker 仓库,速度慢的可以换阿里云的源。</span>
</span></span><span style=display:flex><span>yum-config-manager <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --add-repo <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span style=display:flex><span><span style=color:#75715e># 阿里云源地址</span>
</span></span><span style=display:flex><span><span style=color:#75715e># http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 安装 Docker CE.</span>
</span></span><span style=display:flex><span>yum install -y containerd.io-1.2.10 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    docker-ce-19.03.4 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    docker-ce-cli-19.03.4
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 启动 Docker 并添加开机启动</span>
</span></span><span style=display:flex><span>systemctl start docker
</span></span><span style=display:flex><span>systemctl enable docker
</span></span></code></pre></div><h2 id=22修改-cgroup-driver>2.2、修改 Cgroup Driver</h2><p>需要将Docker 的 Cgroup Driver 修改为 systemd，不然在为Kubernetes 集群添加节点时会报如下错误：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 执行 kubeadm join 的 WARNING 信息</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>WARNING IsDockerSystemdCheck<span style=color:#f92672>]</span>: detected <span style=color:#e6db74>&#34;cgroupfs&#34;</span> as the Docker cgroup driver. The recommended driver is <span style=color:#e6db74>&#34;systemd&#34;</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/
</span></span></code></pre></div><p>目前 Docker 的 Cgroup Driver 看起来应该是这样的：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ docker info|grep <span style=color:#e6db74>&#34;Cgroup Driver&#34;</span>
</span></span><span style=display:flex><span>  Cgroup Driver: cgroupfs
</span></span></code></pre></div><p>需要将这个值修改为 systemd ，同时我将registry替换成国内的一些仓库地址，以免直接在官方仓库拉取镜像会很慢，操作如下。</p><blockquote><p>⚠️⚠️⚠️：注意缩进，直接复制的缩进可能有问题，请确保缩进为正确的 Json 格式；如果 Docker 重启后查看状态不正常，大概率是此文件缩进有问题，Json格式的缩进自己了解一下。</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Setup daemon.</span>
</span></span><span style=display:flex><span>cat &gt; /etc/docker/daemon.json <span style=color:#e6db74>&lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#e6db74>{
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;],
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;log-driver&#34;: &#34;json-file&#34;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;log-opts&#34;: {
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;max-size&#34;: &#34;100m&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    },
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;storage-driver&#34;: &#34;overlay2&#34;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;registry-mirrors&#34;:[
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;https://kfwkfulq.mirror.aliyuncs.com&#34;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;https://2lqq34jg.mirror.aliyuncs.com&#34;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;https://pee6w651.mirror.aliyuncs.com&#34;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;http://hub-mirror.c.163.com&#34;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;https://docker.mirrors.ustc.edu.cn&#34;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;https://registry.docker-cn.com&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    ]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>}
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mkdir -p /etc/systemd/system/docker.service.d
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Restart docker.</span>
</span></span><span style=display:flex><span>systemctl daemon-reload
</span></span><span style=display:flex><span>systemctl restart docker
</span></span></code></pre></div><h1 id=三安装-kubeadmkubelet-和-kubectl>三、安装 kubeadm、kubelet 和 kubectl</h1><h2 id=31安装准备>3.1、安装准备</h2><p>需要在每台机器上安装以下的软件包：</p><ul><li><p><code>kubeadm</code>：用来初始化集群的指令。</p></li><li><p><code>kubelet</code>：在集群中的每个节点上用来启动 pod 和容器等。</p></li><li><p><code>kubectl</code>：用来与集群通信的命令行工具（Worker 节点可以不装，但是我装了，不影响什么）。</p></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 配置K8S的yum源</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 这部分用是阿里云的源，如果可以访问Google，则建议用官方的源</span>
</span></span><span style=display:flex><span>cat <span style=color:#e6db74>&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style=display:flex><span><span style=color:#e6db74>[kubernetes]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>name=Kubernetes
</span></span></span><span style=display:flex><span><span style=color:#e6db74>baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style=display:flex><span><span style=color:#e6db74>enabled=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>repo_gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 官方源配置如下</span>
</span></span><span style=display:flex><span>cat <span style=color:#e6db74>&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style=display:flex><span><span style=color:#e6db74>[kubernetes]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>name=Kubernetes
</span></span></span><span style=display:flex><span><span style=color:#e6db74>baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style=display:flex><span><span style=color:#e6db74>enabled=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>repo_gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span></code></pre></div><h2 id=32开始安装>3.2、开始安装</h2><p>安装指定版本 <code>kubelet</code>、 <code>kubeadm</code> 、<code>kubectl</code>， 我这里选择当前较新的稳定版 Kubernetes 1.17.3，如果选择的版本不一样，在执行集群初始化的时候，注意 <code>--kubernetes-version</code> 的值。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 增加配置</span>
</span></span><span style=display:flex><span>cat <span style=color:#e6db74>&lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf
</span></span></span><span style=display:flex><span><span style=color:#e6db74>net.ipv4.ip_forward=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>net.bridge.bridge-nf-call-iptables = 1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 加载</span>
</span></span><span style=display:flex><span>sysctl --system
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 安装</span>
</span></span><span style=display:flex><span>yum install -y kubelet-1.17.3 kubeadm-1.17.3 kubectl-1.17.3 --disableexcludes<span style=color:#f92672>=</span>kubernetes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 启动并设置 kubelet 开机启动</span>
</span></span><span style=display:flex><span>systemctl start kubelet
</span></span><span style=display:flex><span>systemctl enable --now kubelet
</span></span></code></pre></div><blockquote><p>⚠️⚠️⚠️WARNING</p><p>如果此时执行 <code>systemctl status kubelet</code> 命令，系统日志将得到 kubelet 启动失败的错误提示，请忽略此错误，因为必须完成后续步骤中 kubeadm init 的操作，kubelet 才能正常启动</p></blockquote><h1 id=四使用-kubeadm-创建集群>四、使用 Kubeadm 创建集群</h1><h2 id=41初始化-control-planemaster-节点>4.1、初始化 Control-plane/Master 节点</h2><p>在第一台 Master 上执行初始化，执行初始化使用 <code>kubeadm init</code> 命令。初始化首先会执行一系列的运行前检查来确保机器满足运行 Kubernetes 的条件，这些检查会抛出警告并在发现错误的时候终止整个初始化进程。 然后 <code>kubeadm init</code> 会下载并安装集群的 Control-plane 组件。</p><p>在初始化之前，需要先设置一下 hosts 解析，为了避免可能出现的问题，后面的 Worker 节点我也进行了同样的操作。注意按照你的实际情况修改Master节点的IP，并且注意 <code>APISERVER_NAME</code> 的值，如果你将这个 apiserver 名称设置为别的值，下面初始化时候的 <code>--control-plane-endpoint</code> 的值保持一致。</p><blockquote><p>提示：为了使 Kubernetes 集群高可用，建议给集群的控制节点配置负载均衡器，如 HAproxy + Keepalived 或 Nginx，云上可以使用公有云的负载均衡器，然后在以下部分设置 <code>MASTER_IP</code> 和 <code>APISERVER_NAME</code> 为负载均衡器的地址（IP:6443） 和域名。</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 设置hosts</span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;127.0.0.1 </span><span style=color:#66d9ef>$(</span>hostname<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span> &gt;&gt; /etc/hosts
</span></span><span style=display:flex><span>export MASTER_IP<span style=color:#f92672>=</span>192.168.115.49
</span></span><span style=display:flex><span>export APISERVER_NAME<span style=color:#f92672>=</span>kuber4s.api
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>MASTER_IP<span style=color:#e6db74>}</span><span style=color:#e6db74> </span><span style=color:#e6db74>${</span>APISERVER_NAME<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> &gt;&gt; /etc/hosts
</span></span></code></pre></div><blockquote><p>友情提示🙂🙂🙂：</p><p>截止2020年01月29日，官方文档声明了使用 kubeadm 初始化 master 时，--config 这个参数是实验性质的，所以就不用了；我们用其他参数一样可以完成 master 的初始化。</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>--config string   kubeadm 配置文件。 警告：配置文件的使用是试验性的。
</span></span></code></pre></div><p>下面有不带注释的初始化命令，建议先查看带注释的每个参数对应的意义，确保与你的当前配置的环境是一致的，然后再执行初始化操作，避免踩雷。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 初始化 Control-plane/Master 节点</span>
</span></span><span style=display:flex><span>kubeadm init <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --apiserver-advertise-address 0.0.0.0 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#75715e># API 服务器所公布的其正在监听的 IP 地址,指定“0.0.0.0”以使用默认网络接口的地址</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 切记只可以是内网IP，不能是外网IP，如果有多网卡，可以使用此选项指定某个网卡</span>
</span></span><span style=display:flex><span>    --apiserver-bind-port <span style=color:#ae81ff>6443</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#75715e># API 服务器绑定的端口,默认 6443</span>
</span></span><span style=display:flex><span>    --cert-dir /etc/kubernetes/pki <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#75715e># 保存和存储证书的路径，默认值：&#34;/etc/kubernetes/pki&#34;</span>
</span></span><span style=display:flex><span>    --control-plane-endpoint kuber4s.api <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#75715e># 为控制平面指定一个稳定的 IP 地址或 DNS 名称,</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 这里指定的 kuber4s.api 已经在 /etc/hosts 配置解析为本机IP</span>
</span></span><span style=display:flex><span>    --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#75715e># 选择用于拉取Control-plane的镜像的容器仓库，默认值：&#34;k8s.gcr.io&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 因 Google被墙，这里选择国内仓库</span>
</span></span><span style=display:flex><span>    --kubernetes-version 1.17.3 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#75715e># 为Control-plane选择一个特定的 Kubernetes 版本， 默认值：&#34;stable-1&#34;</span>
</span></span><span style=display:flex><span>    --node-name master01 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#75715e>#  指定节点的名称,不指定的话为主机hostname，默认可以不指定</span>
</span></span><span style=display:flex><span>    --pod-network-cidr 10.10.0.0/16 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#75715e># 指定pod的IP地址范围</span>
</span></span><span style=display:flex><span>    --service-cidr 10.20.0.0/16 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#75715e># 指定Service的VIP地址范围</span>
</span></span><span style=display:flex><span>    --service-dns-domain cluster.local <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#75715e># 为Service另外指定域名，默认&#34;cluster.local&#34;</span>
</span></span><span style=display:flex><span>    --upload-certs
</span></span><span style=display:flex><span>    <span style=color:#75715e># 将 Control-plane 证书上传到 kubeadm-certs Secret</span>
</span></span></code></pre></div><p>不带注释的内容如下，如果初始化超时，可以修改DNS为8.8.8.8后重启网络服务再次尝试。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm init <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --apiserver-advertise-address 0.0.0.0 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --apiserver-bind-port <span style=color:#ae81ff>6443</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --cert-dir /etc/kubernetes/pki <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --control-plane-endpoint kuber4s.api <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --kubernetes-version 1.17.3 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --pod-network-cidr 10.10.0.0/16 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --service-cidr 10.20.0.0/16 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --service-dns-domain cluster.local <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --upload-certs
</span></span></code></pre></div><p>接下来这个过程有点漫长（初始化会下载镜像、创建配置文件、启动容器等操作），泡杯茶，耐心等待，你也可以执行 <code>tailf /var/log/messages</code> 来实时查看系统日志，观察 Master 的初始化进展，期间碰到一些报错不要紧张，可能只是暂时的错误，等待最终反馈的结果即可。</p><p>如果初始化最终成功执行，你将看到如下信息：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>Your Kubernetes control-plane has initialized successfully!
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>To start using your cluster, you need to run the following as a regular user:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  mkdir -p $HOME/.kube
</span></span><span style=display:flex><span>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style=display:flex><span>  sudo chown <span style=color:#66d9ef>$(</span>id -u<span style=color:#66d9ef>)</span>:<span style=color:#66d9ef>$(</span>id -g<span style=color:#66d9ef>)</span> $HOME/.kube/config
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>You should now deploy a pod network to the cluster.
</span></span><span style=display:flex><span>Run <span style=color:#e6db74>&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
</span></span><span style=display:flex><span>  https://kubernetes.io/docs/concepts/cluster-administration/addons/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>You can now join any number of the control-plane node running the following command on each as root:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  kubeadm join kuber4s.api:6443 --token 0j287q.jw9zfjxud8w85tis <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --control-plane --certificate-key 528b0b9f2861f8f02dfd4a59fc54ad21e42a7dea4dc5552ac24d9c650c5d4d80
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
</span></span><span style=display:flex><span>As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
</span></span><span style=display:flex><span><span style=color:#e6db74>&#34;kubeadm init phase upload-certs --upload-certs&#34;</span> to reload certs afterward.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Then you can join any number of worker nodes by running the following on each as root:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubeadm join kuber4s.api:6443 --token 0j287q.jw9zfjxud8w85tis <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f
</span></span></code></pre></div><p>为普通用户添加 <code>kubectl</code> 运行权限，命令内容在初始化成功后的输出内容中可以看到。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mkdir -p $HOME/.kube
</span></span><span style=display:flex><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style=display:flex><span>sudo chown <span style=color:#66d9ef>$(</span>id -u<span style=color:#66d9ef>)</span>:<span style=color:#66d9ef>$(</span>id -g<span style=color:#66d9ef>)</span> $HOME/.kube/config
</span></span></code></pre></div><p>建议root用户也进行以上操作，作者使用的是root用户执行的初始化操作，然后在操作完成后查看集群状态的时候，出现如下错误：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>The connection to the server localhost:8080 was refused - did you specify the right host or port?
</span></span></code></pre></div><p>这时候请备份好 <code>kubeadm init</code> 输出中的 <code>kubeadm join</code> 命令，因为将会需要这个命令来给集群添加节点。</p><blockquote><p>⚠️⚠️⚠️提示：令牌是主节点和新添加的节点之间进行相互身份验证的，因此请确保其安全。任何人只要知道了这些令牌，就可以随便给您的集群添加节点。 你可以使用 <code>kubeadm token</code> 命令来查看、创建和删除这类令牌。</p></blockquote><h2 id=42安装-pod-网络附加组件>4.2、安装 Pod 网络附加组件</h2><p>关于 Kubernetes 网络，建议读完这篇 <a href=https://yuerblog.cc/2019/02/25/flannel-and-calico/ target=_blank rel="noopener noreferrer">文章</a>，以及文末的其他链接，如<a href=https://juejin.im/entry/599d33ad6fb9a0247804d430 target=_blank rel="noopener noreferrer">这个</a>。</p><p>集群必须安装Pod网络插件，以使Pod可以相互通信，只需要在Master节点操作，其他新加入的节点会自动创建相关pod。</p><p>必须在任何应用程序之前部署网络组件。另外，在安装网络之前，CoreDNS将不会启动（你可以通过命令 <code>kubectl get pods --all-namespaces|grep coredns</code> 查看 CoreDNS 的状态）。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 查看 CoreDNS 的状态,并不是 Running 状态</span>
</span></span><span style=display:flex><span>$ kubectl get pods --all-namespaces|grep coredns
</span></span><span style=display:flex><span>kube-system   coredns-7f9c544f75-bzksd    0/1   Pending   <span style=color:#ae81ff>0</span>     14m
</span></span><span style=display:flex><span>kube-system   coredns-7f9c544f75-mtrwq    0/1   Pending   <span style=color:#ae81ff>0</span>     14m
</span></span></code></pre></div><p>kubeadm 支持多种网络插件，我们选择 Calico 网络插件（kubeadm 仅支持基于容器网络接口（CNI）的网络（不支持kubenet）。），默认情况下，它给出的pod的IP段地址是 <code>192.168.0.0/16</code> ,如果你的机器已经使用了此IP段，就需要修改这个配置项，将其值改为在初始化 Master 节点时使用 <code>kubeadm init --pod-network-cidr=x.x.x.x/x</code> 的IP地址段，即我们上面配置的 <code>10.10.0.0/16</code> ，大概在625行左右，操作如下:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 获取配置文件</span>
</span></span><span style=display:flex><span>mkdir calico <span style=color:#f92672>&amp;&amp;</span> cd calico
</span></span><span style=display:flex><span>wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 修改配置文件</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 找到 625 行左右的 192.168.0.0/16 ，并修改为我们初始化时配置的 10.10.0.0/16</span>
</span></span><span style=display:flex><span>vim calico.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 部署 Pod 网络组件</span>
</span></span><span style=display:flex><span>kubectl apply -f calico.yaml
</span></span></code></pre></div><p>稍等片刻查询 pod 详情，你也可以使用 <code>watch</code> 命令来实时查看 pod 的状态，等待 Pod 网络组件部署成功后，就可以看到一些信息了，包括 Pod 的 IP 地址信息，这个过程时间可能会有点长。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>watch -n <span style=color:#ae81ff>2</span> kubectl get pods --all-namespaces -o wide
</span></span></code></pre></div><h2 id=43将-worker-节点添加到-kubernetes>4.3、将 Worker 节点添加到 Kubernetes</h2><p>请首先确认 Worker 节点满足第一部分的环境说明，并且已经安装了 Docker 和 kubeadm、kubelet 、kubectl，并且已经启动 kubelet。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 添加 Hosts 解析</span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;127.0.0.1 </span><span style=color:#66d9ef>$(</span>hostname<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span> &gt;&gt; /etc/hosts
</span></span><span style=display:flex><span>export MASTER_IP<span style=color:#f92672>=</span>192.168.115.49
</span></span><span style=display:flex><span>export APISERVER_NAME<span style=color:#f92672>=</span>kuber4s.api
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>MASTER_IP<span style=color:#e6db74>}</span><span style=color:#e6db74> </span><span style=color:#e6db74>${</span>APISERVER_NAME<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> &gt;&gt; /etc/hosts
</span></span></code></pre></div><p>将 Worker 节点添加到集群，这里注意，执行后可能会报错，有幸的话你会跳进这个坑，这是因为 Worker 节点加入集群的命令实际上在初始化 master 时已经有提示出来了，不过两小时后会删除上传的证书，所以如果你此时加入集群的时候提示证书相关的错误，请执行 <code>kubeadm init phase upload-certs --upload-certs</code> 重新加载证书。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm join kuber4s.api:6443 --token 0y1dj2.ih27ainxwyib0911 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --discovery-token-ca-cert-hash sha256:5204b3e358a0d568e147908cba8036bdb63e604d4f4c1c3730398f33144fac61 <span style=color:#ae81ff>\
</span></span></span></code></pre></div><p>执行加入操作，你可能会发现卡着不动，大概率是因为令牌ID对此集群无效或已过 2 小时的有效期（通过执行 <code>kubeadm join --v=5</code> 来获取详细的加入过程，看到了内容为 ”token id "0y1dj2" is invalid for this cluster or it has expired“ 的提示），接下来需要在 Master 上通过 <code>kubeadm token create</code> 来创建新的令牌。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubeadm token create --print-join-command
</span></span><span style=display:flex><span>W0129 19:10:04.842735   <span style=color:#ae81ff>15533</span> validation.go:28<span style=color:#f92672>]</span> Cannot validate kube-proxy config - no validator is available
</span></span><span style=display:flex><span>W0129 19:10:04.842808   <span style=color:#ae81ff>15533</span> validation.go:28<span style=color:#f92672>]</span> Cannot validate kubelet config - no validator is available
</span></span><span style=display:flex><span><span style=color:#75715e># 输出结果如下</span>
</span></span><span style=display:flex><span>kubeadm join kuber4s.api:6443 --token 1hk9bc.oz7f3lmtbzf15x9b     --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f
</span></span></code></pre></div><p>在 Worker 节点上重新执行加入集群命令</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm join kuber4s.api:6443 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --token 1hk9bc.oz7f3lmtbzf15x9b <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f
</span></span></code></pre></div><p>接下来在Master上查看 Worker 节点加入的状况，直到 Worker 节点的状态变为 Ready 便证明加入成功，这个过程可能会有点漫长，30 分钟以内都算正常的，主要看你网络的情况或者说拉取镜像的速度；另外不要一看到 <code>/var/log/messages</code> 里面报错就慌了，那也得看具体报什么错，看不懂就稍微等一下，一般在 Master 上能看到已经加入（虽然没有Ready）就没什么问题。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>watch kubectl get nodes -o wide
</span></span></code></pre></div><h2 id=44添加-master-节点>4.4、添加 Master 节点</h2><p>需要至少2个CPU核心，否则会报错</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm join kuber4s.api:6443 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --token 1hk9bc.oz7f3lmtbzf15x9b <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --control-plane --certificate-key 5253fc7e9a4e6204d0683ed2d60db336b3ff64ddad30ba59b4c0bf40d8ccadcd
</span></span></code></pre></div><h2 id=45补充内容>4.5、补充内容</h2><ul><li><a href=https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/ target=_blank rel="noopener noreferrer">kubeadm init</a> 初始化 Kubernetes 主节点</li><li><a href=https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-token/ target=_blank rel="noopener noreferrer">kubeadm token</a> 管理 <code>kubeadm join</code> 的令牌</li><li><a href=https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-reset/ target=_blank rel="noopener noreferrer">kubeadm reset</a> 将 <code>kubeadm init</code> 或 <code>kubeadm join</code> 对主机的更改恢复到之前状态，一般与 <code>-f</code> 参数使用</li></ul><p>移除 worker 节点</p><p>正常情况下，你无需移除 worker 节点，如果要移除，在准备移除的 worker 节点上执行</p><pre tabindex=0><code>kubeadm reset -f
</code></pre><p>或者在 Control-plane 上执行</p><pre tabindex=0><code>kubectl delete node nodename
</code></pre><blockquote><ul><li>将 nodename 替换为要移除的 worker 节点的名字</li><li>worker 节点的名字可以通过在 Control-plane 上执行 kubectl get nodes 命令获得</li></ul></blockquote><h1 id=五kubernetes-高可用集群>五、Kubernetes 高可用集群</h1><h2 id=51环境说明>5.1、环境说明</h2><p>如果你使用的是以上方法部署你的 Kubernetes 集群，想在当前基础上进行高可用集群的创建，则可以按照下面的步骤继续进行。</p><p>值得注意的是，这里没有将ETCD放在Master外的机器上，而是使用默认的架构，即官方的 Stacked etcd topology 方式的集群</p><p><img src=https://92uu-blog.oss-cn-beijing.aliyuncs.com/2020-03-25-091655.png alt></p><p>你需要至少 3 台 Master 节点和 3 台 Worker 节点，或者更多的机器，但要保证是 Master 和 Worker 节点数都是奇数的，以防止 leader 选举时出现脑裂状况。</p><table><thead><tr><th>机器名称</th><th>机器IP</th><th>工作内容</th></tr></thead><tbody><tr><td>master01</td><td>192.168.115.49</td><td>master、etcd</td></tr><tr><td>master02</td><td>192.168.115.41</td><td>master、etcd</td></tr><tr><td>master03</td><td>192.168.115.42</td><td>master、etcd</td></tr><tr><td>node01</td><td>192.168.115.46</td><td>worker</td></tr><tr><td>node02</td><td>192.168.115.47</td><td>worker</td></tr><tr><td>node03</td><td>192.168.115.48</td><td>worker</td></tr><tr><td>nfs</td><td>192.168.115.50</td><td>存储</td></tr></tbody></table><h2 id=52高可用扩展>5.2、高可用扩展</h2><p>Kubernetes 的高可用扩展其实挺简单，你只需要将不同的 Master 和 Worker 节点加入到集群中就行了。加入的指令在你初始化集群时已经给出了。</p><ul><li>添加 Master 节点：</li></ul><p>需要至少 2 个 CPU 核心，否则会报错</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm join kuber4s.api:6443 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --token 1hk9bc.oz7f3lmtbzf15x9b <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span> --control-plane --certificate-key 5253fc7e9a4e6204d0683ed2d60db336b3ff64ddad30ba59b4c0bf40d8ccadcd
</span></span></code></pre></div><ul><li>添加 Worker 节点</li></ul><p>在 Worker 节点上重新执行加入集群命令</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm join kuber4s.api:6443 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--token 1hk9bc.oz7f3lmtbzf15x9b <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f
</span></span></code></pre></div><h1 id=六安装-kubesphere>六、安装 KubeSphere</h1><h2 id=61kubesphere简介>6.1、KubeSphere简介</h2><p>Kubernetes 官方有提供一套 Dashboard，但是我这里选择功能更强大的 KubeSphere，以下内容引用自 KubeSphere 官网：</p><p><a href=https://kubesphere.com.cn/docs/zh-CN/ target=_blank rel="noopener noreferrer">KubeSphere</a> 是在 <a href=https://kubernetes.io/ target=_blank rel="noopener noreferrer">Kubernetes</a> 之上构建的以应用为中心的容器平台，提供简单易用的操作界面以及向导式操作方式，在降低用户使用容器调度平台学习成本的同时，极大减轻开发、测试、运维的日常工作的复杂度，旨在解决 Kubernetes 本身存在的存储、网络、安全和易用性等痛点。除此之外，平台已经整合并优化了多个适用于容器场景的功能模块，以完整的解决方案帮助企业轻松应对敏捷开发与自动化运维、DevOps、微服务治理、灰度发布、多租户管理、工作负载和集群管理、监控告警、日志查询与收集、服务与网络、应用商店、镜像构建与镜像仓库管理和存储管理等多种场景。后续版本将提供和支持多集群管理、大数据、AI 等场景。</p><p><img src=https://pek3b.qingstor.com/kubesphere-docs/png/20200327114511.png alt></p><h2 id=62安装要求>6.2、安装要求</h2><p>KubeSphere 支持直接在 Linux 上部署集群，也支持在 Kubernetes 上部署，我这里选择后者，基本的要求如下：</p><ul><li><code>Kubernetes</code> 版本：<code>1.15.x ≤ K8s version ≤ 1.17.x</code>；</li><li><code>Helm</code> 版本：<code>2.10.0 ≤ Helm Version ＜ 3.0.0</code>（不支持 helm 2.16.0<a href=https://github.com/helm/helm/issues/6894 target=_blank rel="noopener noreferrer">#6894</a>），且已安装了 Tiller，参考 <a href=https://devopscube.com/install-configure-helm-kubernetes/ target=_blank rel="noopener noreferrer">如何安装与配置 Helm</a>（预计 3.0 支持 Helm v3）；</li><li>集群已有默认的存储类型（StorageClass），若还没有准备存储请参考<a href=https://kubesphere.com.cn/docs/zh-CN/appendix/install-openebs target=_blank rel="noopener noreferrer">安装 OpenEBS 创建 LocalPV 存储类型</a>用作开发测试环境。</li><li>集群能够访问外网，若无外网请参考 <a href=https://kubesphere.com.cn/docs/installation/install-on-k8s-airgapped/ target=_blank rel="noopener noreferrer">在 Kubernetes 离线安装 KubeSphere</a>。</li></ul><h2 id=63安装-helm>6.3、安装 Helm</h2><h3 id=631helm-简介>6.3.1、Helm 简介</h3><p>Helm 基本思想如图所示</p><p><img src=https://92uu-blog.oss-cn-beijing.aliyuncs.com/2020-03-25-095440.png alt></p><p>以下内容引用自 <a href=https://blog.csdn.net/weixin_30566063/article/details/99247145 target=_blank rel="noopener noreferrer">此篇文章</a></p><p><strong>Helm 基本概念</strong></p><p>Helm 可以理解为 Kubernetes 的包管理工具，可以方便地发现、共享和使用为Kubernetes构建的应用，它包含几个基本概念：</p><ul><li>Chart：一个 Helm 包，其中包含了运行一个应用所需要的镜像、依赖和资源定义等，还可能包含 Kubernetes 集群中的服务定义</li><li>Release: 在 Kubernetes 集群上运行的 Chart 的一个实例。在同一个集群上，一个 Chart 可以安装很多次。每次安装都会创建一个新的 release。例如一个 MySQL Chart，如果想在服务器上运行两个数据库，就可以把这个 Chart 安装两次。每次安装都会生成自己的 Release，会有自己的 Release 名称。</li><li>Repository：用于发布和存储 Chart 的仓库。</li></ul><h3 id=632helm安装>6.3.2、Helm安装</h3><p>安装过程如下</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 创建部署目录并下载Helm</span>
</span></span><span style=display:flex><span>mkdir tiller
</span></span><span style=display:flex><span>cd tiller
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 先使用官方的方式安装，如果安装不了，可以看到下载文件的地址，然后手动下载解压</span>
</span></span><span style=display:flex><span>curl -L https://git.io/get_helm.sh | bash
</span></span><span style=display:flex><span><span style=color:#75715e># 获取到下载地址后，想办法下载</span>
</span></span><span style=display:flex><span>wget https://get.helm.sh/helm-v2.16.3-linux-amd64.tar.gz
</span></span><span style=display:flex><span>tar zxf helm-v2.16.3-linux-amd64.tar.gz
</span></span><span style=display:flex><span>mv linux-amd64/helm /usr/local/bin/helm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 验证</span>
</span></span><span style=display:flex><span>helm version
</span></span></code></pre></div><p>部署 Tiller，即 Helm 的服务端。先创建 SA</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># yaml文件如下</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>$ cat /root/tiller/helm-rbac.yaml</span>
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ServiceAccount</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span> <span style=color:#f92672>name</span>: <span style=color:#ae81ff>tiller</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>kube-system</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>rbac.authorization.k8s.io/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ClusterRoleBinding</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span> <span style=color:#f92672>name</span>: <span style=color:#ae81ff>tiller</span>
</span></span><span style=display:flex><span><span style=color:#f92672>roleRef</span>:
</span></span><span style=display:flex><span> <span style=color:#f92672>apiGroup</span>: <span style=color:#ae81ff>rbac.authorization.k8s.io</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ClusterRole</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>name</span>: <span style=color:#ae81ff>cluster-admin</span>
</span></span><span style=display:flex><span><span style=color:#f92672>subjects</span>:
</span></span><span style=display:flex><span> - <span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ServiceAccount</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>name</span>: <span style=color:#ae81ff>tiller</span>
</span></span><span style=display:flex><span> <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>kube-system</span>
</span></span></code></pre></div><p>创建 RBAC：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f helm-rbac.yaml
</span></span></code></pre></div><p>初始化，这个过程可能不会成功，具体接着往下看</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>helm init --service-account<span style=color:#f92672>=</span>tiller --history-max <span style=color:#ae81ff>300</span>
</span></span></code></pre></div><p>检查初始化的情况，不出意外的话，墙内用户看pod详情可以看到获取不到镜像的错误。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get deployment tiller-deploy -n kube-system
</span></span></code></pre></div><p>如果一直获取不到镜像，可以通过更换到Azure中国镜像源来解决，操作步骤如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 编辑 deploy</span>
</span></span><span style=display:flex><span>kubectl edit deploy tiller-deploy -n kube-system
</span></span><span style=display:flex><span><span style=color:#75715e># 查找到image地址，替换为如下地址，保存退出</span>
</span></span><span style=display:flex><span>gcr.azk8s.cn/kubernetes-helm/tiller:v2.16.3
</span></span></code></pre></div><p>接下来稍等片刻，再次查看deployment和pod详情，就正常了</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get deployment tiller-deploy -n kube-system
</span></span></code></pre></div><h2 id=64安装-storageclass>6.4、安装 StorageClass</h2><p>Kubernetes 支持多种 StorageClass，我这选择 NFS 作为集群的 StorageClass。</p><p>参考地址：<a href=https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client target=_blank rel="noopener noreferrer">https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client</a></p><h3 id=641下载所需文件>6.4.1、下载所需文件</h3><p>下载所需文件，并进行内容调整</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mkdir nfsvolume <span style=color:#f92672>&amp;&amp;</span> cd nfsvolume
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> file in class.yaml deployment.yaml rbac.yaml ; <span style=color:#66d9ef>do</span> wget https://raw.githubusercontent.com/kubernetes-incubator/external-storage/master/nfs-client/deploy/$file ; <span style=color:#66d9ef>done</span>
</span></span></code></pre></div><p>修改 deployment.yaml 中的两处 NFS 服务器 IP 和目录</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>...
</span></span><span style=display:flex><span>          <span style=color:#f92672>env</span>:
</span></span><span style=display:flex><span>            - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>PROVISIONER_NAME</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>value</span>: <span style=color:#ae81ff>fuseim.pri/ifs</span>
</span></span><span style=display:flex><span>            - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>NFS_SERVER</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>value</span>: <span style=color:#ae81ff>192.168.115.50</span>
</span></span><span style=display:flex><span>            - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>NFS_PATH</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>value</span>: <span style=color:#ae81ff>/data/k8s</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nfs-client-root</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>nfs</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>server</span>: <span style=color:#ae81ff>192.168.115.50</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>path</span>: <span style=color:#ae81ff>/data/k8s</span>
</span></span></code></pre></div><h2 id=642部署创建>6.4.2、部署创建</h2><p>具体的说明可以去官网查看。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl create -f rbac.yaml
</span></span><span style=display:flex><span>kubectl create -f class.yaml
</span></span><span style=display:flex><span>kubectl create -f deployment.yaml
</span></span></code></pre></div><p>如果日志中看到“上有坏超级块”，请在集群内所有机器上安装nfs-utils并启动。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum -y install nfs-utils
</span></span><span style=display:flex><span>systemctl start nfs-utils
</span></span><span style=display:flex><span>systemctl enable nfs-utils
</span></span><span style=display:flex><span>rpcinfo -p
</span></span></code></pre></div><p>查看storageclass</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get storageclass
</span></span><span style=display:flex><span>NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE
</span></span><span style=display:flex><span>managed-nfs-storage fuseim.pri/ifs Delete Immediate false 10m
</span></span></code></pre></div><h3 id=643标记一个默认的-storageclass>6.4.3、标记一个默认的 StorageClass</h3><p>操作命令格式如下</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl patch storageclass  -p <span style=color:#e6db74>&#39;{&#34;metadata&#34;: {&#34;annotations&#34;:{&#34;storageclass.kubernetes.io/is-default-class&#34;:&#34;true&#34;}}}&#39;</span>
</span></span></code></pre></div><p>请注意，最多只能有一个 StorageClass 能够被标记为默认。</p><p>验证标记是否成功</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get storageclass
</span></span><span style=display:flex><span>NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE
</span></span><span style=display:flex><span>managed-nfs-storage <span style=color:#f92672>(</span>default<span style=color:#f92672>)</span> fuseim.pri/ifs Delete Immediate false 12m
</span></span></code></pre></div><h2 id=65部署-kubesphere>6.5、部署 KubeSphere</h2><p>过程很简单，如果你的机器资源足够，建议你进行完整安装，操作步骤如下。如果你的资源不是很充足，则可以进行最小化安装，<a href=https://kubesphere.com.cn/docs/zh-CN/installation/prerequisites/ target=_blank rel="noopener noreferrer">参考地址</a>。我当然是选择完整安装了，香！</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 下载 yaml 文件</span>
</span></span><span style=display:flex><span>mkdir kubesphere <span style=color:#f92672>&amp;&amp;</span> cd kubesphere
</span></span><span style=display:flex><span>wget https://raw.githubusercontent.com/kubesphere/ks-installer/master/kubesphere-complete-setup.yaml
</span></span><span style=display:flex><span><span style=color:#75715e># 部署 KubeSphere</span>
</span></span><span style=display:flex><span>kubectl apply -f kubesphere-complete-setup.yaml
</span></span></code></pre></div><p>这个过程根据你实际网速，实际使用时间长度有所不同。你可以通过如下命令查看实时的日志输出。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl logs -n kubesphere-system <span style=color:#66d9ef>$(</span>kubectl get pod -n kubesphere-system -l app<span style=color:#f92672>=</span>ks-install -o jsonpath<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;{.items[0].metadata.name}&#39;</span><span style=color:#66d9ef>)</span> -f
</span></span></code></pre></div><p>当你看到如下日志输出，证明你的 KubeSphere 部署成功</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>**************************************************
</span></span><span style=display:flex><span>task monitoring status is successful
</span></span><span style=display:flex><span>task notification status is successful
</span></span><span style=display:flex><span>task devops status is successful
</span></span><span style=display:flex><span>task alerting status is successful
</span></span><span style=display:flex><span>task logging status is successful
</span></span><span style=display:flex><span>task openpitrix status is successful
</span></span><span style=display:flex><span>task servicemesh status is successful
</span></span><span style=display:flex><span>total: <span style=color:#ae81ff>7</span>     completed:7
</span></span><span style=display:flex><span>**************************************************
</span></span><span style=display:flex><span><span style=color:#75715e>#####################################################</span>
</span></span><span style=display:flex><span><span style=color:#75715e>###              Welcome to KubeSphere!           ###</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#####################################################</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Console: http://192.168.115.49:30880
</span></span><span style=display:flex><span>Account: admin
</span></span><span style=display:flex><span>Password: P@88w0rd
</span></span><span style=display:flex><span><span style=color:#75715e>#####################################################</span>
</span></span></code></pre></div><p>确认 Pod 都正常运行后，可使用<code>IP:30880</code>访问 KubeSphere UI 界面，默认的集群管理员账号为<code>admin/P@88w0rd</code>，Enjoy it，😏！</p><p><img src=https://92uu-blog.oss-cn-beijing.aliyuncs.com/2020-03-25-103029.png alt></p><p><img src=https://92uu-blog.oss-cn-beijing.aliyuncs.com/2020-03-25-145648.png alt></p><h2 id=参考>参考</h2><p>本文出处 Segmentfault：<code>https://segmentfault.com/a/1190000022146020</code></p></div></div><div class=share-2><div class=share><a href="https://twitter.com/intent/tweet?url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-kubesphere-ha%2f&text=%e6%89%8b%e6%8a%8a%e6%89%8b%e4%bb%8e%e9%9b%b6%e9%83%a8%e7%bd%b2%e4%b8%8e%e8%bf%90%e8%90%a5%e7%94%9f%e4%ba%a7%e7%ba%a7%e7%9a%84%20Kubernetes%20%e9%9b%86%e7%be%a4%e4%b8%8e%20KubeSphere" target=_blank rel="noopener noreferrer"><img src=/images/share/Twitter.svg alt="twitter icon">
</a><a href="https://reddit.com/submit?url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-kubesphere-ha%2f&title=%e6%89%8b%e6%8a%8a%e6%89%8b%e4%bb%8e%e9%9b%b6%e9%83%a8%e7%bd%b2%e4%b8%8e%e8%bf%90%e8%90%a5%e7%94%9f%e4%ba%a7%e7%ba%a7%e7%9a%84%20Kubernetes%20%e9%9b%86%e7%be%a4%e4%b8%8e%20KubeSphere" target=_blank rel="noopener noreferrer"><img src=/images/share/Reddit.svg alt="reddit icon">
</a><a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-kubesphere-ha%2f" target=_blank rel="noopener noreferrer"><img src=/images/share/Facebook.svg alt="facebook icon">
</a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-kubesphere-ha%2f" target=_blank rel="noopener noreferrer"><img src=/images/share/Linkedin.svg alt="linkedin icon">
</a><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fopenksc.github.io%2fzh%2fblogs%2fkubernetes-kubesphere-ha%2f&t=%e6%89%8b%e6%8a%8a%e6%89%8b%e4%bb%8e%e9%9b%b6%e9%83%a8%e7%bd%b2%e4%b8%8e%e8%bf%90%e8%90%a5%e7%94%9f%e4%ba%a7%e7%ba%a7%e7%9a%84%20Kubernetes%20%e9%9b%86%e7%be%a4%e4%b8%8e%20KubeSphere" target=_blank rel="noopener noreferrer"><img src=/images/share/HackerNews.svg alt="hackernews icon"></a></div></div></div><div class=aside><div class=inner-div><div class=title>目录</div><div class=tabs><nav id=TableOfContents><ul><li><a href=#一准备环境>一、准备环境</a></li></ul><ul><li><a href=#21安装-docker>2.1、安装 Docker</a></li><li><a href=#22修改-cgroup-driver>2.2、修改 Cgroup Driver</a></li></ul><ul><li><a href=#31安装准备>3.1、安装准备</a></li><li><a href=#32开始安装>3.2、开始安装</a></li></ul><ul><li><a href=#41初始化-control-planemaster-节点>4.1、初始化 Control-plane/Master 节点</a></li><li><a href=#42安装-pod-网络附加组件>4.2、安装 Pod 网络附加组件</a></li><li><a href=#43将-worker-节点添加到-kubernetes>4.3、将 Worker 节点添加到 Kubernetes</a></li><li><a href=#44添加-master-节点>4.4、添加 Master 节点</a></li><li><a href=#45补充内容>4.5、补充内容</a></li></ul><ul><li><a href=#51环境说明>5.1、环境说明</a></li><li><a href=#52高可用扩展>5.2、高可用扩展</a></li></ul><ul><li><a href=#61kubesphere简介>6.1、KubeSphere简介</a></li><li><a href=#62安装要求>6.2、安装要求</a></li><li><a href=#63安装-helm>6.3、安装 Helm</a><ul><li><a href=#631helm-简介>6.3.1、Helm 简介</a></li><li><a href=#632helm安装>6.3.2、Helm安装</a></li></ul></li><li><a href=#64安装-storageclass>6.4、安装 StorageClass</a><ul><li><a href=#641下载所需文件>6.4.1、下载所需文件</a></li></ul></li><li><a href=#642部署创建>6.4.2、部署创建</a><ul><li><a href=#643标记一个默认的-storageclass>6.4.3、标记一个默认的 StorageClass</a></li></ul></li><li><a href=#65部署-kubesphere>6.5、部署 KubeSphere</a></li><li><a href=#参考>参考</a></li></ul></nav></div></div></div></div></section><div class=SubscribeForm><div class=innerBox><img class=close src=/images/home/close.svg alt=close><p class=description>通过邮件接收 KubeSphere 最新的技术博客与产品更新的通知</p><div id=blog_formAddress data-actionaddress="https://www.sendcloud.net/v3/api/subInvite/subscription?invitecode=1dc5a4fb-894c-4470-b01d-ca7fa9d47a46" data-usesendcloud=true data-lang=zh><input name=EMAIL id=email-input-blog type=text placeholder>
<button id=email-submit-blog>订阅</button>
<span id=message_blog data-message1=请提供您的邮箱 data-message2=请输入有效的邮箱地址! data-message3=邮箱地址已经存在 style=color:red></span><span id=message1_blog style=color:#00a971 data-success=订阅成功啦，我们保证不会给你发垃圾邮件的啦></span></div></div></div><footer><div class=footer><div class="footer-main common-layout"><div class=up-main><div class=left-div><img src=/images/logo.svg alt class=foot-logo><p>通过邮件接收 KubeSphere 最新的技术博客与产品更新的通知</p><div id=formAddress data-actionaddress="https://www.sendcloud.net/v3/api/subInvite/subscription?invitecode=1dc5a4fb-894c-4470-b01d-ca7fa9d47a46" data-usesendcloud=true data-lang=zh><input name=EMAIL id=email-input type=text placeholder=请输入您的邮箱地址>
<button id=email-submit>订阅</button></div><span id=message data-message1=请提供您的邮箱 data-message2=请输入有效的邮箱地址! data-message3=邮箱地址已经存在></span><span id=message1 style=color:#00a971 data-success=订阅成功啦，我们保证不会给你发垃圾邮件的啦></span><script>var bindSubmit=function(){var e=$("#email-input");$("#email-submit").click(function(t){t.stopPropagation();var s,o,n=e.val(),i=$("#message").data("message1"),a=$("#message").data("message2"),r=$("#message").data("message3"),c=$("#message1").data("success");if(n)if(validateEmail(n)){if(s=$("#formAddress").data("usesendcloud"),!s)return;o=$("#formAddress").data("actionaddress"),$.post({type:"post",url:o,data:{email:$("#email-input").val().toString()},success:function(){showSuccessMessage(c),setTimeout(function(){$("#email-input").val("")},1e3)},error:function(){showMessage(r)}})}else t.preventDefault(),showMessage(a);else t.preventDefault(),showMessage(i)})},validateEmail=function(e){var t=/^[A-Za-z0-9]+([_.][A-Za-z0-9]+)*@([A-Za-z0-9-]+\.)+[A-Za-z]{2,6}$/;return t.test(e)},showMessage=function(e){$("#message").html(e).show()},showSuccessMessage=function(e){$("#message1").html(e).show()},bindHideMessage=function(){$(window).click(function(){$("#message").hide(),$("#message1").hide()})},bindClose=function(){$(".formBox .close").click(function(e){e.stopPropagation(),$(".formBox").fadeOut()})};bindSubmit(),bindClose(),bindHideMessage()</script><span id=message data-message1=请提供您的邮箱 data-message2=请输入有效的邮箱地址!></span></div><div class=right-div><ul class=common-flex-layout><li class=nowrap-li><div class=h3>应用场景</div><a href=/zh/devops/>拥抱一站式 DevOps</a>
<a href=/zh/service-mesh/>在 K8s 运行微服务</a>
<a href=/zh/observability/>构建云原生可观测性</a>
<a href=https://github.com/kubesphere/kubekey target=_blank rel="noopener noreferrer">K8s 一键部署与运维</a>
<a href=https://github.com/OpenFunction/OpenFunction target=_blank rel="noopener noreferrer">构建 FaaS 平台与 Serverless 架构</a>
<a href=https://github.com/openpitrix/openpitrix target=_blank rel="noopener noreferrer">多云应用管理平台</a></li><li class=nowrap-li><div class=h3>资源</div><a href=/zh/projects/>开源项目</a>
<a href=/zh/blogs/>技术博客</a>
<a href=/zh/conferences/>开源峰会</a>
<a href=/zh/videos/>视频资源</a>
<a href=/zh/learn/>云原生实战</a></li><li class=nowrap-li><div class=h3>文档中心</div><a href=/zh/docs/v4.1/01-intro/01-introduction/>产品介绍</a>
<a href=/zh/docs/v4.1/03-installation-and-upgrade/02-install-kubesphere/02-install-kubernetes-and-kubesphere/>如何安装</a>
<a href=/zh/docs/v4.1/02-quickstart/>快速入门</a>
<a href=/zh/docs/v3.4/reference/api-docs/>API 文档</a></li><li class=nowrap-li><div class=h3>开源社区</div><a href=/zh/contribution/>参与贡献</a>
<a href=/zh/live/>社区活动</a>
<a href=/zh/case/>案例学习</a>
<a href=/zh/partner/>合作伙伴</a>
<a href=/zh/user-group/>用户委员会</a>
<a href=https://github.com/kubesphere/kubesphere/blob/master/docs/roadmap.md target=_blank rel="noopener noreferrer">版本计划</a>
<a href=https://kubesphere.com.cn/ target=_blank rel="noopener noreferrer">中国站</a>
<a href=https://ask.kubesphere.io/forum target=_blank rel="noopener noreferrer">中文论坛</a>
<a href=https://kubesphere.io target=_blank rel="noopener noreferrer">全球站</a></li><li class=nowrap-li><div class=h3>产品与服务</div><a href=https://aws.amazon.com/cn/quickstart/architecture/qingcloud-kubesphere/ target=_blank rel="noopener noreferrer">KubeSphere on AWS</a>
<a href=https://market.azure.cn/marketplace/apps/qingcloud.kubesphere target=_blank rel="noopener noreferrer">KubeSphere on Azure</a>
<a href=https://marketplace.digitalocean.com/apps/kubesphere target=_blank rel="noopener noreferrer">KubeSphere on DigitalOcean</a>
<a href=https://www.qingcloud.com/products/kubesphereqke target=_blank rel="noopener noreferrer">KubeSphere on QingCloud(QKE)</a>
<a href=https://kubesphere.com.cn/kse/ target=_blank rel="noopener noreferrer">KubeSphere 企业版</a>
<a href=https://kubesphere.cloud/ksv/ target=_blank rel="noopener noreferrer">KubeSphere 虚拟化平台</a>
<a href=https://kubesphere.com.cn/marketplace/ target=_blank rel="noopener noreferrer">云原生扩展组件市场</a>
<a href=https://kubesphere.cloud target=_blank rel="noopener noreferrer">云原生应用服务平台</a>
<a href=https://m.qingcloud.com/p/aec50 target=_blank rel="noopener noreferrer">了解商业产品与咨询合作</a></li></ul></div></div><div class=down-main><div class=img-div><a class=wechat href=javascript:void(0); aria-label=wechat><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28" height="28" viewBox="0 0 28 28"><defs><path id="a" d="M0 0h15.673v12.156H0z"/></defs><g fill="none" fill-rule="evenodd" transform="translate(1 1)"><circle cx="13" cy="13" r="13" stroke="#B6C2CD"/><g transform="translate(5 7)"><mask id="b" fill="#fff"><use xlink:href="#a"/></mask><path fill="currentColor" d="M15.673 7.898c0-2.061-2.173-3.74-4.619-3.74-2.59.0-4.625 1.679-4.625 3.74.0 2.066 2.035 3.738 4.625 3.738.542.0 1.09-.13 1.632-.256l1.493.776-.408-1.29c1.09-.776 1.902-1.81 1.902-2.968zm-6.119-.645c-.27.0-.541-.257-.541-.514.0-.256.27-.514.541-.514.41.0.681.258.681.514.0.257-.271.514-.681.514zm2.994.0c-.27.0-.541-.257-.541-.514.0-.256.27-.514.54-.514.41.0.681.258.681.514.0.257-.277.514-.68.514z" mask="url(#b)"/><path fill="currentColor" d="M10.602 3.674c.177.0.356.011.533.029C10.657 1.576 8.27.0 5.543.0 2.498.0.0 1.974.0 4.485c0 1.45.829 2.64 2.216 3.564l-.552 1.588 1.94-.929c.693.129 1.251.263 1.94.263.17.0.343-.005.515-.022a3.68 3.68.0 01-.172-1.104c0-2.302 2.081-4.171 4.715-4.171zM7.618 2.243c.417.0.693.263.693.66s-.276.66-.693.66c-.418.0-.835-.263-.835-.66.006-.398.423-.66.835-.66zm-3.88 1.319c-.417.0-.834-.263-.834-.66s.417-.66.834-.66c.418.0.695.263.695.66.0.392-.277.66-.695.66z" mask="url(#b)"/></g></g></svg><div class=hide-div><img src=/images/home/wechat.svg alt></div></a><a class=facebook-a href=https://www.facebook.com/kubesphere target=_blank aria-label=facebook></a><a class=twitter-a href=https://x.com/KubeSphere target=_blank aria-label=twitter rel="noopener noreferrer"></a><a class=linkedin-a href=https://www.linkedin.com/company/kubesphere/ target=_blank aria-label=linkedin rel="noopener noreferrer"></a><a class=bilibili-a href=https://space.bilibili.com/438908638 target=_blank aria-label=bilibili rel="noopener noreferrer"></a><a class=slack-a href=https://join.slack.com/t/kubesphere/shared_invite/zt-2b4t6rdb4-ico_4UJzCln_S2c1pcrIpQ target=_blank aria-label=slack rel="noopener noreferrer"></a><a class=github-a href=https://github.com/kubesphere/kubesphere target=_blank aria-label=github rel="noopener noreferrer"></a><a class=medium-a href=https://itnext.io/@kubesphere target=_blank aria-label=medium rel="noopener noreferrer"></a></div><p class=p1></p><p class=case><a href=http://www.beian.miit.gov.cn/ target=_blank rel="noopener noreferrer"><span>京ICP备13019086号</span>
</a><a target=_blank rel="noopener noreferrer" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010502041003"><img src=/images/footer/case-icon.png alt=备案图标>
<span>京公网安备 11010502041003号</span></a></p></div></div></div><div class=cookie><div class=common-layout><p>您的隐私对我们很重要。我们使用Cookie来记住订阅详细信息，优化网站功能并交付根据您的兴趣量身定制的内容。要了解更多信息，请参阅我们的<a href=/zh/privacy>隐私政策</a>.</p><button>
接受并继续</button></div></div></footer><script>var lazyLoad=function(e,t){for(var n,o,i,s=0;s<t;s++){if(n=e.eq(s),o=n.attr("data-loaded"),o)continue;n.offset().top<parseInt($(window).height())+parseInt($(window).scrollTop())&&(i=n.attr("src"),n.attr("src",i),n.attr("data-loaded",!0))}},bindLayLoad=function(){var e=$("img"),t=e.length;lazyLoad(e,t),$(window).scroll(function(){lazyLoad(e,t)})},bindAddPadding=function(){var e=$("#close-join");e.length>0&&$(".main-section").addClass("padding")},docCookies={getItem:function(e){return decodeURIComponent(document.cookie.replace(new RegExp("(?:(?:^|.*;)\\s*"+encodeURIComponent(e).replace(/[-.+*]/g,"\\$&")+"\\s*\\=\\s*([^;]*).*$)|^.*$"),"$1"))||null},setItem:function(e,t){return!!e&&!/^(?:expires|max-age|path|domain|secure)$/i.test(e)&&(document.cookie=encodeURIComponent(e)+"="+encodeURIComponent(t),!0)}},bindHideCookie=function(){var t=docCookies.getItem("hasAuth"),e=$(".cookie");t?e.hide():e.show(),e.find("button").on("click",function(){docCookies.setItem("hasAuth","1"),e.hide()})};bindAddPadding(),bindHideCookie()</script><script type=text/javascript src=/js/aside.2d6977c0f16aef4ed3e886dd66675ce74bd0efcd467c2b2bcdb30b92d5e7c7c0e5c6e0c9d8f09a883c22f58df9e6b0b6347fcdd3c9a920b7faba6d7f91a201c3.js integrity="sha512-LWl3wPFq707T6IbdZmdc50vQ781GfCsrzbMLktXnx8DlxuDJ2PCaiDwi9Y355rC2NH/N08mpILf6um1/kaIBww=="></script><script type=text/javascript src=/js/markdown-tab.17f9f46b021adebc7250ce1b07134a577b307e7a436daa4aaf388f218e8463966f53770b26a64817c06c168738a887672d47fb4c29615adfc446e11d09a344cf.js integrity="sha512-F/n0awIa3rxyUM4bBxNKV3swfnpDbapKrziPIY6EY5ZvU3cLJqZIF8BsFoc4qIdnLUf7TClhWt/ERuEdCaNEzw=="></script><script>let forbidForm=!1;var viewer=new Viewer(document.querySelector(".md-body"),{url:"src"}),blogBindSubmit=function(){var e=$("#email-input-blog");$("#email-submit-blog").click(function(t){t.stopPropagation();var s,o,n=e.val(),i=$("#message_blog").data("message1"),a=$("#message_blog").data("message2"),r=$("#message_blog").data("message3"),c=$("#message1_blog").data("success");if(n)if(validateEmail(n)){if(s=$("#blog_formAddress").data("usesendcloud"),!s)return;o=$("#blog_formAddress").data("actionaddress"),$.post({type:"post",url:o,data:{email:n.toString()},success:function(){showSuccessMessage_blog(c),setTimeout(function(){window.onscroll="",$(".SubscribeForm").hide(),$("#email-input-blog").val("")},5e3)},error:function(){showMessage_blog(r)}})}else t.preventDefault(),$("#message_blog").html(a).show();else t.preventDefault(),$("#message_blog").html(i).show()})},validateEmail=function(e){var t=/^[A-Za-z0-9]+([_.][A-Za-z0-9]+)*@([A-Za-z0-9-]+\.)+[A-Za-z]{2,6}$/;return t.test(e)},bindHideMessageBlog=function(){$(window).click(function(){$("#message_blog").hide()})},bindCloseBlog=function(){$(".SubscribeForm .close").click(function(e){e.stopPropagation(),$(".SubscribeForm").fadeOut(),window.onscroll=""})},showMessage_blog=function(e){$("#message_blog").html(e).show()},showSuccessMessage_blog=function(e){$("#message1_blog").html(e).show()};window.onscroll=()=>{var e=document.documentElement.scrollTop||document.body.scrollTop,t=document.documentElement.clientHeight||document.body.clientHeight,n=document.documentElement.scrollHeight||document.body.scrollHeight;forbidForm&&(window.onscroll=""),e+t>n-710?$(".SubscribeForm").hide():$(".SubscribeForm").show()},blogBindSubmit(),bindCloseBlog(),bindHideMessageBlog()</script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script></body></html>